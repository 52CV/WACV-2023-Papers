# 52CV-WACV-Papers
![469c6797185d7c14eb859840ed9bb06](https://user-images.githubusercontent.com/62801906/209522296-cea08a9c-9f23-4ece-9093-69863b2e7027.jpg)

官网链接：[https://wacv2023.thecvf.com/home](https://wacv2023.thecvf.com/home)

会议日期：2023年1月3日-1月7日

## 历年综述论文分类汇总戳这里↘️[CV-Surveys](https://github.com/52CV/CV-Surveys)施工中~~~~~~~~~~

## 2023 年论文分类汇总戳这里
↘️[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
↘️[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)

## 2022 年论文分类汇总戳这里
↘️[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers)
↘️[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
↘️[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers)

## 2021年论文分类汇总戳这里
↘️[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
↘️[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

## 2020 年论文分类汇总戳这里
↘️[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers)
↘️[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)


# :exclamation::exclamation::exclamation::star2::star2::star2:WACV 2023收录论文已全部公布，下载可在【我爱计算机视觉】后台回复“paper”，即可收到。共计 638 篇。
# 目录

|:dog:|:mouse:|:hamster:|:tiger:|
|---------|---------|---------|---------|
|[53.Gaze Estimation(视线估计)](#53)|[54.Optical Flow(光流)](#54)|[55.Object Counting(物体计数)](#55)|
|[49.Debiasing(去偏见)](#49)|[50.Sign Language Translation(手语翻译)](#50)|[51.SSC(语义场景完成)](#51)|[52.Eye Tracking(眼动跟踪)](#52)|
|[45.Class-Incremental Learning(类增量学习)](#45)|[46.Metric Learning(度量学习)](#46)|[47.Data Augmentation(数据增强)](#47)|[48.Light Fields(光场)](#48)|
|[41.Action Generation(动作生成)](#41)|[42.Landmark Detection(关键点检测)](#42)|[43.Active Learning(主动学习)](#43)|[44.Multi-Task Learning(多任务学习)](#44)|
|[37.OT(目标跟踪)](#37)|[38.Sound(音频处理)](#38)|[39.Style Transfer(风格迁移)](#39)|[40.AD(异常检测)](#40)|
|[33.View Synthesis(视图合成)](#33)|[34.SLAM\Robots](#34)|[35.VQA(视觉问答)](#35)|[36.Soft Biometrics(软生物技术)](#36)|
|[29.Image Classification(图像分类)](#29)|[30.RL(强化学习)](#30)|[31.Deepfake Detection(假象检测)](#31)|[32.Continual Learning(持续学习)](#32)|
|[25.Image Captioning(图像字幕)](#25)|[26.Dataset(数据集)](#26)|[27.Defect Detection(缺陷检测)](#27)|[28.OPE(物体姿态估计)](#28)|
|[21.PC(点云)](#21)|[22.HAR(人体动作识别与检测)](#22)|[23.AD(智能驾驶)](#23)|[24.Image Retrieval(图像检索)](#24)|
|[17.OCR(文本检测)](#17)|[18.NAS(神经架构搜索)](#18)|[19.MC\KD\Pruning(模型压缩\知识蒸馏\剪枝)](#19)|[20.Transformer](#20)|
|[13.Image Segmentation(图像分割)](#13)|[14.SSL(半监督学习)](#14)|[15.Image Synthesis(图像合成)](#15)|[16.SR(超分辨率)](#16)|
|[9.RS\Satellite Image(遥感\卫星图像)](#9)|[10.AL(对抗学习)](#10)|[11.Face(人脸)](#11)|[12.FSL or DA\G(小样本学习 or 域适应\泛化)](#12)|
|[5.OD(目标检测)](#5)|[6.Video(视频相关)](#6)|[7.Pose(人体姿态)](#7)|[8.Image Processing(图像处理)](#8)|
|[1.其它](#1)|[2.Medical Image(医学影像)](#2)|[3.3D(三维视觉)](#3)|[4.GAN(生成对抗网络)](#4)|


## 合成说话头
* 唇语阅读
  * [Towards MOOCs for Lipreading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale](https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Towards_MOOCs_for_Lipreading_Using_Synthetic_Talking_Heads_To_Train_WACV_2023_paper.pdf)

## Place Recognition(位置识别)
* [ETR: An Efficient Transformer for Re-ranking in Visual Place Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_ETR_An_Efficient_Transformer_for_Re-Ranking_in_Visual_Place_Recognition_WACV_2023_paper.pdf)
* [MixVPR: Feature Mixing for Visual Place Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Ali-bey_MixVPR_Feature_Mixing_for_Visual_Place_Recognition_WACV_2023_paper.pdf)
## Dense Prediction
* [Dense Prediction With Attentive Feature Aggregation](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Dense_Prediction_With_Attentive_Feature_Aggregation_WACV_2023_paper.pdf)
## Neural Radiance(渲染)
* [Ev-NeRF: Event Based Neural Radiance Field](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Jointly_Learning_Band_Selection_and_Filter_Array_Design_for_Hyperspectral_WACV_2023_paper.pdf)
* [DDNeRF: Depth Distribution Neural Radiance Fields](https://openaccess.thecvf.com/content/WACV2023/papers/Dadon_DDNeRF_Depth_Distribution_Neural_Radiance_Fields_WACV_2023_paper.pdf)
* [X-NeRF: Explicit Neural Radiance Field for Multi-Scene 360deg Insufficient RGB-D Views](https://openaccess.thecvf.com/content/WACV2023/papers/Zhu_X-NeRF_Explicit_Neural_Radiance_Field_for_Multi-Scene_360deg_Insufficient_RGB-D_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/HaoyiZhu/XNeRF)

##  geo-localization(城市地理定位)

## Image-to-Image Translation(图像-图像翻译)
* [Panoptic-Aware Image-to-Image Translation](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Panoptic-Aware_Image-to-Image_Translation_WACV_2023_paper.pdf)

## Human Motion Prediction(人类运动预测)
* [Multi-view Tracking Using Weakly Supervised Human Motion Prediction](https://arxiv.org/abs/2210.10771)<br>:star:[code](https://github.com/cvlab-epfl/MVFlow)
* [Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation](https://arxiv.org/abs/2210.12649)<br>:star:[code](https://github.com/zeyun-zhong/AFFT)
* [GliTr: Glimpse Transformers with Spatiotemporal Consistency for Online Action Prediction](https://arxiv.org/abs/2210.13605)

## 场景图生成
* [Grounding Scene Graphs on Natural Images via Visio-Lingual Message Passing](https://arxiv.org/abs/2211.01969)<br>:star:[code](https://github.com/IISCAditayTripathi/Scene-graph-localization):house:[project](https://iiscaditaytripathi.github.io/sgl/)

## Contrastive Learning
* [Similarity Contrastive Estimation for Self-Supervised Soft Contrastive Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Denize_Similarity_Contrastive_Estimation_for_Self-Supervised_Soft_Contrastive_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/CEA-LIST/SCE)

## Human Object Interaction(人物交互)
* 手物交互  
  * [Fine-grained Affordance Annotation for Egocentric Hand-Object Interaction Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_Fine-Grained_Affordance_Annotation_for_Egocentric_Hand-Object_Interaction_Videos_WACV_2023_paper.pdf)

## Person ReID
* 行人搜索
  * [Gallery Filter Network for Person Search](https://arxiv.org/abs/2210.12903)<br>:star:[code](https://github.com/LukeJaffe/GFN)
  * [UPAR: Unified Pedestrian Attribute Recognition and Person Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Specker_UPAR_Unified_Pedestrian_Attribute_Recognition_and_Person_Retrieval_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/speckean/upar_dataset)
  * [SAT: Scale-Augmented Transformer for Person Search](https://openaccess.thecvf.com/content/WACV2023/papers/Fiaz_SAT_Scale-Augmented_Transformer_for_Person_Search_WACV_2023_paper.pdf)
* Re-id
  * [Camera Alignment and Weighted Contrastive Learning for Domain Adaptation in Video Person ReID](https://arxiv.org/abs/2211.03626)<br>:star:[code](https://github.com/dmekhazni/CAWCL-ReID)
  * [MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification](https://arxiv.org/abs/2211.04656)<br>:star:[code](https://github.com/Kitware/MEVID)
  * [Feature Disentanglement Learning with Switching and Aggregation for Video-based Person Re-Identification](https://arxiv.org/abs/2212.09498)
  * [Graph-Based Self-Learning for Robust Person Re-Identification](https://openaccess.thecvf.com/content/WACV2023/papers/Xian_Graph-Based_Self-Learning_for_Robust_Person_Re-Identification_WACV_2023_paper.pdf)
  * [Body Part-Based Representation Learning for Occluded Person Re-Identification](https://openaccess.thecvf.com/content/WACV2023/papers/Somers_Body_Part-Based_Representation_Learning_for_Occluded_Person_Re-Identification_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/VlSomers/bpbreid)
* 步态识别
  * [Gait Recognition Using 3-D Human Body Shape Inference](https://arxiv.org/abs/2212.09042)
* 步态迁移
  * [CTrGAN: Cycle Transformers GAN for Gait Transfer](https://openaccess.thecvf.com/content/WACV2023/papers/Mahpod_CTrGAN_Cycle_Transformers_GAN_for_Gait_Transfer_WACV_2023_paper.pdf)
* 嫌疑人识别
  * [A Suspect Identification Framework using Contrastive Relevance Feedback](https://cdn.iiit.ac.in/cdn/precog.iiit.ac.in/pubs/WACV_2023_FaIRCoP_Camera_Ready.pdf)
* 人群计数
  * [Dynamic Mixture of Counter Network for Location-Agnostic Crowd Counting](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_Dynamic_Mixture_of_Counter_Network_for_Location-Agnostic_Crowd_Counting_WACV_2023_paper.pdf)

## 57.Federated Learning(联邦学习)
* [Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning](https://arxiv.org/abs/2210.02326)<br>:star:[code](https://github.com/Erosinho13/LADD)
* [Federated Learning for Commercial Image Sources](https://openaccess.thecvf.com/content/WACV2023/papers/Jain_Federated_Learning_for_Commercial_Image_Sources_WACV_2023_paper.pdf)

## 56.Vision-Language(视觉语言)
* [VL-Taboo: An Analysis of Attribute-based Zero-shot Capabilities of Vision-Language Models](https://arxiv.org/abs/2209.06103)<br>:star:[code](https://github.com/felixVogel02/VL-Taboo/tree/main)
* [Learning by Hallucinating: Vision-Language Pre-training with Weak Supervision](https://arxiv.org/abs/2210.13591)
* [Perceiver-VL: Efficient Vision-and-Language Modeling with Iterative Latent Attention](https://arxiv.org/abs/2211.11701)<br>:star:[code](https://github.com/zinengtang/Perceiver_VL)

<a name="55"/>

## 55.Object Counting(物体计数)

<a name="54"/>

## 54.Optical Flow(光流)
* [Weakly-Supervised Optical Flow Estimation for Time-of-Flight](https://arxiv.org/abs/2210.05298)
* [Rebalancing Gradient To Improve Self-Supervised Co-Training of Depth, Odometry and Optical Flow Predictions](https://openaccess.thecvf.com/content/WACV2023/papers/Hariat_Rebalancing_Gradient_To_Improve_Self-Supervised_Co-Training_of_Depth_Odometry_and_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/mhariat/CoopNet)
* [DCVNet: Dilated Cost Volume Networks for Fast Optical Flow](https://openaccess.thecvf.com/content/WACV2023/papers/Jiang_DCVNet_Dilated_Cost_Volume_Networks_for_Fast_Optical_Flow_WACV_2023_paper.pdf)

<a name="53"/>

## 53.Gaze Estimation(视线估计)
* iris localization(虹膜定位)
  * [Segmentation-free Direct Iris Localization Networks](https://arxiv.org/abs/2210.10403)
* 视线跟随
  * [Patch-level Gaze Distribution Prediction for Gaze Following](https://arxiv.org/abs/2211.11062)

<a name="52"/>

## 52.Eye Tracking(眼动跟踪)

<a name="51"/>

## 51.Semantic Scene Completion(语义场景完成SSC)

<a name="50"/>

## 50.Sign Language Translation(手语翻译)

<a name="49"/>

## 49.Debiasing(去偏见)

<a name="48"/>

## 48.Light Fields(光场)
* 相机
  * [Event-based RGB sensing with structured light](https://openaccess.thecvf.com/content/WACV2023/papers/Bajestani_Event-Based_RGB_Sensing_With_Structured_Light_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/MISTLab/event_based_rgbd_ros)
* 兴趣点检测
  * [EventPoint: Self-Supervised Interest Point Detection and Description for Event-Based Camera](https://openaccess.thecvf.com/content/WACV2023/papers/Huang_EventPoint_Self-Supervised_Interest_Point_Detection_and_Description_for_Event-Based_Camera_WACV_2023_paper.pdf)

<a name="47"/>

## 47.Data Augmentation(数据增强)
* [Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive Positive or Negative Data Augmentation](https://arxiv.org/abs/2210.12681)<br>:star:[code](https://github.com/AtsuMiyai/rethinking_rotation)

<a name="46"/>

## 46.Metric Learning(度量学习)
* [InDiReCT: Language-Guided Zero-Shot Deep Metric Learning for Images](https://arxiv.org/abs/2211.12760)<br>:star:[code](https://github.com/LSX-UniWue/InDiReCT)

<a name="45"/>

## 45.Class-Incremental Learning(类增量学习)
* [AdvisIL - A Class-Incremental Learning Advisor](https://openaccess.thecvf.com/content/WACV2023/papers/Feillet_AdvisIL_-_A_Class-Incremental_Learning_Advisor_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/EvaJF/AdvisIL)
* 增量学习
  * [Neural Weight Search for Scalable Task Incremental Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Jiang_Neural_Weight_Search_for_Scalable_Task_Incremental_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/JianJiangKCL/NeuralWeightSearch)

<a name="44"/>

## 44.Multi-Task Learning(多任务学习)

<a name="43"/>

## 43.Active Learning(主动学习)

<a name="42"/>

## 42.Landmark Detection(关键点检测)
* [CoKe: Contrastive Learning for Robust Keypoint Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Bai_CoKe_Contrastive_Learning_for_Robust_Keypoint_Detection_WACV_2023_paper.pdf)

<a name="41"/>

## 41.Action Generation(动作生成)
* 全身运动合成
  * [DSAG: A Scalable Deep Framework for Action-Conditioned Multi-Actor Full Body Motion Synthesis](https://openaccess.thecvf.com/content/WACV2023/papers/Gupta_DSAG_A_Scalable_Deep_Framework_for_Action-Conditioned_Multi-Actor_Full_Body_WACV_2023_paper.pdf)

<a name="40"/>

## 40.Anomaly Detection(异常检测)
* [Asymmetric Student-Teacher Networks for Industrial Anomaly Detection](https://arxiv.org/abs/2210.07829)<br>:star:[code](https://github.com/marco-rudolph/ast)
* [Zero-Shot Versus Many-Shot: Unsupervised Texture Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Aota_Zero-Shot_Versus_Many-Shot_Unsupervised_Texture_Anomaly_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://drive.google.com/drive/folders/10OyPzvI3H6llCZBxKxFlKWt1Pw1tkMK1)
* 异常聚类
  * [Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly Types](https://openaccess.thecvf.com/content/WACV2023/papers/Sohn_Anomaly_Clustering_Grouping_Images_Into_Coherent_Clusters_of_Anomaly_Types_WACV_2023_paper.pdf)

<a name="39"/>

## 39.Style Transfer(风格迁移)
* [Line Search-Based Feature Transformation for Fast, Stable, and Tunable Content-Style Control in Photorealistic Style Transfer](https://arxiv.org/abs/2210.05996)<br>:star:[code](https://github.com/chiutaiyin/LS-FT)
* [RAST: Restorable Arbitrary Style Transfer via Multi-Restoration](https://openaccess.thecvf.com/content/WACV2023/papers/Ma_RAST_Restorable_Arbitrary_Style_Transfer_via_Multi-Restoration_WACV_2023_paper.pdf)

<a name="38"/>

## 38.Sound(音频处理)
* Audio Visual Event Localization视听事件定位
  * [AVE-CLIP: AudioCLIP-based Multi-window Temporal Transformer for Audio Visual Event Localization](https://arxiv.org/abs/2210.05060)
* 音频去噪
  * [BirdSoundsDenoising: Deep Visual Audio Denoising for Bird Sounds](https://arxiv.org/abs/2210.10196)
* 视听分割
  * [Unsupervised Audio-Visual Lecture Segmentation](https://arxiv.org/abs/2210.16644)<br>:house:[project](https://cvit.iiit.ac.in/research/projects/cvit-projects/avlectures)
* 生源定位
  * [Hear The Flow: Optical Flow-Based Self-Supervised Visual Sound Source Localization](https://arxiv.org/abs/2211.03019)<br>:star:[code](https://github.com/denfed/heartheflow)
* 语音识别
  * [Audio-Visual Efficient Conformer for Robust Speech Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Burchi_Audio-Visual_Efficient_Conformer_for_Robust_Speech_Recognition_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/burchim/AVEC)

<a name="37"/>

## 37.Object Tracking(目标跟踪)
* [Efficient Visual Tracking with Exemplar Transformers](https://arxiv.org/abs/2112.09686)<br>:star:[code](https://github.com/pblatter/ettrack)
* [Hard to Track Objects with Irregular Motions and Similar Appearances?Make It Easier by Buffering the Matching Space](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Hard_To_Track_Objects_With_Irregular_Motions_and_Similar_Appearances_WACV_2023_paper.pdf)
* [HOOT: Heavy Occlusions in Object Tracking Benchmark](https://openaccess.thecvf.com/content/WACV2023/papers/Sahin_HOOT_Heavy_Occlusions_in_Object_Tracking_Benchmark_WACV_2023_paper.pdf)
* [VirtualHome Action Genome: A Simulated Spatio-Temporal Scene Graph Dataset With Consistent Relationship Labels](https://openaccess.thecvf.com/content/WACV2023/papers/Qiu_VirtualHome_Action_Genome_A_Simulated_Spatio-Temporal_Scene_Graph_Dataset_With_WACV_2023_paper.pdf)
* 多目标跟踪
  * [AttTrack: Online Deep Attention Transfer for Multi-object Tracking](https://arxiv.org/abs/2210.08648)
  * [Detection Recovery in Online Multi-Object Tracking With Sparse Graph Tracker](https://openaccess.thecvf.com/content/WACV2023/papers/Hyun_Detection_Recovery_in_Online_Multi-Object_Tracking_With_Sparse_Graph_Tracker_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/HYUNJS/SGT)

<a name="36"/>

## 36.Soft Biometrics(软生物技术)
* 手指静脉识别
  * [Analysis of Master Vein Attacks on Finger Vein Recognition Systems](https://arxiv.org/abs/2210.10667)
* 隐形眼镜虹膜PAD算法的错误分类
  * [Misclassifications of Contact Lens Iris PAD Algorithms: Is it Gender Bias or Environmental Conditions](https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Misclassifications_of_Contact_Lens_Iris_PAD_Algorithms_Is_It_Gender_WACV_2023_paper.pdf)
* 生物信息识别
  * [Can Shadows Reveal Biometric Information?](https://openaccess.thecvf.com/content/WACV2023/papers/Medin_Can_Shadows_Reveal_Biometric_Information_WACV_2023_paper.pdf)

<a name="35"/>

## 35.VQA(视觉问答)
* [DRAMA: Joint Risk Localization and Captioning in Driving](https://arxiv.org/abs/2209.10767)
* [VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge](https://arxiv.org/abs/2210.13626)<br>:star:[code](https://github.com/aditya10/VLC-BERT)
* [How To Practice VQA on a Resource-Limited Target Domain](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_How_To_Practice_VQA_on_a_Resource-Limited_Target_Domain_WACV_2023_paper.pdf)<br>:house:[project](https://people.cs.pitt.edu/~mzhang/practice-vqa/)
* VideoQA
  * [Dense but Efficient VideoQA for Intricate Compositional Reasoning](https://arxiv.org/abs/2210.10300)
* 视觉问题生成
  * [K-VQG: Knowledge-Aware Visual Question Generation for Common-Sense Acquisition](https://openaccess.thecvf.com/content/WACV2023/papers/Uehara_K-VQG_Knowledge-Aware_Visual_Question_Generation_for_Common-Sense_Acquisition_WACV_2023_paper.pdf)<br>:house:[project](https://uehara-mech.github.io/kvqg)

<a name="34"/>

## 34.SLAM\Robots
* SLAM
  * [Probabilistic Volumetric Fusion for Dense Monocular SLAM](https://arxiv.org/abs/2210.01276)
* AR
  * [Heightfields for Efficient Scene Reconstruction for AR](https://openaccess.thecvf.com/content/WACV2023/papers/Watson_Heightfields_for_Efficient_Scene_Reconstruction_for_AR_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/nianticlabs/heightfields)

<a name="33"/>

## 33.View Synthesis(视图合成)
* [Vision Transformer for NeRF-Based View Synthesis From a Single Input Image](https://openaccess.thecvf.com/content/WACV2023/papers/Lin_Vision_Transformer_for_NeRF-Based_View_Synthesis_From_a_Single_Input_WACV_2023_paper.pdf)

<a name="32"/>

## 32.Continual Learning(持续学习)
* [Continual Learning with Dependency Preserving Hypernetworks](https://arxiv.org/abs/2209.07712)
* [Do Pre-trained Models Benefit Equally in Continual Learning](https://arxiv.org/abs/2210.15701)<br>:star:[code](https://github.com/eric11220/pretrained-models-in-CL)
* [Saliency Guided Experience Packing for Replay in Continual Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Saha_Saliency_Guided_Experience_Packing_for_Replay_in_Continual_Learning_WACV_2023_paper.pdf)

<a name="31"/>

## 31.Deepfake Detection(假象检测)
* [TI2Net: Temporal Identity Inconsistency Network for Deepfake Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_TI2Net_Temporal_Identity_Inconsistency_Network_for_Deepfake_Detection_WACV_2023_paper.pdf)
* 图像伪造
  * [CFL-Net: Image Forgery Localization Using Contrastive Learning](https://arxiv.org/abs/2210.02182)<br>:star:[code](https://github.com/niloy193/CFLNet)

<a name="30"/>

## 30.Reinforcement Learning(强化学习)
* [Switching to Discriminative Image Captioning by Relieving a Bottleneck of Reinforcement Learning](https://arxiv.org/abs/2212.03230)<br>:star:[code](https://github.com/ukyh/switchdisccaption)

<a name="29"/>

## 29.Image Classification(图像分类)
* [Wavelength-Aware 2D Convolutions for Hyperspectral Imaging](https://openaccess.thecvf.com/content/WACV2023/papers/Varga_Wavelength-Aware_2D_Convolutions_for_Hyperspectral_Imaging_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/cogsys-tuebingen/hyve_conv)
* [ML-Decoder: Scalable and Versatile Classification Head](https://openaccess.thecvf.com/content/WACV2023/papers/Ridnik_ML-Decoder_Scalable_and_Versatile_Classification_Head_WACV_2023_paper.pdf)
* [CNN2Graph: Building Graphs for Image Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Trivedy_CNN2Graph_Building_Graphs_for_Image_Classification_WACV_2023_paper.pdf)
* 长尾识别
  * [Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition](https://arxiv.org/abs/2209.02960)
* pen-Set Classification
  * [Large-Scale Open-Set Classification Protocols for ImageNet](https://arxiv.org/abs/2210.06789)
* 细粒度分类
  * [SSFE-Net: Self-Supervised Feature Enhancement for Ultra-Fine-Grained Few-Shot Class Incremental Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Pan_SSFE-Net_Self-Supervised_Feature_Enhancement_for_Ultra-Fine-Grained_Few-Shot_Class_Incremental_Learning_WACV_2023_paper.pdf)
* 多标签分类
  * [Spatial Consistency Loss for Training Multi-Label Classifiers From Single-Label Annotations](https://openaccess.thecvf.com/content/WACV2023/papers/Verelst_Spatial_Consistency_Loss_for_Training_Multi-Label_Classifiers_From_Single-Label_Annotations_WACV_2023_paper.pdf)
* 小样本分类
  * [Contrastive Knowledge-Augmented Meta-Learning for Few-Shot Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Subramanyam_Contrastive_Knowledge-Augmented_Meta-Learning_for_Few-Shot_Classification_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Rakshith-2905/CAML) 
 
<a name="28"/>

## 28.Pose Estimation(姿态估计)
* 6D
  * [CRT-6D: Fast 6D Object Pose Estimation with Cascaded Refinement Transformers](https://arxiv.org/abs/2210.11718)<br>:star:[code](https://github.com/PedroCastro/CRT-6D)
  * [SD-Pose: Structural Discrepancy Aware Category-Level 6D Object Pose Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Li_SD-Pose_Structural_Discrepancy_Aware_Category-Level_6D_Object_Pose_Estimation_WACV_2023_paper.pdf)

<a name="27"/>

## 27.Defect Detection(缺陷检测)

<a name="26"/>

## 26.Dataset\Benchmark(数据集\基准)
* [OpenEarthMap: A Benchmark Dataset for Global High-Resolution Land Cover Mapping](https://arxiv.org/abs/2210.10732)<br>:sunflower:[dataset](https://open-earth-map.org/)
* [IDD-3D: A Dataset for Driving in Unstructured Road Scenes](https://arxiv.org/abs/2210.12878)<br>:sunflower:[dataset](https://github.com/shubham1810/idd3d_kit)
* 目标检测、分割、跟踪
  * [BURST: A Benchmark for Unifying Object Recognition, Segmentation and Tracking in Video](https://openaccess.thecvf.com/content/WACV2023/papers/Athar_BURST_A_Benchmark_for_Unifying_Object_Recognition_Segmentation_and_Tracking_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Ali2500/BURST-benchmark)

<a name="25"/>

## 25.Image Captioning(图像字幕)
* 人体图像分析
  * [Split To Learn: Gradient Split for Multi-Task Human Image Analysis](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Split_To_Learn_Gradient_Split_for_Multi-Task_Human_Image_Analysis_WACV_2023_paper.pdf)
* 图像字幕
  * [Expert-defined Keywords Improve Interpretability of Retinal Image Captioning](https://openaccess.thecvf.com/content/WACV2023/papers/Wu_Expert-Defined_Keywords_Improve_Interpretability_of_Retinal_Image_Captioning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Jhhuangkay/Expert-defined-Keywords-Improve-Interpretability-of-Retinal-Image-Captioning)
* 视频字幕
  * [Lightweight Video Denoising Using Aggregated Shifted Window Attention](https://openaccess.thecvf.com/content/WACV2023/papers/Lindner_Lightweight_Video_Denoising_Using_Aggregated_Shifted_Window_Attention_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/LLindn/ASwin-Video-Denoising)

<a name="24"/>

## 24.Image Retrieval(图像检索)
* [Boosting vision transformers for image retrieval](https://arxiv.org/abs/2210.11909)<br>:star:[code](https://github.com/dealicious-inc/DToP)
* [Certified Defense for Content Based Image Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Kakizaki_Certified_Defense_for_Content_Based_Image_Retrieval_WACV_2023_paper.pdf)
* [Fashion Image Retrieval with Text Feedback by Additive Attention Compositional Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Tian_Fashion_Image_Retrieval_With_Text_Feedback_by_Additive_Attention_Compositional_WACV_2023_paper.pdf)
* 图像-句子检索
  * [Cross-modal Semantic Enhanced Interaction for Image-Sentence Retrieval](https://arxiv.org/abs/2210.08908)
* 图像-文本检索
  * [Dissecting Deep Metric Learning Losses for Image-Text Retrieval](https://arxiv.org/abs/2210.13188)<br>:star:[code](https://github.com/littleredxh/VSE-Gradient)

<a name="23"/>

## 23.Autonomous Driving(智能驾驶)
* [IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes](https://arxiv.org/abs/2210.12878)<br>:star:[code](https://github.com/shubham1810/idd3d_kit)
* [PP4AV: A Benchmarking Dataset for Privacy-Preserving Autonomous Driving](https://openaccess.thecvf.com/content/WACV2023/papers/Trinh_PP4AV_A_Benchmarking_Dataset_for_Privacy-Preserving_Autonomous_Driving_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/khaclinh/pp4av)

<a name="22"/>

## 22.Human Action Recognition(人体动作识别与检测)
* 动作识别
  * [Modality Mixer for Multi-modal Action Recognition](https://arxiv.org/abs/2208.11314)
  * [STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition](https://arxiv.org/abs/2210.07503)
  * [Holistic Interaction Transformer Network for Action Detection](https://arxiv.org/abs/2210.12686)<br>:star:[code](https://github.com/joslefaure/HIT)
  * [Reconstructing Humpty Dumpty: Multi-feature Graph Autoencoder for Open Set Action Recognition](https://arxiv.org/abs/2212.06023)<br>:star:[code](https://github.com/Kitware/graphautoencoder)
  * [DA-AIM: Exploiting Instance-based Mixed Sampling via Auxiliary Source Domain Supervision for Domain-adaptive Action Detection](https://arxiv.org/pdf/2209.15439.pdf)<br>:star:[code](https://github.com/wwwfan628/DA-AIM)
  * [Spatio-Temporal Action Detection Under Large Motion](https://arxiv.org/pdf/2209.02250.pdf)<br>:star:[code](https://github.com/gurkirt/ActionTrackDetectron)
  * [Efficient Skeleton-Based Action Recognition via Joint-Mapping Strategies](https://openaccess.thecvf.com/content/WACV2023/papers/Kang_Efficient_Skeleton-Based_Action_Recognition_via_Joint-Mapping_Strategies_WACV_2023_paper.pdf)
  * [Recur, Attend or Convolve? On Whether Temporal Modeling Matters for Cross-Domain Robustness in Action Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Broome_Recur_Attend_or_Convolve_On_Whether_Temporal_Modeling_Matters_for_WACV_2023_paper.pdf)
  * [Semantics Guided Contrastive Learning of Transformers for Zero-Shot Temporal Activity Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Nag_Semantics_Guided_Contrastive_Learning_of_Transformers_for_Zero-Shot_Temporal_Activity_WACV_2023_paper.pdf)
  * [Adaptive Local-Component-Aware Graph Convolutional Network for One-Shot Skeleton-Based Action Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Zhu_Adaptive_Local-Component-Aware_Graph_Convolutional_Network_for_One-Shot_Skeleton-Based_Action_Recognition_WACV_2023_paper.pdf)
  * [Multi-View Action Recognition using Contrastive Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Shah_Multi-View_Action_Recognition_Using_Contrastive_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/kshah33/ViewCon)
* 时序动作定位
  * [Temporal Feature Enhancement Dilated Convolution Network for Weakly-Supervised Temporal Action Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Zhou_Temporal_Feature_Enhancement_Dilated_Convolution_Network_for_Weakly-Supervised_Temporal_Action_WACV_2023_paper.pdf)

<a name="21"/>

## 21.Point Cloud(点云)
* [PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning of Point Clouds](https://arxiv.org/abs/2210.08305)
* [Visualizing Global Explanations of Point Cloud DNNs](https://openaccess.thecvf.com/content/WACV2023/papers/Tan_Visualizing_Global_Explanations_of_Point_Cloud_DNNs_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Explain3D/PointCloudAM)
* [RSF: Optimizing Rigid Scene Flow From 3D Point Clouds Without Labels](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_RSF_Optimizing_Rigid_Scene_Flow_From_3D_Point_Clouds_Without_WACV_2023_paper.pdf)
* [Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Nearest_Neighbors_Meet_Deep_Neural_Networks_for_Point_Cloud_Analysis_WACV_2023_paper.pdf)
* 点云配准
  * [Overlap-guided Gaussian Mixture Models for Point Cloud Registration](https://arxiv.org/abs/2210.09836)<br>:star:[code](https://github.com/gfmei/ogmm)
  * [SGPCR: Spherical Gaussian Point Cloud Representation and its Application to Object Registration and Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Salihu_SGPCR_Spherical_Gaussian_Point_Cloud_Representation_and_Its_Application_To_WACV_2023_paper.pdf)
* 点云重建
  * [PointInverter: Point Cloud Reconstruction and Editing via a Generative Model with Shape Priors](https://arxiv.org/abs/2211.08702)<br>:star:[code](https://github.com/hkust-vgd/point_inverter)
* 3D点云
  * [PIDS: Joint Point Interaction-Dimension Search for 3D Point Cloud](https://arxiv.org/abs/2211.15759)

<a name="20"/>

## 20.Transformer
* [EmbryosFormer: Deformable Transformer and Collaborative Encoding-Decoding for Embryos Stage Development Classification](https://arxiv.org/abs/2210.04615)<br>:star:[code](https://github.com/UARK-AICV/Embryos)
* [Delving into Masked Autoencoders for Multi-Label Thorax Disease Classification](https://arxiv.org/abs/2210.12843)<br>:star:[code](https://github.com/lambert-x/Medical_MAE)
* [Accumulated Trivial Attention Matters in Vision Transformers on Small Datasets](https://arxiv.org/abs/2210.12333)<br>:star:[code](https://github.com/xiangyu8/SATA)
* [Couplformer: Rethinking Vision Transformer With Coupling Attention](https://openaccess.thecvf.com/content/WACV2023/papers/Lan_Couplformer_Rethinking_Vision_Transformer_With_Coupling_Attention_WACV_2023_paper.pdf)
* [Trans4Map: Revisiting Holistic Bird's-Eye-View Mapping From Egocentric Images to Allocentric Semantics With Vision Transformers](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Trans4Map_Revisiting_Holistic_Birds-Eye-View_Mapping_From_Egocentric_Images_to_Allocentric_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/jamycheung/Trans4Map)
* [PatchDropout: Economizing Vision Transformers Using Patch Dropout](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_PatchDropout_Economizing_Vision_Transformers_Using_Patch_Dropout_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/yueliukth/PatchDropout)
* [Discrete Cosin TransFormer: Image Modeling From Frequency Domain](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Discrete_Cosin_TransFormer_Image_Modeling_From_Frequency_Domain_WACV_2023_paper.pdf)

<a name="19"/>

## 19.Model Compression\Knowledge Distillation\Pruning(模型压缩\知识蒸馏\剪枝)
* 剪枝
  * [Pushing the Efficiency Limit Using Structured Sparse Convolutions](https://arxiv.org/abs/2210.12818)<br>:star:[code](https://github.com/vkvermaa/SSC)
  * [Calibrating Deep Neural Networks using Explicit Regularisation and Dynamic Data Pruning](https://arxiv.org/abs/2212.10005)
* 知识蒸馏
  * [Collaborative Multi-Teacher Knowledge Distillation for Learning Low Bit-width Deep Neural Networks](https://arxiv.org/abs/2210.16103)
  * [Understanding the Role of Mixup in Knowledge Distillation: \\An Empirical Study](https://arxiv.org/abs/2211.03946)<br>:star:[code](https://github.com/hchoi71/MIX-KD)
* 自我蒸馏
  * [SSSD: Self-Supervised Self Distillation](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_SSSD_Self-Supervised_Self_Distillation_WACV_2023_paper.pdf)

<a name="18"/>

## 18.NAS(神经架构搜索)
* [Revisiting Training-free NAS Metrics: An Efficient Training-based Method](https://arxiv.org/abs/2211.08666)<br>:star:[code](https://github.com/taoyang1122/Revisit_TrainingFree_NAS)
* [SVD-NAS: Coupling Low-Rank Approximation and Neural Architecture Search](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_SVD-NAS_Coupling_Low-Rank_Approximation_and_Neural_Architecture_Search_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Yu-Zhewen/SVD-NAS)

<a name="17"/>

## 17.OCR(文本检测)
* [OCR-VQGAN: Taming Text-within-Image Generation](https://arxiv.org/abs/2210.11248)<br>:star:[code](https://github.com/joanrod/ocr-vqgan)
* [Efficient few-shot learning for pixel-precise handwritten document layout analysis](https://arxiv.org/abs/2210.15570)
* 文本识别
  * [Seq-UPS: Sequential Uncertainty-aware Pseudo-label Selection for Semi-Supervised Text Recognition](https://arxiv.org/abs/2209.00641)
* 表格检测
  * [LayerDoc: Layer-Wise Extraction of Spatial Hierarchical Structure in Visually-Rich Documents](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_LayerDoc_Layer-Wise_Extraction_of_Spatial_Hierarchical_Structure_in_Visually-Rich_Documents_WACV_2023_paper.pdf)
  
<a name="16"/>

## 16.Super-Resolution(超分辨率)
* [Single Image Super-Resolution via a Dual Interactive Implicit Neural Network](https://arxiv.org/abs/2210.12593)
* [HIME: Efficient Headshot Image Super-Resolution with Multiple Exemplars](https://arxiv.org/abs/2203.14863)
* [Deep Model-Based Super-Resolution With Non-Uniform Blur](https://openaccess.thecvf.com/content/WACV2023/papers/Laroche_Deep_Model-Based_Super-Resolution_With_Non-Uniform_Blur_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/claroche-r/DMBSR)
* [Kernel-Aware Burst Blind Super-Resolution](https://openaccess.thecvf.com/content/WACV2023/papers/Lian_Kernel-Aware_Burst_Blind_Super-Resolution_WACV_2023_paper.pdf)
* 视频超分辨率
  * [Cross-Resolution Flow Propagation for Foveated Video Super-Resolution](https://arxiv.org/abs/2212.13525)<br>:star:[code](https://github.com/eugenelet/CRFP)
  * [Fast Online Video Super-Resolution With Deformable Attention Pyramid](https://openaccess.thecvf.com/content/WACV2023/papers/Fuoli_Fast_Online_Video_Super-Resolution_With_Deformable_Attention_Pyramid_WACV_2023_paper.pdf)

<a name="15"/>

## 15.Image Synthesis(图像合成)
* [One-Shot Synthesis of Images and Segmentation Masks](https://arxiv.org/abs/2209.07547)<br>:star:[code](https://github.com/boschresearch/one-shot-synthesis)
* [Style-Guided Inference of Transformer for High-resolution Image Synthesis](https://arxiv.org/abs/2210.05533)
* [Evaluating Generative Networks Using Gaussian Mixtures of Image Features](https://openaccess.thecvf.com/content/WACV2023/papers/Luzi_Evaluating_Generative_Networks_Using_Gaussian_Mixtures_of_Image_Features_WACV_2023_paper.pdf)
* 图像生成
  * [Adaptively-Realistic Image Generation from Stroke and Sketch with Diffusion Model](https://arxiv.org/abs/2208.12675)<br>:star:[code](https://github.com/cyj407/DiSS):house:[project](https://cyj407.github.io/DiSS/)
  * [Spatially Multi-Conditional Image Generation](https://openaccess.thecvf.com/content/WACV2023/papers/Popovic_Spatially_Multi-Conditional_Image_Generation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/96ritika/TLAM)
* 文本-图像合成
  * [Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation](https://arxiv.org/abs/2211.07751)<br>:star:[code](https://github.com/openai/glide-text2im)
* 文字引导的图像操作
  * [Interactive Image Manipulation with Complex Text Instructions](https://arxiv.org/abs/2211.15352) 
 
<a name="14"/>

## 14.Un\Self\Semi-Supervised Learning(无\自\半监督学习)
* 自监督
  * [Self-Supervised Pyramid Representation Learning for Multi-Label Visual Analysis and Beyond](https://arxiv.org/abs/2208.14439)<br>:star:[code](https://github.com/WesleyHsieh0806/SS-PRL)
  * [FUSSL: Fuzzy Uncertain Self Supervised Learning](https://arxiv.org/abs/2210.15818)
  * [Self-Supervised Correspondence Estimation via Multiview Registration](https://arxiv.org/abs/2212.03236)<br>:house:[project](https://mbanani.github.io/syncmatch/)
  * [Similarity Contrastive Estimation for Image and Video Soft Contrastive Self-Supervised Learning](https://arxiv.org/abs/2212.11187)
  * [Self-Supervised Relative Pose With Homography Model-Fitting in the Loop](https://openaccess.thecvf.com/content/WACV2023/papers/Muller_Self-Supervised_Relative_Pose_With_Homography_Model-Fitting_in_the_Loop_WACV_2023_paper.pdf)
  * [Self-Distilled Self-supervised Representation Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Jang_Self-Distilled_Self-Supervised_Representation_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/hagiss/SDSSL)
  * [Multi-Level Contrastive Learning for Self-Supervised Vision Transformers](https://openaccess.thecvf.com/content/WACV2023/papers/Mo_Multi-Level_Contrastive_Learning_for_Self-Supervised_Vision_Transformers_WACV_2023_paper.pdf)
* 半监督
  * [Class-Level Confidence Based 3D Semi-Supervised Learning](https://arxiv.org/abs/2210.10138)
  * [Dynamic Re-Weighting for Long-Tailed Semi-Supervised Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Peng_Dynamic_Re-Weighting_for_Long-Tailed_Semi-Supervised_Learning_WACV_2023_paper.pdf)

<a name="13"/>

## 13.Image Segmentation(图像分割)
* [Image Segmentation-based Unsupervised Multiple Objects Discovery](https://arxiv.org/abs/2212.10124)
* VOS
  * [Unsupervised Video Object Segmentation via Prototype Memory Network](https://arxiv.org/abs/2209.03712)
* VSS
  * [Domain Adaptive Video Semantic Segmentation via Cross-Domain Moving Object Mixing](https://arxiv.org/abs/2211.02307)
* 语义分割
  * [Attribution-aware Weight Transfer: A Warm-Start Initialization for Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2210.07207)<br>:star:[code](https://github.com/dfki-av/AWT-for-CISS)
  * [Full Contextual Attention for Multi-resolution Transformers in Semantic Segmentation](https://arxiv.org/abs/2212.07890)
  * [Urban Scene Semantic Segmentation with Low-Cost Coarse Annotation](https://arxiv.org/abs/2212.07911)
  * [LoopDA: Constructing Self-loops to Adapt Nighttime Semantic Segmentation](https://arxiv.org/abs/2211.11870)<br>:star:[code](https://github.com/fy-vision/LoopDA)
  * [Empirical Generalization Study: Unsupervised Domain Adaptation vs. Domain Generalization Methods for Semantic Segmentation in the Wild](https://openaccess.thecvf.com/content/WACV2023/papers/Piva_Empirical_Generalization_Study_Unsupervised_Domain_Adaptation_vs._Domain_Generalization_Methods_WACV_2023_paper.pdf)
  * [Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions](https://openaccess.thecvf.com/content/WACV2023/papers/Bruggemann_Refign_Align_and_Refine_for_Adaptation_of_Semantic_Segmentation_to_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/brdav/refign)
  * [BEVSegFormer: Bird's Eye View Semantic Segmentation From Arbitrary Camera Rigs](https://openaccess.thecvf.com/content/WACV2023/papers/Peng_BEVSegFormer_Birds_Eye_View_Semantic_Segmentation_From_Arbitrary_Camera_Rigs_WACV_2023_paper.pdf)
  * 半监督语义分割
    * [Pruning-Guided Curriculum Learning for Semi-Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Kong_Pruning-Guided_Curriculum_Learning_for_Semi-Supervised_Semantic_Segmentation_WACV_2023_paper.pdf)
  * Multi-class part parsing
    * [AFPSNet: Multi-Class Part Parsing Based on Scaled Attention and Feature Fusion](https://openaccess.thecvf.com/content/WACV2023/papers/Alsudays_AFPSNet_Multi-Class_Part_Parsing_Based_on_Scaled_Attention_and_Feature_WACV_2023_paper.pdf)
* BEV segmentation
  * [X-Align: Cross-Modal Cross-View Alignment for Bird's-Eye-View Segmentation](https://arxiv.org/abs/2210.06778)<br>:star:[code](https://github.com/robot-learning-freiburg/PanopticBEV)
* 全景分割
  * [MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to Depth-aware Video Panoptic Segmentation](https://arxiv.org/abs/2210.07577)
  * [PRN: Panoptic Refinement Network](https://openaccess.thecvf.com/content/WACV2023/papers/Sun_PRN_Panoptic_Refinement_Network_WACV_2023_paper.pdf)
* 实例分割
  * [From Forks to Forceps: A New Framework for Instance Segmentation of Surgical Instruments](https://arxiv.org/abs/2211.16200)
  * [CellTranspose: Few-shot Domain Adaptation for Cellular Instance Segmentation](https://arxiv.org/abs/2212.14121)
  * [Weakly Supervised Cell-Instance Segmentation With Two Types of Weak Labels by Single Instance Pasting](https://openaccess.thecvf.com/content/WACV2023/papers/Nishimura_Weakly_Supervised_Cell-Instance_Segmentation_With_Two_Types_of_Weak_Labels_WACV_2023_paper.pdf)
  * [Self-Supervised Learning With Masked Image Modeling for Teeth Numbering, Detection of Dental Restorations, and Instance Segmentation in Dental Panoramic Radiographs](https://openaccess.thecvf.com/content/WACV2023/papers/Almalki_Self-Supervised_Learning_With_Masked_Image_Modeling_for_Teeth_Numbering_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/AmaniHAlmalki/DentalMIM)
  * [Weakly-Supervised Point Cloud Instance Segmentation With Geometric Priors](https://openaccess.thecvf.com/content/WACV2023/papers/Du_Weakly-Supervised_Point_Cloud_Instance_Segmentation_With_Geometric_Priors_WACV_2023_paper.pdf)
* 小样本分割
  * [Elimination of Non-Novel Segments at Multi-Scale for Few-Shot Segmentation](https://arxiv.org/abs/2211.02300)
* 叶子疾病分割
  * [AnoLeaf: Unsupervised Leaf Disease Segmentation via Structurally Robust Generative Inpainting](https://openaccess.thecvf.com/content/WACV2023/papers/Bhugra_AnoLeaf_Unsupervised_Leaf_Disease_Segmentation_via_Structurally_Robust_Generative_Inpainting_WACV_2023_paper.pdf)
* 细胞分割
  * [Knowing What to Label for Few Shot Microscopy Image Cell Segmentation](https://arxiv.org/abs/2211.10244)<br>:star:[code](https://github.com/Yussef93/KnowWhatToLabel/)
* 目标分割
  * [Unsupervised 4D LiDAR Moving Object Segmentation in Stationary Settings with Multivariate Occupancy Time Series](https://arxiv.org/abs/2212.14750)
* 抠图
  * [Video Object Matting via Hierarchical Space-Time Semantic Guidance](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_Video_Object_Matting_via_Hierarchical_Space-Time_Semantic_Guidance_WACV_2023_paper.pdf)

<a name="12"/>

## 12.One\Few-Shot Learning or Domain Adaptation\Generalization\Shift(单\小样本学习 or 域适应\泛化\偏移)
* 域适应
  * [Reducing Annotation Effort by Identifying and Labeling Contextually Diverse Classes for Semantic Segmentation Under Domain Shift](https://arxiv.org/abs/2210.06749)<br>:star:[code](https://github.com/sharat29ag/contextual_class)
  * [Self-Distillation for Unsupervised 3D Domain Adaptation](https://arxiv.org/abs/2210.08226)<br>:house:[project](https://cvlab-unibo.github.io/FeatureDistillation/)
  * [CoNMix for Source-free Single and Multi-target Domain Adaptation](https://arxiv.org/abs/2211.03876)<br>:star:[code](https://github.com/vcl-iisc/CoNMix):house:[project](https://sites.google.com/view/conmix-vcl)
  * [Learning Classifiers of Prototypes and Reciprocal Points for Universal Domain Adaptation](https://arxiv.org/abs/2212.08355)
  * [Select, Label, and Mix: Learning Discriminative Invariant Feature Representations for Partial Domain Adaptation](https://openaccess.thecvf.com/content/WACV2023/papers/Sahoo_Select_Label_and_Mix_Learning_Discriminative_Invariant_Feature_Representations_for_WACV_2023_paper.pdf)<br>:house:[project](https://cvir.github.io/projects/slm)
  * [TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_TVT_Transferable_Vision_Transformer_for_Unsupervised_Domain_Adaptation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/uta-smile/TVT)
* 域泛化
  * [Intra-Source Style Augmentation for Improved Domain Generalization](https://arxiv.org/abs/2210.10175)
  * [Center-aware Adversarial Augmentation for Single Domain Generalization](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Center-Aware_Adversarial_Augmentation_for_Single_Domain_Generalization_WACV_2023_paper.pdf)
* 零样本
  * [Learning Attention Propagation for Compositional Zero-Shot Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Khan_Learning_Attention_Propagation_for_Compositional_Zero-Shot_Learning_WACV_2023_paper.pdf)
* 小样本
  * [Aggregating Bilateral Attention for Few-Shot Instance Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Hsieh_Aggregating_Bilateral_Attention_for_Few-Shot_Instance_Localization_WACV_2023_paper.pdf)

<a name="11"/>

## 11.Face(人脸)
* [My Face My Choice: Privacy Enhancing Deepfakes for Social Media Anonymization](https://arxiv.org/abs/2211.01361)
* 读唇术
  * [Towards MOOCs for Lip Reading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale](https://arxiv.org/abs/2208.09796)
* 3D人脸
  * [Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance](https://openaccess.thecvf.com/content/WACV2023/papers/Taherkhani_Controllable_3D_Generative_Adversarial_Face_Model_via_Disentangling_Shape_and_WACV_2023_paper.pdf)<br>:house:[project](https://aashishrai3799.github.io/3DFaceCAM/)
* 人脸识别
  * [DigiFace-1M: 1 Million Digital Face Images for Face Recognition](https://arxiv.org/abs/2210.02579)<br>:star:[code](https://github.com/microsoft/DigiFace1M)
  * [CAST: Conditional Attribute Subsampling Toolkit for Fine-Grained Evaluation](https://openaccess.thecvf.com/content/WACV2023/papers/Robbins_CAST_Conditional_Attribute_Subsampling_Toolkit_for_Fine-Grained_Evaluation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/WesRobbins/CAST)
  * [Harnessing Unrecognizable Faces for Improving Face Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Harnessing_Unrecognizable_Faces_for_Improving_Face_Recognition_WACV_2023_paper.pdf)
* 人脸修复/恢复
  * [Nested Deformable Multi-head Attention for Facial Image Inpainting](https://openaccess.thecvf.com/content/WACV2023/papers/Phutke_Nested_Deformable_Multi-Head_Attention_for_Facial_Image_Inpainting_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/shrutiphutke/NDMA_Facial_Inpainting)
  * [AT-DDPM: Restoring Faces degraded by Atmospheric Turbulence using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2208.11284)
* 人脸交换
  * [FaceOff: A Video-to-Video Face Swapping System](https://arxiv.org/abs/2208.09788)
  * [FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping](https://openaccess.thecvf.com/content/WACV2023/papers/Rosberg_FaceDancer_Pose-_and_Occlusion-Aware_High_Fidelity_Face_Swapping_WACV_2023_paper.pdf)
* 人脸表情识别
  * [Uncertainty-aware Label Distribution Learning for Facial Expression Recognition](https://arxiv.org/abs/2209.10448)<br>:star:[code](https://github.com/minhnhatvt/label-distribution-learning-fer-tf)
  * 微表情识别
    * [RNAS-MER: A Refined Neural Architecture Search With Hybrid Spatiotemporal Operations for Micro-Expression Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Verma_RNAS-MER_A_Refined_Neural_Architecture_Search_With_Hybrid_Spatiotemporal_Operations_WACV_2023_paper.pdf)
* 人脸重现
  * [Audio-Visual Face Reenactment](https://arxiv.org/abs/2210.02755)<br>:house:[project](http://cvit.iiit.ac.in/research/projects/cvit-projects/avfr)
* 人脸命名
  * [Weakly Supervised Face Naming with Symmetry-Enhanced Contrastive Loss](https://arxiv.org/abs/2210.08957)
* 人脸重建
  * [ReEnFP: Detail-Preserving Face Reconstruction by Encoding Facial Priors](https://openaccess.thecvf.com/content/WACV2023/papers/Sun_ReEnFP_Detail-Preserving_Face_Reconstruction_by_Encoding_Facial_Priors_WACV_2023_paper.pdf)
* Facial Action Unit Detection
  * [FAN-Trans: Online Knowledge Distillation for Facial Action Unit Detection](https://arxiv.org/abs/2211.06143) 
* 人脸质量评估
  * [IFQA: Interpretable Face Quality Assessment](https://arxiv.org/abs/2211.07077)<br>:star:[code](https://github.com/VCLLab/IFQA) 
* 活体检测
* [Domain Invariant Vision Transformer Learning for Face Anti-Spoofing](https://openaccess.thecvf.com/content/WACV2023/papers/Liao_Domain_Invariant_Vision_Transformer_Learning_for_Face_Anti-Spoofing_WACV_2023_paper.pdf)
* 基于表情的脸部皱纹合成
  * [Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces](https://arxiv.org/abs/2210.03529)
* 文字和图像引导的3D头像生成
  * [Text and Image Guided 3D Avatar Generation and Manipulation](https://openaccess.thecvf.com/content/WACV2023/papers/Canfes_Text_and_Image_Guided_3D_Avatar_Generation_and_Manipulation_WACV_2023_paper.pdf) 
 
 
<a name="10"/>

## 10.Adversarial Learning(对抗学习)
* [Leveraging Local Patch Differences in Multi-Object Scenes for Generative Adversarial Attacks](https://arxiv.org/abs/2209.09883)
* [Inducing Data Amplification Using Auxiliary Datasets in Adversarial Training](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_Inducing_Data_Amplification_Using_Auxiliary_Datasets_in_Adversarial_Training_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Saehyung-Lee/BiaMAT)
* [FLOAT: Fast Learnable Once-for-All Adversarial Training for Tunable Trade-off between Accuracy and Robustness](https://openaccess.thecvf.com/content/WACV2023/papers/Kundu_FLOAT_Fast_Learnable_Once-for-All_Adversarial_Training_for_Tunable_Trade-Off_Between_WACV_2023_paper.pdf)

<a name="9"/>

## 9.Remote Sensing\Satellite Image(遥感\卫星图像)
* RS
  * [Handling Image and Label Resolution Mismatch in Remote Sensing](https://arxiv.org/abs/2211.15790)
  * [GAF-Net: Improving the Performance of Remote Sensing Image Fusion Using Novel Global Self and Cross Attention Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Jha_GAF-Net_Improving_the_Performance_of_Remote_Sensing_Image_Fusion_Using_WACV_2023_paper.pdf)
* 变化检测
  * [Self-Pair: Synthesizing Changes from Single Source for Object Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2212.10236)<br>:star:[code](https://github.com/seominseok0429/Self-Pair-for-Change-Detection)
* 航空图像检测
  * [ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Sairam_ARUBA_An_Architecture-Agnostic_Balanced_Loss_for_Aerial_Object_Detection_WACV_2023_paper.pdf)

<a name="8"/>

## 8.Image Processing(图像处理)
* 图像恢复
  * [Large-to-small Image Resolution Asymmetry in Deep Metric Learning](https://arxiv.org/abs/2210.05463)<br>:star:[code](https://github.com/pavelsuma/raml)
  * [DSTrans: Dual-Stream Transformer for Hyperspectral Image Restoration](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_DSTrans_Dual-Stream_Transformer_for_Hyperspectral_Image_Restoration_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/yudadabing/Dual-Stream-Transformer-for-Hyperspectral-Image-Restoration)
  * [Semi-Supervised Learning for Low-light Image Restoration through Quality Assisted Pseudo-Labeling](https://openaccess.thecvf.com/content/WACV2023/papers/Malik_Semi-Supervised_Learning_for_Low-Light_Image_Restoration_Through_Quality_Assisted_Pseudo-Labeling_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/sameerIISc/SSL-LLR)
* 图像修复
  * [GeoFill: Reference-Based Image Inpainting With Better Geometric Understanding](https://openaccess.thecvf.com/content/WACV2023/papers/Zhao_GeoFill_Reference-Based_Image_Inpainting_With_Better_Geometric_Understanding_WACV_2023_paper.pdf)
* 图像增强
  * [Perceptual Image Enhancement for Smartphone Real-Time Applications](https://arxiv.org/abs/2210.13552)<br>:star:[code](https://github.com/mv-lab/AISP)
  * [Robust Real-World Image Enhancement Based on Multi-Exposure LDR Images](https://openaccess.thecvf.com/content/WACV2023/papers/Ren_Robust_Real-World_Image_Enhancement_Based_on_Multi-Exposure_LDR_Images_WACV_2023_paper.pdf)
  * [End-to-End Single-Frame Image Signal Processing for High Dynamic Range Scenes](https://openaccess.thecvf.com/content/WACV2023/papers/Dinh_End-to-End_Single-Frame_Image_Signal_Processing_for_High_Dynamic_Range_Scenes_WACV_2023_paper.pdf)
* 图像着色
  * [Guiding Users to Where to Give Color Hints for Efficient Interactive Sketch Colorization via Unsupervised Region Prioritization](https://arxiv.org/abs/2210.14270)
  * [Generative Colorization of Structured Mobile Web Pages](https://arxiv.org/abs/2212.11541)<br>:star:[code](https://github.com/CyberAgentAILab/webcolor)
* 图像重新缩放
  * [Effective Invertible Arbitrary Image Rescaling](https://openaccess.thecvf.com/content/WACV2023/papers/Pan_Effective_Invertible_Arbitrary_Image_Rescaling_WACV_2023_paper.pdf)
* HDR重构
  * [Single-Image HDR Reconstruction by Multi-Exposure Generation](https://arxiv.org/abs/2210.15897)<br>:star:[code](https://github.com/VinAIResearch/single_image_hdr)
* 去噪
  * [On the Importance of Denoising When Learning To Compress Images](https://openaccess.thecvf.com/content/WACV2023/papers/Brummer_On_the_Importance_of_Denoising_When_Learning_To_Compress_Images_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/trougnouf/compression) 
  * [Self Supervised Low Dose Computed Tomography Image Denoising Using Invertible Network Exploiting Inter Slice Congruence](https://openaccess.thecvf.com/content/WACV2023/papers/Bera_Self_Supervised_Low_Dose_Computed_Tomography_Image_Denoising_Using_Invertible_WACV_2023_paper.pdf) 
* 去雾
  * [Aerial Image Dehazing With Attentive Deformable Transformers](https://openaccess.thecvf.com/content/WACV2023/papers/Kulkarni_Aerial_Image_Dehazing_With_Attentive_Deformable_Transformers_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/AshutoshKulkarni4998/AIDTransformer)
 * 阴影消除
   * [Fine-Context Shadow Detection Using Shadow Removal](https://openaccess.thecvf.com/content/WACV2023/papers/Valanarasu_Fine-Context_Shadow_Detection_Using_Shadow_Removal_WACV_2023_paper.pdf)  
   
<a name="7"/>

## 7.Human Pose(人体姿态)
* [Kinematic-aware Hierarchical Attention Network for Human Pose Estimation in Videos](https://arxiv.org/abs/2211.15868)<br>:star:[code](https://github.com/KyungMinJin/HANet)
* [HuPR: A Benchmark for Human Pose Estimation Using Millimeter Wave Radar](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_HuPR_A_Benchmark_for_Human_Pose_Estimation_Using_Millimeter_Wave_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/robert80203/HuPR-A-Benchmark-for-Human-Pose-Estimation-Using-Millimeter-Wave-Radar)
* 多人姿态估计
  * [SoMoFormer: Multi-Person Pose Forecasting with Transformers](https://arxiv.org/abs/2208.14023)<br>:house:[project](https://somof.stanford.edu/result/217/)
* 三维人体
  * [Placing Human Animations into 3D Scenes by Learning Interaction- and Geometry-Driven Keyframes](https://arxiv.org/abs/2209.06314)
  * [Uplift and Upsample: Efficient 3D Human Pose Estimation with Uplifting Transformers](https://arxiv.org/abs/2210.06110)<br>:star:[code](https://github.com/goldbricklemon/uplift-upsample-3dhpe)
  * [Learning 3D Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge Between Skeleton Formats](https://arxiv.org/abs/2212.14474)<br>:house:[project](https://vision.rwth-aachen.de/wacv23sarandi)
  * [GarSim: Particle Based Neural Garment Simulator](https://openaccess.thecvf.com/content/WACV2023/papers/Tiwari_GarSim_Particle_Based_Neural_Garment_Simulator_WACV_2023_paper.pdf)
* 手部姿势
  * 3D手
    * [Marker-Removal Networks To Collect Precise 3D Hand Data for RGB-Based Estimation and Its Application in Piano](https://openaccess.thecvf.com/content/WACV2023/papers/Wu_Marker-Removal_Networks_To_Collect_Precise_3D_Hand_Data_for_RGB-Based_WACV_2023_paper.pdf)
    * [HandGCNFormer: A Novel Topology-Aware Transformer Network for 3D Hand Pose Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_HandGCNFormer_A_Novel_Topology-Aware_Transformer_Network_for_3D_Hand_Pose_WACV_2023_paper.pdf)
  * 手部重建
    * [THOR-Net: End-to-end Graformer-based Realistic Two Hands and Object Reconstruction with Self-supervision](https://arxiv.org/abs/2210.13853)<br>:star:[code](https://github.com/ATAboukhadra/THOR-Net)
  * 手-物体姿势估计
    * [Interacting Hand-Object Pose Estimation via Dense Mutual Attention](https://arxiv.org/abs/2211.08805)<br>:star:[code](https://github.com/rongakowang/DenseMutualAttention)

<a name="6"/>

## 6.Video(视频相关)
* 视频增强
  * [Fast and Accurate: Video Enhancement Using Sparse Depth](https://openaccess.thecvf.com/content/WACV2023/papers/Feng_Fast_and_Accurate_Video_Enhancement_Using_Sparse_Depth_WACV_2023_paper.pdf)
* 视频理解
  * 通用事件边界检测
    * [Motion Aware Self-Supervision for Generic Event Boundary Detection](https://arxiv.org/abs/2210.05574)<br>:star:[code](https://github.com/rayush7/motion_ssl_gebd)
* 视频摘要
  * [Contrastive Losses Are Natural Criteria for Unsupervised Video Summarization](https://arxiv.org/abs/2211.10056)<br>:star:[code](https://github.com/pangzss/pytorch-CTVSUM)
  * [Progressive Video Summarization via Multimodal Self-Supervised Learning](https://arxiv.org/abs/2201.02494)
* 多人检测
  * [Two-level Data Augmentation for Calibrated Multi-view Detection](https://arxiv.org/abs/2210.10756)<br>:star:[code](https://github.com/cvlab-epfl/MVAug)
* 场景识别
  * [MovieCLIP: Visual Scene Recognition in Movies](https://arxiv.org/abs/2210.11065)<br>:house:[project](https://sail.usc.edu/~mica/MovieCLIP/)
* Video Grounding
  * [Language-free Training for Zero-shot Video Grounding](https://arxiv.org/abs/2210.12977)
* 视频异常检测(VAD)
  * [DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection Network](https://arxiv.org/abs/2211.00882)
  * [Cross-Domain Video Anomaly Detection without Target Domain Adaptation](https://arxiv.org/abs/2212.07010)
  * [Bi-Directional Frame Interpolation for Unsupervised Video Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Bi-Directional_Frame_Interpolation_for_Unsupervised_Video_Anomaly_Detection_WACV_2023_paper.pdf)
  * [Towards Interpretable Video Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Doshi_Towards_Interpretable_Video_Anomaly_Detection_WACV_2023_paper.pdf)
* 图像视频编解码
  * [Universal Deep Image Compression via Content-Adaptive Optimization with Adapters](https://arxiv.org/abs/2211.00918)<br>:star:[code](https://github.com/kktsubota/universal-dic)
  * [Boosting Neural Video Codecs by Exploiting Hierarchical Redundancy](https://openaccess.thecvf.com/content/WACV2023/papers/Pourreza_Boosting_Neural_Video_Codecs_by_Exploiting_Hierarchical_Redundancy_WACV_2023_paper.pdf)
* 视频人像合成
  * [Dynamic Neural Portraits](https://arxiv.org/abs/2211.13994)
* 视频帧插值
  * [Splatting-based Synthesis for Video Frame Interpolation](https://arxiv.org/abs/2201.10075)<br>:house:[project](http://sniklaus.com/splatsyn)
* 视频运动重定位
  * [Cross-Identity Video Motion Retargeting With Joint Transformation and Synthesis](https://openaccess.thecvf.com/content/WACV2023/papers/Ni_Cross-Identity_Video_Motion_Retargeting_With_Joint_Transformation_and_Synthesis_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/nihaomiao/WACV23_TSNet)

<a name="5"/>

## 5.Object Detection(目标检测)
* [ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing](https://arxiv.org/abs/2210.11539)<br>:star:[code](https://github.com/giuliomattolin/ConfMix)
* [Is Your Noise Correction Noisy? PLS: Robustness To Label Noise With Two Stage Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Albert_Is_Your_Noise_Correction_Noisy_PLS_Robustness_To_Label_Noise_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/PaulAlbert31/PLS)
* [Domain Adaptive Object Detection for Autonomous Driving under Foggy Weather](https://arxiv.org/abs/2210.15176)<br>:star:[code](https://github.com/jinlong17/DA-Detect)
* [ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy](https://arxiv.org/abs/2210.16083)
* [Towards Online Domain Adaptive Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/VS_Towards_Online_Domain_Adaptive_Object_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Vibashan/memXformer-online-da)
* [MT-DETR: Robust End-to-end Multimodal Detection with Confidence Fusion](https://openaccess.thecvf.com/content/WACV2023/papers/Chu_MT-DETR_Robust_End-to-End_Multimodal_Detection_With_Confidence_Fusion_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Chushihyun/MT-DETR)
* 3D目标检测
  * [TransPillars: Coarse-To-Fine Aggregation for Multi-Frame 3D Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Luo_TransPillars_Coarse-To-Fine_Aggregation_for_Multi-Frame_3D_Object_Detection_WACV_2023_paper.pdf)
  * [Adaptive Feature Fusion for Cooperative Perception Using LiDAR Point Clouds](https://openaccess.thecvf.com/content/WACV2023/papers/Qiao_Adaptive_Feature_Fusion_for_Cooperative_Perception_Using_LiDAR_Point_Clouds_WACV_2023_paper.pdf)
* VOD
  * [BoxMask: Revisiting Bounding Box Supervision for Video Object Detection](https://arxiv.org/abs/2210.06008)
* OOD
  * [Out-of-distribution Detection via Frequency-regularized Generative Models](https://arxiv.org/abs/2208.09083)<br>:star:[code](https://github.com/mu-cai/FRL)
  * [Heatmap-based Out-of-Distribution Detection](https://arxiv.org/abs/2211.08115)<br>:star:[code](https://github.com/jhornauer/heatmap_ood)
  * [Out-of-Distribution Detection with Reconstruction Error and Typicality-based Penalty](https://arxiv.org/abs/2212.12641)
  * [Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Mixture_Outlier_Exposure_Towards_Out-of-Distribution_Detection_in_Fine-Grained_Environments_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/zjysteven/MixOE)
* WSOD
  * [D2DF2WOD: Learning Object Proposals for Weakly-Supervised Object Detection via Progressive Domain Adaptation](https://arxiv.org/abs/2212.01376)
* 伪装目标检测
  * [MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection](https://arxiv.org/abs/2210.06361)<br>:star:[code](https://github.com/dwardzheng/MFFN_COD)
* 目标发现
  * [Foreground Guidance and Multi-Layer Feature Fusion for Unsupervised Object Discovery with Transformers](https://arxiv.org/abs/2210.13053)<br>:star:[code](https://github.com/VDIGPKU/FORMULA)
* 3D目标检测
  * [Li3DeTr: A LiDAR based 3D Detection Transformer](https://arxiv.org/abs/2210.15365)
  * [Far3Det: Towards Far-Field 3D Detection](https://arxiv.org/abs/2211.13858)
  * [Dense Voxel Fusion for 3D Object Detection](https://arxiv.org/abs/2203.00871)
  * [MonoEdge: Monocular 3D Object Detection Using Local Perspectives](https://arxiv.org/pdf/2301.01802.pdf)
* 变化检测
  * [The Change You Want to See](https://arxiv.org/abs/2209.14341)
* 用于穿行式安检系统的三维雷达图像的实时隐蔽武器检测
  * [Real-Time Concealed Weapon Detection on 3D Radar Images for Walk-Through Screening System](https://openaccess.thecvf.com/content/WACV2023/papers/Khan_Real-Time_Concealed_Weapon_Detection_on_3D_Radar_Images_for_Walk-Through_WACV_2023_paper.pdf)
* 图像识别
  * [Federated Domain Generalization for Image Recognition via Cross-Client Style Transfer](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Federated_Domain_Generalization_for_Image_Recognition_via_Cross-Client_Style_Transfer_WACV_2023_paper.pdf)<br>:house:[project](https://chenjunming.ml/proj/CCST/)
 

<a name="4"/>

## 4.GAN(生成对抗网络)
* [HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks](https://arxiv.org/abs/2210.06909)
* [Image Completion with Heterogeneously Filtered Spectral Hints](https://arxiv.org/abs/2211.03700)<br>:star:[code](https://github.com/SHI-Labs/SH-GAN)
* [Indirect Adversarial Losses via an Intermediate Distribution for Training GANs](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Indirect_Adversarial_Losses_via_an_Intermediate_Distribution_for_Training_GANs_WACV_2023_paper.pdf)
* [SLI-pSp: Injecting Multi-Scale Spatial Layout in pSp](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_SLI-pSp_Injecting_Multi-Scale_Spatial_Layout_in_pSp_WACV_2023_paper.pdf)
* fashion attribute editing(时尚属性编辑)
  * [Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation](https://arxiv.org/abs/2210.05872)
* 匿名化
  * [DeepPrivacy2: Towards Realistic Full-Body Anonymization](https://arxiv.org/abs/2211.09454)<br>:star:[code](https://github.com/hukkelas/deep_privacy2)  
* 指纹生成
  * [Synthetic Latent Fingerprint Generator](https://openaccess.thecvf.com/content/WACV2023/papers/Wyzykowski_Synthetic_Latent_Fingerprint_Generator_WACV_2023_paper.pdf)<br>:house:[project](https://prip-lab.github.io/Synthetic-Latent-Fingerprint-Generator/)  
* 开集识别
  * [MORGAN: Meta-Learning-based Few-Shot Open-Set Recognition via Generative Adversarial Network](https://openaccess.thecvf.com/content/WACV2023/papers/Pal_MORGAN_Meta-Learning-Based_Few-Shot_Open-Set_Recognition_via_Generative_Adversarial_Network_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/DebabrataPal7/MORGAN)  
  
<a name="3"/>

## 3.3D(三维视觉)
* [Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data](https://arxiv.org/abs/2210.11750)<br>:star:[code](https://github.com/kazuto1011/dusty-gan-v2)
* [Seg&Struct: The Interplay Between Part Segmentation and Structure Inference for 3D Shape Parsing](https://arxiv.org/abs/2211.00382)
* [Surface normal estimation from optimized and distributed light sources using DNN-based photometric stereo](https://openaccess.thecvf.com/content/WACV2023/papers/Iwaguchi_Surface_Normal_Estimation_From_Optimized_and_Distributed_Light_Sources_Using_WACV_2023_paper.pdf)
* [Meta-Auxiliary Learning for Future Depth Prediction in Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_Meta-Auxiliary_Learning_for_Future_Depth_Prediction_in_Videos_WACV_2023_paper.pdf)
* 三维重建
  * [Automated Line Labelling: Dataset for Contour Detection and 3D Reconstruction](https://openaccess.thecvf.com/content/WACV2023/papers/Santhanam_Automated_Line_Labelling_Dataset_for_Contour_Detection_and_3D_Reconstruction_WACV_2023_paper.pdf)
* 深度估计
  * [Frequency-Aware Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2210.05479)<br>:star:[code](https://github.com/xingyuuchen/freq-aware-depth)
  * [Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention](https://arxiv.org/abs/2210.09071)<br>:star:[code](https://github.com/ashutosh1807/PixelFormer)
  * [High-Resolution Depth Estimation for 360-degree Panoramas through Perspective and Panoramic Depth Images Registration](https://arxiv.org/abs/2210.10414)
  * [Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth Information](https://arxiv.org/abs/2211.10177)
  * [Temporally Consistent Online Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2111.09337)<br>:star:[code](https://github.com/facebookresearch/CODD)
  * [Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening Problem](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Self-Supervised_Monocular_Depth_Estimation_Solving_the_Edge-Fattening_Problem_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/xingyuuchen/tri-depth)
* 深度补全
  * [Sparsity Agnostic Depth Completion](https://arxiv.org/abs/2212.00790)
  * [SIUNet: Sparsity Invariant U-Net for Edge-Aware Depth Completion](https://openaccess.thecvf.com/content/WACV2023/papers/Ramesh_SIUNet_Sparsity_Invariant_U-Net_for_Edge-Aware_Depth_Completion_WACV_2023_paper.pdf)
  * [Uncertainty-Aware Interactive LiDAR Sampling for Deep Depth Completion](https://openaccess.thecvf.com/content/WACV2023/papers/Taguchi_Uncertainty-Aware_Interactive_LiDAR_Sampling_for_Deep_Depth_Completion_WACV_2023_paper.pdf)
* MVS
  * [Multi-View Photometric Stereo Revisited](https://arxiv.org/abs/2210.07670)
  * [DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo](https://arxiv.org/abs/2212.06626)
  * [nLMVS-Net: Deep Non-Lambertian Multi-View Stereo](https://openaccess.thecvf.com/content/WACV2023/papers/Yamashita_nLMVS-Net_Deep_Non-Lambertian_Multi-View_Stereo_WACV_2023_paper.pdf)<br>:house:[project](https://vision.ist.i.kyoto-u.ac.jp/)
* RGB-D重建
  * [High-Quality RGB-D Reconstruction via Multi-View Uncalibrated Photometric Stereo and Gradient-SDF](https://arxiv.org/abs/2210.12202)<br>:star:[code](https://github.com/Sangluisme/PSgradientSDF)
* Stereo Matching
  * [Expansion of Visual Hints for Improved Generalization in Stereo Matching](https://arxiv.org/abs/2211.00392)
* 神经辐射场
  * [ScanNeRF: a Scalable Benchmark for Neural Radiance Fields](https://arxiv.org/abs/2211.13762)<br>:house:[project](https://eyecan-ai.github.io/scannerf/)
* 三维定位
  * [3D Change Localization and Captioning From Dynamic Scans of Indoor Scenes](https://openaccess.thecvf.com/content/WACV2023/papers/Qiu_3D_Change_Localization_and_Captioning_From_Dynamic_Scans_of_Indoor_WACV_2023_paper.pdf)

<a name="2"/>

## 2.Medical Image(医学影像)
* [DBCE: A Saliency Method for Medical Deep Learning Through Anatomically-Consistent Free-Form Deformations](https://openaccess.thecvf.com/content/WACV2023/papers/Peters_DBCE_A_Saliency_Method_for_Medical_Deep_Learning_Through_Anatomically-Consistent_WACV_2023_paper.pdf)
* 胸部X光分类
  * [Probabilistic Integration of Object Level Annotations in Chest X-ray Classification](https://arxiv.org/abs/2210.06980)
* CT图像融合
  * [Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion](https://arxiv.org/abs/2210.07611)
* 医学图像定位
  * [Attend Who is Weak: Pruning-assisted Medical Image Localization under Sophisticated and Implicit Imbalances](https://arxiv.org/abs/2212.02675)
* 医学图像分割
  * [Few-shot Medical Image Segmentation with Cycle-resemblance Attention](https://arxiv.org/abs/2212.03967)
  * [Medical Image Segmentation via Cascaded Attention Decoding](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.pdf)
  * [HiFormer: Hierarchical Multi-scale Representations Using Transformers for Medical Image Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Heidari_HiFormer_Hierarchical_Multi-Scale_Representations_Using_Transformers_for_Medical_Image_Segmentation_WACV_2023_paper.pdf)
  * 病变分割
    * [Cut-Paste Consistency Learning for Semi-Supervised Lesion Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Yap_Cut-Paste_Consistency_Learning_for_Semi-Supervised_Lesion_Segmentation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/BPYap/Cut-Paste-Consistency)
* 医学图像分类
  * [ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Stegmuller_ScoreNet_Learning_Non-Uniform_Attention_and_Augmentation_for_Transformer-Based_Histopathological_Image_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/stegmuel/ScoreNet)
* 医学图像超分辨率
  * [Multimodal Multi-Head Convolutional Attention With Various Kernel Sizes for Medical Image Super-Resolution](https://openaccess.thecvf.com/content/WACV2023/papers/Georgescu_Multimodal_Multi-Head_Convolutional_Attention_With_Various_Kernel_Sizes_for_Medical_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/lilygeorgescu/MHCA)

<a name="1"/>

## 1.其它
* [Instance-Dependent Noisy Label Learning via Graphical Modelling](https://arxiv.org/abs/2209.00906)
* [Color Recommendation for Vector Graphic Documents based on Multi-Palette Representation](https://arxiv.org/abs/2209.10820)
* [TeST: Test-time Self-Training under Distribution Shift](https://arxiv.org/abs/2209.11459)
* [Simultaneous Acquisition of High Quality RGB Image and Polarization Information using a Sparse Polarization Sensor](https://arxiv.org/abs/2209.13106)<br>:star:[code](https://github.com/sony/polar-densification)
* [Enabling ISP-less Low-Power Computer Vision](https://arxiv.org/abs/2210.05451)
* [AdaNorm: Adaptive Gradient Norm Correction based Optimizer for CNNs](https://arxiv.org/abs/2210.06364)<br>:star:[code](https://github.com/shivram1987/AdaNorm)
* [Composite Learning for Robust and Effective Dense Predictions](https://arxiv.org/abs/2210.07239)
* [SAILOR: Scaling Anchors via Insights into Latent Object](https://arxiv.org/abs/2210.07811)<br>:star:[code](https://github.com/malicd/sailor)
* [Modeling the Lighting in Scenes as Style for Auto White-Balance Correction](https://arxiv.org/abs/2210.09090)<br>:star:[code](https://github.com/birdortyedi/lighting-as-style-awb-correction)
* [DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers](https://arxiv.org/abs/2210.08929)<br>:house:[project](https://sites.google.com/view/decrop)
* [Anisotropic Multi-Scale Graph Convolutional Network for Dense Shape Correspondence](https://arxiv.org/abs/2210.09466)
* [ATCON: Attention Consistency for Vision Models](https://arxiv.org/abs/2210.09705)<br>:star:[code](https://github.com/alimirzazadeh/SemisupervisedAttention)
* [LAVA: Label-efficient Visual Learning and Adaptation](https://arxiv.org/abs/2210.10317)
* [Interpolated SelectionConv for Spherical Images and Surfaces](https://arxiv.org/abs/2210.10123)
* [Augmentation by Counterfactual Explanation -- Fixing an Overconfident Classifier](https://arxiv.org/abs/2210.12196)
* [Weakly Supervised Annotations for Multi-modal Greeting Cards Dataset](https://arxiv.org/abs/2212.00847)
* [Multimodal Vision Transformers with Forced Attention for Behavior Analysis](https://arxiv.org/abs/2212.03968)<br>:star:[code](https://github.com/Parapompadoo/FAt-Transformers)
* [LINEEX: Data Extraction from Scientific Line Charts](https://openaccess.thecvf.com/content/WACV2023/papers/P._LineEX_Data_Extraction_From_Scientific_Line_Charts_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Shiva-sankaran/LineEX)
* [Neural Implicit Representations for Physical Parameter Inference From a Single Video](https://openaccess.thecvf.com/content/WACV2023/papers/Hofherr_Neural_Implicit_Representations_for_Physical_Parameter_Inference_From_a_Single_WACV_2023_paper.pdf)<br>:house:[project](https://florianhofherr.github.io/phys-param-inference/)
* [Physically Plausible Animation of Human Upper Body from a Single Image](https://arxiv.org/abs/2212.04741)
* [Partially Calibrated Semi-Generalized Pose From Hybrid Point Correspondences](https://openaccess.thecvf.com/content/WACV2023/papers/Bhayani_Partially_Calibrated_Semi-Generalized_Pose_From_Hybrid_Point_Correspondences_WACV_2023_paper.pdf)
* [Learning How to MIMIC: Using Model Explanations To Guide Deep Learning Training](https://openaccess.thecvf.com/content/WACV2023/papers/Watson_Learning_How_to_MIMIC_Using_Model_Explanations_To_Guide_Deep_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/mattswatson/learning-to-mimic)
* [Improving Multi-Fidelity Optimization With a Recurring Learning Rate for Hyperparameter Tuning](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_Improving_Multi-Fidelity_Optimization_With_a_Recurring_Learning_Rate_for_Hyperparameter_WACV_2023_paper.pdf)
* [What can we Learn by Predicting Accuracy?](https://openaccess.thecvf.com/content/WACV2023/papers/Risser-Maroix_What_Can_We_Learn_by_Predicting_Accuracy_WACV_2023_paper.pdf)
* [Jointly Learning Band Selection and Filter Array Design for Hyperspectral Imaging](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Jointly_Learning_Band_Selection_and_Filter_Array_Design_for_Hyperspectral_WACV_2023_paper.pdf)
* [LCS: Learning Compressible Subspaces for Efficient, Adaptive, Real-Time Network Compression at Inference Time](https://openaccess.thecvf.com/content/WACV2023/papers/Nunez_LCS_Learning_Compressible_Subspaces_for_Efficient_Adaptive_Real-Time_Network_Compression_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/apple/learning-compressible-subspaces)
* [Self-Attentive Pooling for Efficient Deep Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Self-Attentive_Pooling_for_Efficient_Deep_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/C-Fun/Non-Local-Pooling)
* [Fine-Grained Activities of People Worldwide](https://openaccess.thecvf.com/content/WACV2023/papers/Byrne_Fine-Grained_Activities_of_People_Worldwide_WACV_2023_paper.pdf)<br>:house:[project](https://visym.github.io/cap/)
* [Relaxing Contrastiveness in Multimodal Representation Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Lin_Relaxing_Contrastiveness_in_Multimodal_Representation_Learning_WACV_2023_paper.pdf)
* [Towards Disturbance-Free Visual Mobile Manipulation](https://openaccess.thecvf.com/content/WACV2023/papers/Ni_Towards_Disturbance-Free_Visual_Mobile_Manipulation_WACV_2023_paper.pdf)<br>:house:[project](https://sites.google.com/view/disturb-free)
* [SERF: Towards Better Training of Deep Neural Networks Using Log-Softplus ERror Activation Function](https://openaccess.thecvf.com/content/WACV2023/papers/Nag_SERF_Towards_Better_Training_of_Deep_Neural_Networks_Using_Log-Softplus_WACV_2023_paper.pdf)
* [RADIANT: Better rPPG Estimation Using Signal Embeddings and Transformer](https://openaccess.thecvf.com/content/WACV2023/papers/Gupta_RADIANT_Better_rPPG_Estimation_Using_Signal_Embeddings_and_Transformer_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Deep-Intelligence-Lab/RADIANT)
* [Dataset Condensation With Distribution Matching](https://openaccess.thecvf.com/content/WACV2023/papers/Zhao_Dataset_Condensation_With_Distribution_Matching_WACV_2023_paper.pdf)
* [HyperPosePDF - Hypernetworks Predicting the Probability Distribution on SO(3)](https://openaccess.thecvf.com/content/WACV2023/papers/Hofer_HyperPosePDF_-_Hypernetworks_Predicting_the_Probability_Distribution_on_SO3_WACV_2023_paper.pdf)
* [RANCER: Non-Axis Aligned Anisotropic Certification with Randomized Smoothing](https://openaccess.thecvf.com/content/WACV2023/papers/Rumezhak_RANCER_Non-Axis_Aligned_Anisotropic_Certification_With_Randomized_Smoothing_WACV_2023_paper.pdf)
* [Match Cutting: Finding Cuts with Smooth Visual Transitions](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Match_Cutting_Finding_Cuts_With_Smooth_Visual_Transitions_WACV_2023_paper.pdf)
* [Are Straight-Through gradients and Soft-Thresholding all you need for Sparse Training?](https://openaccess.thecvf.com/content/WACV2023/papers/Vanderschueren_Are_Straight-Through_Gradients_and_Soft-Thresholding_All_You_Need_for_Sparse_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/vanderschuea/stthree)
* BNN
  * [LAB: Learnable Activation Binarizer for Binary Neural Networks](https://arxiv.org/abs/2210.13858)<br>:star:[code](https://github.com/sfalkena/LAB)
* 图像配准
  * [Diffeomorphic Image Registration with Neural Velocity Field](https://openaccess.thecvf.com/content/WACV2023/papers/Han_Diffeomorphic_Image_Registration_With_Neural_Velocity_Field_WACV_2023_paper.pdf)


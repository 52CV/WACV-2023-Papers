# 52CV-WACV-Papers
![469c6797185d7c14eb859840ed9bb06](https://user-images.githubusercontent.com/62801906/209522296-cea08a9c-9f23-4ece-9093-69863b2e7027.jpg)

官网链接：[https://wacv2023.thecvf.com/home](https://wacv2023.thecvf.com/home)

会议日期：2023年1月3日-1月7日

## 历年综述论文分类汇总戳这里↘️[CV-Surveys](https://github.com/52CV/CV-Surveys)施工中~~~~~~~~~~

## 2023 年论文分类汇总戳这里
↘️[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
↘️[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)

## 2022 年论文分类汇总戳这里
↘️[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers)
↘️[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
↘️[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers)

## 2021年论文分类汇总戳这里
↘️[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
↘️[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

## 2020 年论文分类汇总戳这里
↘️[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers)
↘️[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)


# :exclamation::exclamation::exclamation::star2::star2::star2:分类
# 目录

|:dog:|:mouse:|:hamster:|:tiger:|
|---------|---------|---------|---------|
|[53.Gaze Estimation(视线估计)](#53)|[54.Optical Flow(光流)](#54)|[55.Object Counting(物体计数)](#55)|
|[49.Debiasing(去偏见)](#49)|[50.Sign Language Translation(手语翻译)](#50)|[51.SSC(语义场景完成)](#51)|[52.Eye Tracking(眼动跟踪)](#52)|
|[45.Class-Incremental Learning(类增量学习)](#45)|[46.Metric Learning(度量学习)](#46)|[47.Data Augmentation(数据增强)](#47)|[48.Light Fields(光场)](#48)|
|[41.Action Generation(动作生成)](#41)|[42.Landmark Detection(关键点检测)](#42)|[43.Active Learning(主动学习)](#43)|[44.Multi-Task Learning(多任务学习)](#44)|
|[37.OT(目标跟踪)](#37)|[38.Sound(音频处理)](#38)|[39.Style Transfer(风格迁移)](#39)|[40.AD(异常检测)](#40)|
|[33.View Synthesis(视图合成)](#33)|[34.SLAM\Robots](#34)|[35.VQA(视觉问答)](#35)|[36.Soft Biometrics(软生物技术)](#36)|
|[29.Image Classification(图像分类)](#29)|[30.RL(强化学习)](#30)|[31.Deepfake Detection(假象检测)](#31)|[32.Continual Learning(持续学习)](#32)|
|[25.Image Captioning(图像字幕)](#25)|[26.Dataset(数据集)](#26)|[27.Defect Detection(缺陷检测)](#27)|[28.OPE(物体姿态估计)](#28)|
|[21.PC(点云)](#21)|[22.HAR(人体动作识别与检测)](#22)|[23.AD(智能驾驶)](#23)|[24.Image Retrieval(图像检索)](#24)|
|[17.OCR(文本检测)](#17)|[18.NAS(神经架构搜索)](#18)|[19.MC\KD\Pruning(模型压缩\知识蒸馏\剪枝)](#19)|[20.Transformer](#20)|
|[13.Image Segmentation(图像分割)](#13)|[14.SSL(半监督学习)](#14)|[15.Image Synthesis(图像合成)](#15)|[16.SR(超分辨率)](#16)|
|[9.RS\Satellite Image(遥感\卫星图像)](#9)|[10.AL(对抗学习)](#10)|[11.Face(人脸)](#11)|[12.FSL or DA\G(小样本学习 or 域适应\泛化)](#12)|
|[5.OD(目标检测)](#5)|[6.Video(视频相关)](#6)|[7.Pose(人体姿态)](#7)|[8.Image Processing(图像处理)](#8)|
|[1.其它](#1)|[2.Medical Image(医学影像)](#2)|[3.3D(三维视觉)](#3)|[4.GAN(生成对抗网络)](#4)|


## Human Motion Prediction(人类运动预测)
* [Multi-view Tracking Using Weakly Supervised Human Motion Prediction](https://arxiv.org/abs/2210.10771)<br>:star:[code](https://github.com/cvlab-epfl/MVFlow)
* [Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation](https://arxiv.org/abs/2210.12649)<br>:star:[code](https://github.com/zeyun-zhong/AFFT)
* [GliTr: Glimpse Transformers with Spatiotemporal Consistency for Online Action Prediction](https://arxiv.org/abs/2210.13605)


## Sound
* Audio Visual Event Localization视听事件定位
  * [AVE-CLIP: AudioCLIP-based Multi-window Temporal Transformer for Audio Visual Event Localization](https://arxiv.org/abs/2210.05060)
* 音频去噪
  * [BirdSoundsDenoising: Deep Visual Audio Denoising for Bird Sounds](https://arxiv.org/abs/2210.10196)
* 视听分割
  * [Unsupervised Audio-Visual Lecture Segmentation](https://arxiv.org/abs/2210.16644)<br>:house:[project](https://cvit.iiit.ac.in/research/projects/cvit-projects/avlectures)
* 生源定位
  * [Hear The Flow: Optical Flow-Based Self-Supervised Visual Sound Source Localization](https://arxiv.org/abs/2211.03019)<br>:star:[code](https://github.com/denfed/heartheflow)

## Style Transfer
* [Line Search-Based Feature Transformation for Fast, Stable, and Tunable Content-Style Control in Photorealistic Style Transfer](https://arxiv.org/abs/2210.05996)<br>:star:[code](https://github.com/chiutaiyin/LS-FT)

## 场景图生成
* [Grounding Scene Graphs on Natural Images via Visio-Lingual Message Passing](https://arxiv.org/abs/2211.01969)<br>:star:[code](https://github.com/IISCAditayTripathi/Scene-graph-localization):house:[project](https://iiscaditaytripathi.github.io/sgl/)

## Person ReID
* 行人搜索
  * [Gallery Filter Network for Person Search](https://arxiv.org/abs/2210.12903)<br>:star:[code](https://github.com/LukeJaffe/GFN)
* Re-id
  * [Camera Alignment and Weighted Contrastive Learning for Domain Adaptation in Video Person ReID](https://arxiv.org/abs/2211.03626)<br>:star:[code](https://github.com/dmekhazni/CAWCL-ReID)
  * [MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification](https://arxiv.org/abs/2211.04656)<br>:star:[code](https://github.com/Kitware/MEVID)
  * [Feature Disentanglement Learning with Switching and Aggregation for Video-based Person Re-Identification](https://arxiv.org/abs/2212.09498)
* 步态识别
  * [Gait Recognition Using 3-D Human Body Shape Inference](https://arxiv.org/abs/2212.09042)
* 嫌疑人识别
  * [A Suspect Identification Framework using Contrastive Relevance Feedback](https://cdn.iiit.ac.in/cdn/precog.iiit.ac.in/pubs/WACV_2023_FaIRCoP_Camera_Ready.pdf)

## 57.Federated Learning(联邦学习)
* [Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning](https://arxiv.org/abs/2210.02326)<br>:star:[code](https://github.com/Erosinho13/LADD)

## 56.Vision-Language(视觉语言)
* [VL-Taboo: An Analysis of Attribute-based Zero-shot Capabilities of Vision-Language Models](https://arxiv.org/abs/2209.06103)<br>:star:[code](https://github.com/felixVogel02/VL-Taboo/tree/main)
* [Learning by Hallucinating: Vision-Language Pre-training with Weak Supervision](https://arxiv.org/abs/2210.13591)
* [Perceiver-VL: Efficient Vision-and-Language Modeling with Iterative Latent Attention](https://arxiv.org/abs/2211.11701)<br>:star:[code](https://github.com/zinengtang/Perceiver_VL)

<a name="55"/>

## 55.Object Counting(物体计数)

<a name="54"/>

## 54.Optical Flow(光流)
* [Weakly-Supervised Optical Flow Estimation for Time-of-Flight](https://arxiv.org/abs/2210.05298)

<a name="53"/>

## 53.Gaze Estimation(视线估计)
* iris localization(虹膜定位)
  * [Segmentation-free Direct Iris Localization Networks](https://arxiv.org/abs/2210.10403)
* 视线跟随
  * [Patch-level Gaze Distribution Prediction for Gaze Following](https://arxiv.org/abs/2211.11062)

<a name="52"/>

## 52.Eye Tracking(眼动跟踪)

<a name="51"/>

## 51.Semantic Scene Completion(语义场景完成SSC)

<a name="50"/>

## 50.Sign Language Translation(手语翻译)

<a name="49"/>

## 49.Debiasing(去偏见)

<a name="48"/>

## 48.Light Fields(光场)

<a name="47"/>

## 47.Data Augmentation(数据增强)
* [Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive Positive or Negative Data Augmentation](https://arxiv.org/abs/2210.12681)<br>:star:[code](https://github.com/AtsuMiyai/rethinking_rotation)

<a name="46"/>

## 46.Metric Learning(度量学习)
* [InDiReCT: Language-Guided Zero-Shot Deep Metric Learning for Images](https://arxiv.org/abs/2211.12760)<br>:star:[code](https://github.com/LSX-UniWue/InDiReCT)

<a name="45"/>

## 45.Class-Incremental Learning(类增量学习)

<a name="44"/>

## 44.Multi-Task Learning(多任务学习)

<a name="43"/>

## 43.Active Learning(主动学习)

<a name="42"/>

## 42.Landmark Detection(关键点检测)

<a name="41"/>

## 41.Action Generation(动作生成)

<a name="40"/>

## 40.Anomaly Detection(异常检测)
* [Asymmetric Student-Teacher Networks for Industrial Anomaly Detection](https://arxiv.org/abs/2210.07829)<br>:star:[code](https://github.com/marco-rudolph/ast)

<a name="39"/>

## 39.Style Transfer(风格迁移)

<a name="38"/>

## 38.Sound(音频处理)

<a name="37"/>

## 37.Object Tracking(目标跟踪)
* [Efficient Visual Tracking with Exemplar Transformers](https://arxiv.org/abs/2112.09686)<br>:star:[code](https://github.com/pblatter/ettrack)
* 多目标跟踪
  * [AttTrack: Online Deep Attention Transfer for Multi-object Tracking](https://arxiv.org/abs/2210.08648)

<a name="36"/>

## 36.Soft Biometrics(软生物技术)
* 手指静脉识别
  * [Analysis of Master Vein Attacks on Finger Vein Recognition Systems](https://arxiv.org/abs/2210.10667)

<a name="35"/>

## 35.VQA(视觉问答)
* [DRAMA: Joint Risk Localization and Captioning in Driving](https://arxiv.org/abs/2209.10767)
* [VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge](https://arxiv.org/abs/2210.13626)<br>:star:[code](https://github.com/aditya10/VLC-BERT)
* VideoQA
  * [Dense but Efficient VideoQA for Intricate Compositional Reasoning](https://arxiv.org/abs/2210.10300)
 
<a name="34"/>

## 34.SLAM\Robots
* SLAM
  * [Probabilistic Volumetric Fusion for Dense Monocular SLAM](https://arxiv.org/abs/2210.01276)

<a name="33"/>

## 33.View Synthesis(视图合成)

<a name="32"/>

## 32.Continual Learning(持续学习)
* [Continual Learning with Dependency Preserving Hypernetworks](https://arxiv.org/abs/2209.07712)
* [Do Pre-trained Models Benefit Equally in Continual Learning](https://arxiv.org/abs/2210.15701)<br>:star:[code](https://github.com/eric11220/pretrained-models-in-CL)

<a name="31"/>

## 31.Deepfake Detection(假象检测)
* 图像伪造
  * [CFL-Net: Image Forgery Localization Using Contrastive Learning](https://arxiv.org/abs/2210.02182)<br>:star:[code](https://github.com/niloy193/CFLNet)

<a name="30"/>

## 30.Reinforcement Learning(强化学习)
* [Switching to Discriminative Image Captioning by Relieving a Bottleneck of Reinforcement Learning](https://arxiv.org/abs/2212.03230)<br>:star:[code](https://github.com/ukyh/switchdisccaption)

<a name="29"/>

## 29.Image Classification(图像分类)
* 长尾识别
  * [Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition](https://arxiv.org/abs/2209.02960)
* pen-Set Classification
  * [Large-Scale Open-Set Classification Protocols for ImageNet](https://arxiv.org/abs/2210.06789)
  
<a name="28"/>

## 28.Pose Estimation(姿态估计)
* 6D
  * [CRT-6D: Fast 6D Object Pose Estimation with Cascaded Refinement Transformers](https://arxiv.org/abs/2210.11718)<br>:star:[code](https://github.com/PedroCastro/CRT-6D)

<a name="27"/>

## 27.Defect Detection(缺陷检测)

<a name="26"/>

## 26.Dataset\Benchmark(数据集\基准)
* [OpenEarthMap: A Benchmark Dataset for Global High-Resolution Land Cover Mapping](https://arxiv.org/abs/2210.10732)<br>:sunflower:[dataset](https://open-earth-map.org/)
* [IDD-3D: A Dataset for Driving in Unstructured Road Scenes](https://arxiv.org/abs/2210.12878)<br>:sunflower:[dataset](https://github.com/shubham1810/idd3d_kit)

<a name="25"/>

## 25.Image Captioning(图像字幕)

<a name="24"/>

## 24.Image Retrieval(图像检索)
* [Boosting vision transformers for image retrieval](https://arxiv.org/abs/2210.11909)<br>:star:[code](https://github.com/dealicious-inc/DToP)
* 图像-句子检索
  * [Cross-modal Semantic Enhanced Interaction for Image-Sentence Retrieval](https://arxiv.org/abs/2210.08908)
* 图像-文本检索
  * [Dissecting Deep Metric Learning Losses for Image-Text Retrieval](https://arxiv.org/abs/2210.13188)<br>:star:[code](https://github.com/littleredxh/VSE-Gradient)

<a name="23"/>

## 23.Autonomous Driving(智能驾驶)
* [IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes](https://arxiv.org/abs/2210.12878)<br>:star:[code](https://github.com/shubham1810/idd3d_kit)

<a name="22"/>

## 22.Human Action Recognition(人体动作识别与检测)
* 动作识别
  * [Modality Mixer for Multi-modal Action Recognition](https://arxiv.org/abs/2208.11314)
  * [STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition](https://arxiv.org/abs/2210.07503)
  * [Holistic Interaction Transformer Network for Action Detection](https://arxiv.org/abs/2210.12686)<br>:star:[code](https://github.com/joslefaure/HIT)
  * [Reconstructing Humpty Dumpty: Multi-feature Graph Autoencoder for Open Set Action Recognition](https://arxiv.org/abs/2212.06023)<br>:star:[code](https://github.com/Kitware/graphautoencoder)
  * [DA-AIM: Exploiting Instance-based Mixed Sampling via Auxiliary Source Domain Supervision for Domain-adaptive Action Detection](https://arxiv.org/pdf/2209.15439.pdf)<br>:star:[code](https://github.com/wwwfan628/DA-AIM)
  * [Spatio-Temporal Action Detection Under Large Motion](https://arxiv.org/pdf/2209.02250.pdf)<br>:star:[code](https://github.com/gurkirt/ActionTrackDetectron)

<a name="21"/>

## 21.Point Cloud(点云)
* [PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning of Point Clouds](https://arxiv.org/abs/2210.08305)
* 点云配准
  * [Overlap-guided Gaussian Mixture Models for Point Cloud Registration](https://arxiv.org/abs/2210.09836)<br>:star:[code](https://github.com/gfmei/ogmm)
* 点云重建
  * [PointInverter: Point Cloud Reconstruction and Editing via a Generative Model with Shape Priors](https://arxiv.org/abs/2211.08702)<br>:star:[code](https://github.com/hkust-vgd/point_inverter)
* 3D点云
  * [PIDS: Joint Point Interaction-Dimension Search for 3D Point Cloud](https://arxiv.org/abs/2211.15759)

<a name="20"/>

## 20.Transformer
* [EmbryosFormer: Deformable Transformer and Collaborative Encoding-Decoding for Embryos Stage Development Classification](https://arxiv.org/abs/2210.04615)<br>:star:[code](https://github.com/UARK-AICV/Embryos)
* [Delving into Masked Autoencoders for Multi-Label Thorax Disease Classification](https://arxiv.org/abs/2210.12843)<br>:star:[code](https://github.com/lambert-x/Medical_MAE)
* [Accumulated Trivial Attention Matters in Vision Transformers on Small Datasets](https://arxiv.org/abs/2210.12333)<br>:star:[code](https://github.com/xiangyu8/SATA)

<a name="19"/>

## 19.Model Compression\Knowledge Distillation\Pruning(模型压缩\知识蒸馏\剪枝)
* 剪枝
  * [Pushing the Efficiency Limit Using Structured Sparse Convolutions](https://arxiv.org/abs/2210.12818)<br>:star:[code](https://github.com/vkvermaa/SSC)
  * [Calibrating Deep Neural Networks using Explicit Regularisation and Dynamic Data Pruning](https://arxiv.org/abs/2212.10005)
* 知识蒸馏
  * [Collaborative Multi-Teacher Knowledge Distillation for Learning Low Bit-width Deep Neural Networks](https://arxiv.org/abs/2210.16103)
  * [Understanding the Role of Mixup in Knowledge Distillation: \\An Empirical Study](https://arxiv.org/abs/2211.03946)<br>:star:[code](https://github.com/hchoi71/MIX-KD)

<a name="18"/>

## 18.NAS(神经架构搜索)
* [Revisiting Training-free NAS Metrics: An Efficient Training-based Method](https://arxiv.org/abs/2211.08666)<br>:star:[code](https://github.com/taoyang1122/Revisit_TrainingFree_NAS)

<a name="17"/>

## 17.OCR(文本检测)
* [OCR-VQGAN: Taming Text-within-Image Generation](https://arxiv.org/abs/2210.11248)<br>:star:[code](https://github.com/joanrod/ocr-vqgan)
* [Efficient few-shot learning for pixel-precise handwritten document layout analysis](https://arxiv.org/abs/2210.15570)
* 文本识别
  * [Seq-UPS: Sequential Uncertainty-aware Pseudo-label Selection for Semi-Supervised Text Recognition](https://arxiv.org/abs/2209.00641)

<a name="16"/>

## 16.Super-Resolution(超分辨率)
* [Single Image Super-Resolution via a Dual Interactive Implicit Neural Network](https://arxiv.org/abs/2210.12593)
* [HIME: Efficient Headshot Image Super-Resolution with Multiple Exemplars](https://arxiv.org/abs/2203.14863)

<a name="15"/>

## 15.Image Synthesis(图像合成)
* [One-Shot Synthesis of Images and Segmentation Masks](https://arxiv.org/abs/2209.07547)<br>:star:[code](https://github.com/boschresearch/one-shot-synthesis)
* [Style-Guided Inference of Transformer for High-resolution Image Synthesis](https://arxiv.org/abs/2210.05533)
* 图像生成
  * [Adaptively-Realistic Image Generation from Stroke and Sketch with Diffusion Model](https://arxiv.org/abs/2208.12675)<br>:star:[code](https://github.com/cyj407/DiSS):house:[project](https://cyj407.github.io/DiSS/)
* 文本-图像合成
  * [Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation](https://arxiv.org/abs/2211.07751)<br>:star:[code](https://github.com/openai/glide-text2im)
* 文字引导的图像操作
  * [Interactive Image Manipulation with Complex Text Instructions](https://arxiv.org/abs/2211.15352) 
 
<a name="14"/>

## 14.Un\Self\Semi-Supervised Learning(无\自\半监督学习)
* 自监督
  * [Self-Supervised Pyramid Representation Learning for Multi-Label Visual Analysis and Beyond](https://arxiv.org/abs/2208.14439)<br>:star:[code](https://github.com/WesleyHsieh0806/SS-PRL)
  * [FUSSL: Fuzzy Uncertain Self Supervised Learning](https://arxiv.org/abs/2210.15818)
  * [Self-Supervised Correspondence Estimation via Multiview Registration](https://arxiv.org/abs/2212.03236)<br>:house:[project](https://mbanani.github.io/syncmatch/)
  * [Similarity Contrastive Estimation for Image and Video Soft Contrastive Self-Supervised Learning](https://arxiv.org/abs/2212.11187)
* 半监督
  * [Class-Level Confidence Based 3D Semi-Supervised Learning](https://arxiv.org/abs/2210.10138)

<a name="13"/>

## 13.Image Segmentation(图像分割)
* [Image Segmentation-based Unsupervised Multiple Objects Discovery](https://arxiv.org/abs/2212.10124)
* VOS
  * [Unsupervised Video Object Segmentation via Prototype Memory Network](https://arxiv.org/abs/2209.03712)
* VSS
  * [Domain Adaptive Video Semantic Segmentation via Cross-Domain Moving Object Mixing](https://arxiv.org/abs/2211.02307)
* 语义分割
  * [Attribution-aware Weight Transfer: A Warm-Start Initialization for Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2210.07207)<br>:star:[code](https://github.com/dfki-av/AWT-for-CISS)
  * [Full Contextual Attention for Multi-resolution Transformers in Semantic Segmentation](https://arxiv.org/abs/2212.07890)
  * [Urban Scene Semantic Segmentation with Low-Cost Coarse Annotation](https://arxiv.org/abs/2212.07911)
  * [LoopDA: Constructing Self-loops to Adapt Nighttime Semantic Segmentation](https://arxiv.org/abs/2211.11870)<br>:star:[code](https://github.com/fy-vision/LoopDA)
* BEV segmentation
  * [X-Align: Cross-Modal Cross-View Alignment for Bird's-Eye-View Segmentation](https://arxiv.org/abs/2210.06778)<br>:star:[code](https://github.com/robot-learning-freiburg/PanopticBEV)
* 全景分割
  * [MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to Depth-aware Video Panoptic Segmentation](https://arxiv.org/abs/2210.07577)
* 实例分割
  * [From Forks to Forceps: A New Framework for Instance Segmentation of Surgical Instruments](https://arxiv.org/abs/2211.16200)
* 小样本分割
  * [Elimination of Non-Novel Segments at Multi-Scale for Few-Shot Segmentation](https://arxiv.org/abs/2211.02300)
* 细胞分割
  * [Knowing What to Label for Few Shot Microscopy Image Cell Segmentation](https://arxiv.org/abs/2211.10244)<br>:star:[code](https://github.com/Yussef93/KnowWhatToLabel/)

<a name="12"/>

## 12.One\Few-Shot Learning or Domain Adaptation\Generalization\Shift(单\小样本学习 or 域适应\泛化\偏移)
* 域适应
  * [Reducing Annotation Effort by Identifying and Labeling Contextually Diverse Classes for Semantic Segmentation Under Domain Shift](https://arxiv.org/abs/2210.06749)<br>:star:[code](https://github.com/sharat29ag/contextual_class)
  * [Self-Distillation for Unsupervised 3D Domain Adaptation](https://arxiv.org/abs/2210.08226)<br>:house:[project](https://cvlab-unibo.github.io/FeatureDistillation/)
  * [CoNMix for Source-free Single and Multi-target Domain Adaptation](https://arxiv.org/abs/2211.03876)<br>:star:[code](https://github.com/vcl-iisc/CoNMix):house:[project](https://sites.google.com/view/conmix-vcl)
  * [Learning Classifiers of Prototypes and Reciprocal Points for Universal Domain Adaptation](https://arxiv.org/abs/2212.08355)
* 域泛化
  * [Intra-Source Style Augmentation for Improved Domain Generalization](https://arxiv.org/abs/2210.10175)

<a name="11"/>

## 11.Face(人脸)
* [My Face My Choice: Privacy Enhancing Deepfakes for Social Media Anonymization](https://arxiv.org/abs/2211.01361)
* 人脸识别
  * [DigiFace-1M: 1 Million Digital Face Images for Face Recognition](https://arxiv.org/abs/2210.02579)<br>:star:[code](https://github.com/microsoft/DigiFace1M)
* 人脸交换
  * [FaceOff: A Video-to-Video Face Swapping System](https://arxiv.org/abs/2208.09788)
* 读唇术
  * [Towards MOOCs for Lip Reading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale](https://arxiv.org/abs/2208.09796)
* 人脸恢复
  * [AT-DDPM: Restoring Faces degraded by Atmospheric Turbulence using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2208.11284)
* 人脸表情识别
  * [Uncertainty-aware Label Distribution Learning for Facial Expression Recognition](https://arxiv.org/abs/2209.10448)<br>:star:[code](https://github.com/minhnhatvt/label-distribution-learning-fer-tf)
* 人脸重现
  * [Audio-Visual Face Reenactment](https://arxiv.org/abs/2210.02755)<br>:house:[project](http://cvit.iiit.ac.in/research/projects/cvit-projects/avfr)
* 基于表情的脸部皱纹合成
  * [Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces](https://arxiv.org/abs/2210.03529)
* 人脸命名
  * [Weakly Supervised Face Naming with Symmetry-Enhanced Contrastive Loss](https://arxiv.org/abs/2210.08957)
* Facial Action Unit Detection
  * [FAN-Trans: Online Knowledge Distillation for Facial Action Unit Detection](https://arxiv.org/abs/2211.06143) 
* 人脸质量评估
  * [IFQA: Interpretable Face Quality Assessment](https://arxiv.org/abs/2211.07077)<br>:star:[code](https://github.com/VCLLab/IFQA) 
* 基于表情的合成脸部皱纹
  * [Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces](https://arxiv.org/abs/2210.03529)
 
<a name="10"/>

## 10.Adversarial Learning(对抗学习)
* [Leveraging Local Patch Differences in Multi-Object Scenes for Generative Adversarial Attacks](https://arxiv.org/abs/2209.09883)

<a name="9"/>

## 9.Remote Sensing\Satellite Image(遥感\卫星图像)
* RS
  * [Handling Image and Label Resolution Mismatch in Remote Sensing](https://arxiv.org/abs/2211.15790)
* 变化检测
  * [Self-Pair: Synthesizing Changes from Single Source for Object Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2212.10236)<br>:star:[code](https://github.com/seominseok0429/Self-Pair-for-Change-Detection)
  
<a name="8"/>

## 8.Image Processing(图像处理)
* 图像恢复
  * [Large-to-small Image Resolution Asymmetry in Deep Metric Learning](https://arxiv.org/abs/2210.05463)<br>:star:[code](https://github.com/pavelsuma/raml)
* 图像增强
  * [Perceptual Image Enhancement for Smartphone Real-Time Applications](https://arxiv.org/abs/2210.13552)<br>:star:[code](https://github.com/mv-lab/AISP)
* 图像着色
  * [Guiding Users to Where to Give Color Hints for Efficient Interactive Sketch Colorization via Unsupervised Region Prioritization](https://arxiv.org/abs/2210.14270)
  * [Generative Colorization of Structured Mobile Web Pages](https://arxiv.org/abs/2212.11541)<br>:star:[code](https://github.com/CyberAgentAILab/webcolor)
* HDR重构
  * [Single-Image HDR Reconstruction by Multi-Exposure Generation](https://arxiv.org/abs/2210.15897)<br>:star:[code](https://github.com/VinAIResearch/single_image_hdr)
  
<a name="7"/>

## 7.Human Pose(人体姿态)
* [Kinematic-aware Hierarchical Attention Network for Human Pose Estimation in Videos](https://arxiv.org/abs/2211.15868)<br>:star:[code](https://github.com/KyungMinJin/HANet)
* 多人姿态估计
  * [SoMoFormer: Multi-Person Pose Forecasting with Transformers](https://arxiv.org/abs/2208.14023)<br>:house:[project](https://somof.stanford.edu/result/217/)
* 三维人体
  * [Placing Human Animations into 3D Scenes by Learning Interaction- and Geometry-Driven Keyframes](https://arxiv.org/abs/2209.06314)
  * [Uplift and Upsample: Efficient 3D Human Pose Estimation with Uplifting Transformers](https://arxiv.org/abs/2210.06110)<br>:star:[code](https://github.com/goldbricklemon/uplift-upsample-3dhpe)
* 手部重建
  * [THOR-Net: End-to-end Graformer-based Realistic Two Hands and Object Reconstruction with Self-supervision](https://arxiv.org/abs/2210.13853)<br>:star:[code](https://github.com/ATAboukhadra/THOR-Net)
* 手-物体姿势估计
  * [Interacting Hand-Object Pose Estimation via Dense Mutual Attention](https://arxiv.org/abs/2211.08805)<br>:star:[code](https://github.com/rongakowang/DenseMutualAttention)

<a name="6"/>

## 6.Video(视频相关)
* 视频理解
  * 通用事件边界检测
    * [Motion Aware Self-Supervision for Generic Event Boundary Detection](https://arxiv.org/abs/2210.05574)<br>:star:[code](https://github.com/rayush7/motion_ssl_gebd)
* 视频摘要
  * [Contrastive Losses Are Natural Criteria for Unsupervised Video Summarization](https://arxiv.org/abs/2211.10056)<br>:star:[code](https://github.com/pangzss/pytorch-CTVSUM)
* 多人检测
  * [Two-level Data Augmentation for Calibrated Multi-view Detection](https://arxiv.org/abs/2210.10756)<br>:star:[code](https://github.com/cvlab-epfl/MVAug)
* 场景识别
  * [MovieCLIP: Visual Scene Recognition in Movies](https://arxiv.org/abs/2210.11065)<br>:house:[project](https://sail.usc.edu/~mica/MovieCLIP/)
* Video Grounding
  * [Language-free Training for Zero-shot Video Grounding](https://arxiv.org/abs/2210.12977)
* 视频异常检测(VAD)
  * [DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection Network](https://arxiv.org/abs/2211.00882)
  * [Cross-Domain Video Anomaly Detection without Target Domain Adaptation](https://arxiv.org/abs/2212.07010)
* 图像视频编解码
  * [Universal Deep Image Compression via Content-Adaptive Optimization with Adapters](https://arxiv.org/abs/2211.00918)<br>:star:[code](https://github.com/kktsubota/universal-dic)
* 视频人像合成
  * [Dynamic Neural Portraits](https://arxiv.org/abs/2211.13994)
* 视频帧插值
  * [Splatting-based Synthesis for Video Frame Interpolation](https://arxiv.org/abs/2201.10075)<br>:house:[project](http://sniklaus.com/splatsyn)

<a name="5"/>

## 5.Object Detection(目标检测)
* [ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing](https://arxiv.org/abs/2210.11539)<br>:star:[code](https://github.com/giuliomattolin/ConfMix)
* [Domain Adaptive Object Detection for Autonomous Driving under Foggy Weather](https://arxiv.org/abs/2210.15176)<br>:star:[code](https://github.com/jinlong17/DA-Detect)
* [ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy](https://arxiv.org/abs/2210.16083)
* VOD
  * [BoxMask: Revisiting Bounding Box Supervision for Video Object Detection](https://arxiv.org/abs/2210.06008)
* OOD
  * [Out-of-distribution Detection via Frequency-regularized Generative Models](https://arxiv.org/abs/2208.09083)<br>:star:[code](https://github.com/mu-cai/FRL)
  * [Heatmap-based Out-of-Distribution Detection](https://arxiv.org/abs/2211.08115)<br>:star:[code](https://github.com/jhornauer/heatmap_ood)
  * [Out-of-Distribution Detection with Reconstruction Error and Typicality-based Penalty](https://arxiv.org/abs/2212.12641)
* WSOD
  * [D2DF2WOD: Learning Object Proposals for Weakly-Supervised Object Detection via Progressive Domain Adaptation](https://arxiv.org/abs/2212.01376)
* 伪装目标检测
  * [MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection](https://arxiv.org/abs/2210.06361)<br>:star:[code](https://github.com/dwardzheng/MFFN_COD)
* 目标发现
  * [Foreground Guidance and Multi-Layer Feature Fusion for Unsupervised Object Discovery with Transformers](https://arxiv.org/abs/2210.13053)<br>:star:[code](https://github.com/VDIGPKU/FORMULA)
* 3D目标检测
  * [Li3DeTr: A LiDAR based 3D Detection Transformer](https://arxiv.org/abs/2210.15365)
  * [Far3Det: Towards Far-Field 3D Detection](https://arxiv.org/abs/2211.13858)
  * [Dense Voxel Fusion for 3D Object Detection](https://arxiv.org/abs/2203.00871)
* 变化检测
  * [The Change You Want to See](https://arxiv.org/abs/2209.14341)

<a name="4"/>

## 4.GAN(生成对抗网络)
* [HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks](https://arxiv.org/abs/2210.06909)
* [Image Completion with Heterogeneously Filtered Spectral Hints](https://arxiv.org/abs/2211.03700)<br>:star:[code](https://github.com/SHI-Labs/SH-GAN)
* fashion attribute editing(时尚属性编辑)
  * [Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation](https://arxiv.org/abs/2210.05872)
* 匿名化
  * [DeepPrivacy2: Towards Realistic Full-Body Anonymization](https://arxiv.org/abs/2211.09454)<br>:star:[code](https://github.com/hukkelas/deep_privacy2)  
  
<a name="3"/>

## 3.3D(三维视觉)
* [Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data](https://arxiv.org/abs/2210.11750)<br>:star:[code](https://github.com/kazuto1011/dusty-gan-v2)
* [Seg&Struct: The Interplay Between Part Segmentation and Structure Inference for 3D Shape Parsing](https://arxiv.org/abs/2211.00382)
* 深度估计
  * [Frequency-Aware Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2210.05479)<br>:star:[code](https://github.com/xingyuuchen/freq-aware-depth)
  * [Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention](https://arxiv.org/abs/2210.09071)<br>:star:[code](https://github.com/ashutosh1807/PixelFormer)
  * [High-Resolution Depth Estimation for 360-degree Panoramas through Perspective and Panoramic Depth Images Registration](https://arxiv.org/abs/2210.10414)
  * [Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth Information](https://arxiv.org/abs/2211.10177)
  * [Temporally Consistent Online Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2111.09337)<br>:star:[code](https://github.com/facebookresearch/CODD)
* 深度补全
  * [Sparsity Agnostic Depth Completion](https://arxiv.org/abs/2212.00790)
* MVS
  * [Multi-View Photometric Stereo Revisited](https://arxiv.org/abs/2210.07670)
  * [DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo](https://arxiv.org/abs/2212.06626)
* RGB-D重建
  * [High-Quality RGB-D Reconstruction via Multi-View Uncalibrated Photometric Stereo and Gradient-SDF](https://arxiv.org/abs/2210.12202)<br>:star:[code](https://github.com/Sangluisme/PSgradientSDF)
* Stereo Matching
  * [Expansion of Visual Hints for Improved Generalization in Stereo Matching](https://arxiv.org/abs/2211.00392)
* 神经辐射场
  * [ScanNeRF: a Scalable Benchmark for Neural Radiance Fields](https://arxiv.org/abs/2211.13762)<br>:house:[project](https://eyecan-ai.github.io/scannerf/)

<a name="2"/>

## 2.Medical Image(医学影像)
* 胸部X光分类
  * [Probabilistic Integration of Object Level Annotations in Chest X-ray Classification](https://arxiv.org/abs/2210.06980)
* CT图像融合
  * [Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion](https://arxiv.org/abs/2210.07611)
* 医学图像定位
  * [Attend Who is Weak: Pruning-assisted Medical Image Localization under Sophisticated and Implicit Imbalances](https://arxiv.org/abs/2212.02675)
* 医学图像分割
  * [Few-shot Medical Image Segmentation with Cycle-resemblance Attention](https://arxiv.org/abs/2212.03967)

<a name="1"/>

## 1.其它
* [Instance-Dependent Noisy Label Learning via Graphical Modelling](https://arxiv.org/abs/2209.00906)
* [Color Recommendation for Vector Graphic Documents based on Multi-Palette Representation](https://arxiv.org/abs/2209.10820)
* [TeST: Test-time Self-Training under Distribution Shift](https://arxiv.org/abs/2209.11459)
* [Simultaneous Acquisition of High Quality RGB Image and Polarization Information using a Sparse Polarization Sensor](https://arxiv.org/abs/2209.13106)<br>:star:[code](https://github.com/sony/polar-densification)
* [Enabling ISP-less Low-Power Computer Vision](https://arxiv.org/abs/2210.05451)
* [AdaNorm: Adaptive Gradient Norm Correction based Optimizer for CNNs](https://arxiv.org/abs/2210.06364)<br>:star:[code](https://github.com/shivram1987/AdaNorm)
* [Composite Learning for Robust and Effective Dense Predictions](https://arxiv.org/abs/2210.07239)
* [SAILOR: Scaling Anchors via Insights into Latent Object](https://arxiv.org/abs/2210.07811)<br>:star:[code](https://github.com/malicd/sailor)
* [Modeling the Lighting in Scenes as Style for Auto White-Balance Correction](https://arxiv.org/abs/2210.09090)<br>:star:[code](https://github.com/birdortyedi/lighting-as-style-awb-correction)
* [DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers](https://arxiv.org/abs/2210.08929)<br>:house:[project](https://sites.google.com/view/decrop)
* [Anisotropic Multi-Scale Graph Convolutional Network for Dense Shape Correspondence](https://arxiv.org/abs/2210.09466)
* [ATCON: Attention Consistency for Vision Models](https://arxiv.org/abs/2210.09705)<br>:star:[code](https://github.com/alimirzazadeh/SemisupervisedAttention)
* [LAVA: Label-efficient Visual Learning and Adaptation](https://arxiv.org/abs/2210.10317)
* [Interpolated SelectionConv for Spherical Images and Surfaces](https://arxiv.org/abs/2210.10123)
* [Augmentation by Counterfactual Explanation -- Fixing an Overconfident Classifier](https://arxiv.org/abs/2210.12196)
* [Weakly Supervised Annotations for Multi-modal Greeting Cards Dataset](https://arxiv.org/abs/2212.00847)
* [Multimodal Vision Transformers with Forced Attention for Behavior Analysis](https://arxiv.org/abs/2212.03968)<br>:star:[code](https://github.com/Parapompadoo/FAt-Transformers)
* [Physically Plausible Animation of Human Upper Body from a Single Image](https://arxiv.org/abs/2212.04741)
* BNN
  * [LAB: Learnable Activation Binarizer for Binary Neural Networks](https://arxiv.org/abs/2210.13858)<br>:star:[code](https://github.com/sfalkena/LAB)



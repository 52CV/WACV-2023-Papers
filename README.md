# 52CV-WACV-Papers
![469c6797185d7c14eb859840ed9bb06](https://user-images.githubusercontent.com/62801906/209522296-cea08a9c-9f23-4ece-9093-69863b2e7027.jpg)

官网链接：[https://wacv2023.thecvf.com/home](https://wacv2023.thecvf.com/home)

会议日期：2023年1月3日-1月7日

## 历年综述论文分类汇总戳这里↘️[CV-Surveys](https://github.com/52CV/CV-Surveys)施工中~~~~~~~~~~

## 2023 年论文分类汇总戳这里
↘️[CVPR-2023-Papers](https://github.com/52CV/CVPR-2023-Papers)
↘️[WACV-2023-Papers](https://github.com/52CV/WACV-2023-Papers)

## 2022 年论文分类汇总戳这里
↘️[CVPR-2022-Papers](https://github.com/52CV/CVPR-2022-Papers)
↘️[WACV-2022-Papers](https://github.com/52CV/WACV-2022-Papers)
↘️[ECCV-2022-Papers](https://github.com/52CV/ECCV-2022-Papers)

## 2021年论文分类汇总戳这里
↘️[ICCV-2021-Papers](https://github.com/52CV/ICCV-2021-Papers)
↘️[CVPR-2021-Papers](https://github.com/52CV/CVPR-2021-Papers)

## 2020 年论文分类汇总戳这里
↘️[CVPR-2020-Papers](https://github.com/52CV/CVPR-2020-Papers)
↘️[ECCV-2020-Papers](https://github.com/52CV/ECCV-2020-Papers)


# :exclamation::exclamation::exclamation::star2::star2::star2:WACV 2023收录论文已全部公布，下载可在【我爱计算机视觉】后台回复“paper”，即可收到。共计 638 篇。
# 目录

|:dog:|:mouse:|:hamster:|:tiger:|
|---------|---------|---------|---------|
|[53.Gaze Estimation(视线估计)](#53)|[54.Optical Flow(光流)](#54)|[55.Object Counting(物体计数)](#55)|
|[49.Debiasing(去偏见)](#49)|[50.Sign Language Translation(手语翻译)](#50)|[51.SSC(语义场景完成)](#51)|[52.Eye Tracking(眼动跟踪)](#52)|
|[45.Class-Incremental Learning(类增量学习)](#45)|[46.Metric Learning(度量学习)](#46)|[47.Data Augmentation(数据增强)](#47)|[48.Light Fields(光场)](#48)|
|[41.Action Generation(动作生成)](#41)|[42.Landmark Detection(关键点检测)](#42)|[43.Active Learning(主动学习)](#43)|[44.Multi-Task Learning(多任务学习)](#44)|
|[37.OT(目标跟踪)](#37)|[38.Sound(音频处理)](#38)|[39.Style Transfer(风格迁移)](#39)|[40.AD(异常检测)](#40)|
|[33.View Synthesis(视图合成)](#33)|[34.SLAM\Robots](#34)|[35.VQA(视觉问答)](#35)|[36.Soft Biometrics(软生物技术)](#36)|
|[29.Image Classification(图像分类)](#29)|[30.RL(强化学习)](#30)|[31.Deepfake Detection(假象检测)](#31)|[32.Continual Learning(持续学习)](#32)|
|[25.Image Captioning(图像字幕)](#25)|[26.Dataset(数据集)](#26)|[27.Defect Detection(缺陷检测)](#27)|[28.OPE(物体姿态估计)](#28)|
|[21.PC(点云)](#21)|[22.HAR(人体动作识别与检测)](#22)|[23.AD(智能驾驶)](#23)|[24.Image Retrieval(图像检索)](#24)|
|[17.OCR(文本检测)](#17)|[18.NAS(神经架构搜索)](#18)|[19.MC\KD\Pruning(模型压缩\知识蒸馏\剪枝)](#19)|[20.Transformer](#20)|
|[13.Image Segmentation(图像分割)](#13)|[14.SSL(半监督学习)](#14)|[15.Image Synthesis(图像合成)](#15)|[16.SR(超分辨率)](#16)|
|[9.RS\Satellite Image(遥感\卫星图像)](#9)|[10.AL(对抗学习)](#10)|[11.Face(人脸)](#11)|[12.FSL or DA\G(小样本学习 or 域适应\泛化)](#12)|
|[5.OD(目标检测)](#5)|[6.Video(视频相关)](#6)|[7.Pose(人体姿态)](#7)|[8.Image Processing(图像处理)](#8)|
|[1.其它](#1)|[2.Medical Image(医学影像)](#2)|[3.3D(三维视觉)](#3)|[4.GAN(生成对抗网络)](#4)|


## Open Set Recognition
* [Ancestor Search: Generalized Open Set Recognition via Hyperbolic Side Information Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Dengxiong_Ancestor_Search_Generalized_Open_Set_Recognition_via_Hyperbolic_Side_Information_WACV_2023_paper.pdf)
## Visual Odometry(视觉里程计)
* [Pixel-Wise Prediction Based Visual Odometry via Uncertainty Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Pixel-Wise_Prediction_Based_Visual_Odometry_via_Uncertainty_Estimation_WACV_2023_paper.pdf)

## object re-identification
* [Bent & Broken Bicycles: Leveraging synthetic data for damaged object re-identification](https://openaccess.thecvf.com/content/WACV2023/papers/Piano_Bent__Broken_Bicycles_Leveraging_Synthetic_Data_for_Damaged_Object_WACV_2023_paper.pdf)<br>:house:[project](https://tinyurl.com/37tepf7m)

## 合成说话头
* 唇语阅读
  * [Towards MOOCs for Lipreading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale](https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Towards_MOOCs_for_Lipreading_Using_Synthetic_Talking_Heads_To_Train_WACV_2023_paper.pdf)

## Place Recognition(位置识别)
* [ETR: An Efficient Transformer for Re-ranking in Visual Place Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_ETR_An_Efficient_Transformer_for_Re-Ranking_in_Visual_Place_Recognition_WACV_2023_paper.pdf)
* [MixVPR: Feature Mixing for Visual Place Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Ali-bey_MixVPR_Feature_Mixing_for_Visual_Place_Recognition_WACV_2023_paper.pdf)
## Dense Prediction
* [Dense Prediction With Attentive Feature Aggregation](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Dense_Prediction_With_Attentive_Feature_Aggregation_WACV_2023_paper.pdf)
## Neural Radiance(渲染)
* [Ev-NeRF: Event Based Neural Radiance Field](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Jointly_Learning_Band_Selection_and_Filter_Array_Design_for_Hyperspectral_WACV_2023_paper.pdf)
* [DDNeRF: Depth Distribution Neural Radiance Fields](https://openaccess.thecvf.com/content/WACV2023/papers/Dadon_DDNeRF_Depth_Distribution_Neural_Radiance_Fields_WACV_2023_paper.pdf)
* [X-NeRF: Explicit Neural Radiance Field for Multi-Scene 360deg Insufficient RGB-D Views](https://openaccess.thecvf.com/content/WACV2023/papers/Zhu_X-NeRF_Explicit_Neural_Radiance_Field_for_Multi-Scene_360deg_Insufficient_RGB-D_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/HaoyiZhu/XNeRF)
* [Fast Differentiable Transient Rendering for Non-Line-of-Sight Reconstruction](https://openaccess.thecvf.com/content/WACV2023/papers/Plack_Fast_Differentiable_Transient_Rendering_for_Non-Line-of-Sight_Reconstruction_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/unlikelymaths/totrilib)
* [Compressing Explicit Voxel Grid Representations: fast NeRFs become also small](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Compressing_Explicit_Voxel_Grid_Representations_Fast_NeRFs_Become_Also_Small_WACV_2023_paper.pdf)

##  geo-localization(城市地理定位)
* [TransVLAD: Multi-Scale Attention-Based Global Descriptors for Visual Geo-Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Xu_TransVLAD_Multi-Scale_Attention-Based_Global_Descriptors_for_Visual_Geo-Localization_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/wacv-23/TVLAD)

## Image-to-Image Translation(图像-图像翻译)
* [Panoptic-Aware Image-to-Image Translation](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Panoptic-Aware_Image-to-Image_Translation_WACV_2023_paper.pdf)
* 图像翻译
  * [RIFT: Disentangled Unsupervised Image Translation via Restricted Information Flow](https://openaccess.thecvf.com/content/WACV2023/papers/Usman_RIFT_Disentangled_Unsupervised_Image_Translation_via_Restricted_Information_Flow_WACV_2023_paper.pdf)
* 域到域翻译
  * [Learning Style Subspaces for Controllable Unpaired Domain Translation](https://openaccess.thecvf.com/content/WACV2023/papers/Bhatt_Learning_Style_Subspaces_for_Controllable_Unpaired_Domain_Translation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/GauravBh1010tt/Controllable-Domain-Translation)

## Human Motion Prediction(人类运动预测)
* [Multi-view Tracking Using Weakly Supervised Human Motion Prediction](https://arxiv.org/abs/2210.10771)<br>:star:[code](https://github.com/cvlab-epfl/MVFlow)
* [Anticipative Feature Fusion Transformer for Multi-Modal Action Anticipation](https://arxiv.org/abs/2210.12649)<br>:star:[code](https://github.com/zeyun-zhong/AFFT)
* [GliTr: Glimpse Transformers with Spatiotemporal Consistency for Online Action Prediction](https://arxiv.org/abs/2210.13605)
* 行人轨迹预测
  * [Online Adaptive Temporal Memory with Certainty Estimation for Human Trajectory Prediction](https://openaccess.thecvf.com/content/WACV2023/papers/Huynh_Online_Adaptive_Temporal_Memory_With_Certainty_Estimation_for_Human_Trajectory_WACV_2023_paper.pdf)

## Scene Graph Generation(场景图生成)
* [Grounding Scene Graphs on Natural Images via Visio-Lingual Message Passing](https://arxiv.org/abs/2211.01969)<br>:star:[code](https://github.com/IISCAditayTripathi/Scene-graph-localization):house:[project](https://iiscaditaytripathi.github.io/sgl/)
* [Improving Predicate Representation in Scene Graph Generation by Self-Supervised Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Hasegawa_Improving_Predicate_Representation_in_Scene_Graph_Generation_by_Self-Supervised_Learning_WACV_2023_paper.pdf)

## Contrastive Learning(对比学习)
* [Similarity Contrastive Estimation for Self-Supervised Soft Contrastive Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Denize_Similarity_Contrastive_Estimation_for_Self-Supervised_Soft_Contrastive_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/CEA-LIST/SCE)
* [Representation Disentanglement in Generative Models with Contrastive Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Mo_Representation_Disentanglement_in_Generative_Models_With_Contrastive_Learning_WACV_2023_paper.pdf)

## Meta learning
* [Meta-OLE: Meta-learned Orthogonal Low-Rank Embedding](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_Meta-OLE_Meta-Learned_Orthogonal_Low-Rank_Embedding_WACV_2023_paper.pdf)

## Human Object Interaction(人物交互)
* 手物交互  
  * [Fine-grained Affordance Annotation for Egocentric Hand-Object Interaction Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_Fine-Grained_Affordance_Annotation_for_Egocentric_Hand-Object_Interaction_Videos_WACV_2023_paper.pdf)

## Person ReID
* 行人搜索
  * [Gallery Filter Network for Person Search](https://arxiv.org/abs/2210.12903)<br>:star:[code](https://github.com/LukeJaffe/GFN)
  * [UPAR: Unified Pedestrian Attribute Recognition and Person Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Specker_UPAR_Unified_Pedestrian_Attribute_Recognition_and_Person_Retrieval_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/speckean/upar_dataset)
  * [SAT: Scale-Augmented Transformer for Person Search](https://openaccess.thecvf.com/content/WACV2023/papers/Fiaz_SAT_Scale-Augmented_Transformer_for_Person_Search_WACV_2023_paper.pdf)
* Re-id
  * [Camera Alignment and Weighted Contrastive Learning for Domain Adaptation in Video Person ReID](https://arxiv.org/abs/2211.03626)<br>:star:[code](https://github.com/dmekhazni/CAWCL-ReID)
  * [MEVID: Multi-view Extended Videos with Identities for Video Person Re-Identification](https://arxiv.org/abs/2211.04656)<br>:star:[code](https://github.com/Kitware/MEVID)
  * [Feature Disentanglement Learning with Switching and Aggregation for Video-based Person Re-Identification](https://arxiv.org/abs/2212.09498)
  * [Graph-Based Self-Learning for Robust Person Re-Identification](https://openaccess.thecvf.com/content/WACV2023/papers/Xian_Graph-Based_Self-Learning_for_Robust_Person_Re-Identification_WACV_2023_paper.pdf)
  * [Body Part-Based Representation Learning for Occluded Person Re-Identification](https://openaccess.thecvf.com/content/WACV2023/papers/Somers_Body_Part-Based_Representation_Learning_for_Occluded_Person_Re-Identification_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/VlSomers/bpbreid)
* 步态识别
  * [Gait Recognition Using 3-D Human Body Shape Inference](https://arxiv.org/abs/2212.09042)
* 步态迁移
  * [CTrGAN: Cycle Transformers GAN for Gait Transfer](https://openaccess.thecvf.com/content/WACV2023/papers/Mahpod_CTrGAN_Cycle_Transformers_GAN_for_Gait_Transfer_WACV_2023_paper.pdf)
* 嫌疑人识别
  * [A Suspect Identification Framework using Contrastive Relevance Feedback](https://cdn.iiit.ac.in/cdn/precog.iiit.ac.in/pubs/WACV_2023_FaIRCoP_Camera_Ready.pdf)
* 人群计数
  * [Dynamic Mixture of Counter Network for Location-Agnostic Crowd Counting](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_Dynamic_Mixture_of_Counter_Network_for_Location-Agnostic_Crowd_Counting_WACV_2023_paper.pdf)

## 57.Federated Learning(联邦学习)
* [Learning Across Domains and Devices: Style-Driven Source-Free Domain Adaptation in Clustered Federated Learning](https://arxiv.org/abs/2210.02326)<br>:star:[code](https://github.com/Erosinho13/LADD)
* [Federated Learning for Commercial Image Sources](https://openaccess.thecvf.com/content/WACV2023/papers/Jain_Federated_Learning_for_Commercial_Image_Sources_WACV_2023_paper.pdf)

## 56.Vision-Language(视觉语言)
* [VL-Taboo: An Analysis of Attribute-based Zero-shot Capabilities of Vision-Language Models](https://arxiv.org/abs/2209.06103)<br>:star:[code](https://github.com/felixVogel02/VL-Taboo/tree/main)
* [Learning by Hallucinating: Vision-Language Pre-training with Weak Supervision](https://arxiv.org/abs/2210.13591)
* [Perceiver-VL: Efficient Vision-and-Language Modeling with Iterative Latent Attention](https://arxiv.org/abs/2211.11701)<br>:star:[code](https://github.com/zinengtang/Perceiver_VL)
* VLN
  * [Structure-Encoding Auxiliary Tasks for Improved Visual Representation in Vision-and-Language Navigatio](https://openaccess.thecvf.com/content/WACV2023/papers/Kuo_Structure-Encoding_Auxiliary_Tasks_for_Improved_Visual_Representation_in_Vision-and-Language_Navigation_WACV_2023_paper.pdf)

<a name="55"/>

## 55.Object Counting(物体计数)
* [Few-shot Object Counting with Similarity-Aware Feature Enhancement](https://openaccess.thecvf.com/content/WACV2023/papers/You_Few-Shot_Object_Counting_With_Similarity-Aware_Feature_Enhancement_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/zhiyuanyou/SAFECount)

<a name="54"/>

## 54.Optical Flow(光流)
* [Weakly-Supervised Optical Flow Estimation for Time-of-Flight](https://arxiv.org/abs/2210.05298)
* [Rebalancing Gradient To Improve Self-Supervised Co-Training of Depth, Odometry and Optical Flow Predictions](https://openaccess.thecvf.com/content/WACV2023/papers/Hariat_Rebalancing_Gradient_To_Improve_Self-Supervised_Co-Training_of_Depth_Odometry_and_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/mhariat/CoopNet)
* [DCVNet: Dilated Cost Volume Networks for Fast Optical Flow](https://openaccess.thecvf.com/content/WACV2023/papers/Jiang_DCVNet_Dilated_Cost_Volume_Networks_for_Fast_Optical_Flow_WACV_2023_paper.pdf)
* [MFCFlow : A Motion Feature Compensated Multi-Frame Recurrent Network for Optical Flow Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_MFCFlow_A_Motion_Feature_Compensated_Multi-Frame_Recurrent_Network_for_Optical_WACV_2023_paper.pdf)
* [BrightFlow: Brightness-Change-Aware Unsupervised Learning of Optical Flow](https://openaccess.thecvf.com/content/WACV2023/papers/Marsal_BrightFlow_Brightness-Change-Aware_Unsupervised_Learning_of_Optical_Flow_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/CEA-LIST/BrightFlow)

<a name="53"/>

## 53.Gaze Estimation(视线估计)
* iris localization(虹膜定位)
  * [Segmentation-free Direct Iris Localization Networks](https://arxiv.org/abs/2210.10403)
* 视线跟随
  * [Patch-level Gaze Distribution Prediction for Gaze Following](https://arxiv.org/abs/2211.11062)
* 视线重定向
  * [Fine Gaze Redirection Learning with Gaze Hardness-aware Transformation](https://openaccess.thecvf.com/content/WACV2023/papers/Park_Fine_Gaze_Redirection_Learning_With_Gaze_Hardness-Aware_Transformation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/san9569/Gaze-Redir-Learning)
  * [CUDA-GHR: Controllable Unsupervised Domain Adaptation for Gaze and Head Redirection](https://openaccess.thecvf.com/content/WACV2023/papers/Jindal_CUDA-GHR_Controllable_Unsupervised_Domain_Adaptation_for_Gaze_and_Head_Redirection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/jswati31/cuda-ghr)

<a name="52"/>

## 52.Eye Tracking(眼动跟踪)

<a name="51"/>

## 51.Semantic Scene Completion(语义场景完成SSC)

<a name="50"/>

## 50.Sign Language Translation(手语翻译)

<a name="49"/>

## 49.Debiasing(去偏见)

<a name="48"/>

## 48.Light Fields(光场)
* 光场
  * [I See-Through You: A Framework for Removing Foreground Occlusion in Both Sparse and Dense Light Field Images](https://openaccess.thecvf.com/content/WACV2023/papers/Hur_I_See-Through_You_A_Framework_for_Removing_Foreground_Occlusion_in_WACV_2023_paper.pdf)
* 相机
  * [Event-based RGB sensing with structured light](https://openaccess.thecvf.com/content/WACV2023/papers/Bajestani_Event-Based_RGB_Sensing_With_Structured_Light_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/MISTLab/event_based_rgbd_ros)
  * [Burst Vision Using Single-Photon Cameras](https://openaccess.thecvf.com/content/WACV2023/papers/Ma_Burst_Vision_Using_Single-Photon_Cameras_WACV_2023_paper.pdf)
  * [TVCalib: Camera Calibration for Sports Field Registration in Soccer](https://openaccess.thecvf.com/content/WACV2023/papers/Theiner_TVCalib_Camera_Calibration_for_Sports_Field_Registration_in_Soccer_WACV_2023_paper.pdf)<br>:house:[project](https://mm4spa.github.io/tvcalib/)
* 兴趣点检测
  * [EventPoint: Self-Supervised Interest Point Detection and Description for Event-Based Camera](https://openaccess.thecvf.com/content/WACV2023/papers/Huang_EventPoint_Self-Supervised_Interest_Point_Detection_and_Description_for_Event-Based_Camera_WACV_2023_paper.pdf)

<a name="47"/>

## 47.Data Augmentation(数据增强)
* [Rethinking Rotation in Self-Supervised Contrastive Learning: Adaptive Positive or Negative Data Augmentation](https://arxiv.org/abs/2210.12681)<br>:star:[code](https://github.com/AtsuMiyai/rethinking_rotation)

<a name="46"/>

## 46.Metric Learning(度量学习)
* [InDiReCT: Language-Guided Zero-Shot Deep Metric Learning for Images](https://arxiv.org/abs/2211.12760)<br>:star:[code](https://github.com/LSX-UniWue/InDiReCT)

<a name="45"/>

## 45.Class-Incremental Learning(类增量学习)
* [AdvisIL - A Class-Incremental Learning Advisor](https://openaccess.thecvf.com/content/WACV2023/papers/Feillet_AdvisIL_-_A_Class-Incremental_Learning_Advisor_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/EvaJF/AdvisIL)
* 增量学习
  * [Neural Weight Search for Scalable Task Incremental Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Jiang_Neural_Weight_Search_for_Scalable_Task_Incremental_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/JianJiangKCL/NeuralWeightSearch)

<a name="44"/>

## 44.Multi-Task Learning(多任务学习)
* [Cross-task Attention Mechanism for Dense Multi-task Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Lopes_Cross-Task_Attention_Mechanism_for_Dense_Multi-Task_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/astra-vision/DenseMTL)

<a name="43"/>

## 43.Active Learning(主动学习)

<a name="42"/>

## 42.Landmark Detection(关键点检测)
* [CoKe: Contrastive Learning for Robust Keypoint Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Bai_CoKe_Contrastive_Learning_for_Robust_Keypoint_Detection_WACV_2023_paper.pdf)

<a name="41"/>

## 41.Action Generation(动作生成)
* 全身运动合成
  * [DSAG: A Scalable Deep Framework for Action-Conditioned Multi-Actor Full Body Motion Synthesis](https://openaccess.thecvf.com/content/WACV2023/papers/Gupta_DSAG_A_Scalable_Deep_Framework_for_Action-Conditioned_Multi-Actor_Full_Body_WACV_2023_paper.pdf)

<a name="40"/>

## 40.Anomaly Detection(异常检测)
* [Asymmetric Student-Teacher Networks for Industrial Anomaly Detection](https://arxiv.org/abs/2210.07829)<br>:star:[code](https://github.com/marco-rudolph/ast)
* [Zero-Shot Versus Many-Shot: Unsupervised Texture Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Aota_Zero-Shot_Versus_Many-Shot_Unsupervised_Texture_Anomaly_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://drive.google.com/drive/folders/10OyPzvI3H6llCZBxKxFlKWt1Pw1tkMK1)
* [No Shifted Augmentations (NSA): compact distributions for robust self-supervised Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Yousef_No_Shifted_Augmentations_NSA_Compact_Distributions_for_Robust_Self-Supervised_Anomaly_WACV_2023_paper.pdf)
* 道路异常检测
  * [Image-Consistent Detection of Road Anomalies as Unpredictable Patches](https://openaccess.thecvf.com/content/WACV2023/papers/Vojir_Image-Consistent_Detection_of_Road_Anomalies_As_Unpredictable_Patches_WACV_2023_paper.pdf)
* 异常聚类
  * [Anomaly Clustering: Grouping Images into Coherent Clusters of Anomaly Types](https://openaccess.thecvf.com/content/WACV2023/papers/Sohn_Anomaly_Clustering_Grouping_Images_Into_Coherent_Clusters_of_Anomaly_Types_WACV_2023_paper.pdf)

<a name="39"/>

## 39.Style Transfer(风格迁移)
* [Line Search-Based Feature Transformation for Fast, Stable, and Tunable Content-Style Control in Photorealistic Style Transfer](https://arxiv.org/abs/2210.05996)<br>:star:[code](https://github.com/chiutaiyin/LS-FT)
* [RAST: Restorable Arbitrary Style Transfer via Multi-Restoration](https://openaccess.thecvf.com/content/WACV2023/papers/Ma_RAST_Restorable_Arbitrary_Style_Transfer_via_Multi-Restoration_WACV_2023_paper.pdf)

<a name="38"/>

## 38.Sound(音频处理)
* Audio Visual Event Localization视听事件定位
  * [AVE-CLIP: AudioCLIP-based Multi-window Temporal Transformer for Audio Visual Event Localization](https://arxiv.org/abs/2210.05060)
* 音频去噪
  * [BirdSoundsDenoising: Deep Visual Audio Denoising for Bird Sounds](https://arxiv.org/abs/2210.10196)
* 视听分割
  * [Unsupervised Audio-Visual Lecture Segmentation](https://arxiv.org/abs/2210.16644)<br>:house:[project](https://cvit.iiit.ac.in/research/projects/cvit-projects/avlectures)
* 生源定位
  * [Hear The Flow: Optical Flow-Based Self-Supervised Visual Sound Source Localization](https://arxiv.org/abs/2211.03019)<br>:star:[code](https://github.com/denfed/heartheflow)
  * [Exploiting Visual Context Semantics for Sound Source Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Zhou_Exploiting_Visual_Context_Semantics_for_Sound_Source_Localization_WACV_2023_paper.pdf)
* 语音识别
  * [Audio-Visual Efficient Conformer for Robust Speech Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Burchi_Audio-Visual_Efficient_Conformer_for_Robust_Speech_Recognition_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/burchim/AVEC)

<a name="37"/>

## 37.Object Tracking(目标跟踪)
* [Efficient Visual Tracking with Exemplar Transformers](https://arxiv.org/abs/2112.09686)<br>:star:[code](https://github.com/pblatter/ettrack)
* [Hard to Track Objects with Irregular Motions and Similar Appearances?Make It Easier by Buffering the Matching Space](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Hard_To_Track_Objects_With_Irregular_Motions_and_Similar_Appearances_WACV_2023_paper.pdf)
* [HOOT: Heavy Occlusions in Object Tracking Benchmark](https://openaccess.thecvf.com/content/WACV2023/papers/Sahin_HOOT_Heavy_Occlusions_in_Object_Tracking_Benchmark_WACV_2023_paper.pdf)
* [VirtualHome Action Genome: A Simulated Spatio-Temporal Scene Graph Dataset With Consistent Relationship Labels](https://openaccess.thecvf.com/content/WACV2023/papers/Qiu_VirtualHome_Action_Genome_A_Simulated_Spatio-Temporal_Scene_Graph_Dataset_With_WACV_2023_paper.pdf)
* [Tracking Growth and Decay of Plant Roots in Minirhizotron Images](https://openaccess.thecvf.com/content/WACV2023/papers/Gillert_Tracking_Growth_and_Decay_of_Plant_Roots_in_Minirhizotron_Images_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/alexander-g/Root-Tracking)
* 多目标跟踪
  * [AttTrack: Online Deep Attention Transfer for Multi-object Tracking](https://arxiv.org/abs/2210.08648)
  * [Detection Recovery in Online Multi-Object Tracking With Sparse Graph Tracker](https://openaccess.thecvf.com/content/WACV2023/papers/Hyun_Detection_Recovery_in_Online_Multi-Object_Tracking_With_Sparse_Graph_Tracker_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/HYUNJS/SGT)
  * [MMPTRACK: Large-scale Densely Annotated Multi-camera Multiple People Tracking Benchmark](https://openaccess.thecvf.com/content/WACV2023/papers/Han_MMPTRACK_Large-Scale_Densely_Annotated_Multi-Camera_Multiple_People_Tracking_Benchmark_WACV_2023_paper.pdf)


<a name="36"/>

## 36.Soft Biometrics(软生物技术)
* 手指静脉识别
  * [Analysis of Master Vein Attacks on Finger Vein Recognition Systems](https://arxiv.org/abs/2210.10667)
* 隐形眼镜虹膜PAD算法的错误分类
  * [Misclassifications of Contact Lens Iris PAD Algorithms: Is it Gender Bias or Environmental Conditions](https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Misclassifications_of_Contact_Lens_Iris_PAD_Algorithms_Is_It_Gender_WACV_2023_paper.pdf)
* 生物信息识别
  * [Can Shadows Reveal Biometric Information?](https://openaccess.thecvf.com/content/WACV2023/papers/Medin_Can_Shadows_Reveal_Biometric_Information_WACV_2023_paper.pdf)

<a name="35"/>

## 35.VQA(视觉问答)
* [DRAMA: Joint Risk Localization and Captioning in Driving](https://arxiv.org/abs/2209.10767)
* [VLC-BERT: Visual Question Answering with Contextualized Commonsense Knowledge](https://arxiv.org/abs/2210.13626)<br>:star:[code](https://github.com/aditya10/VLC-BERT)
* [Barlow constrained optimization for Visual Question Answering](https://openaccess.thecvf.com/content/WACV2023/papers/Jha_Barlow_Constrained_Optimization_for_Visual_Question_Answering_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/abskjha/Barlow-constrained-VQA)
* [How To Practice VQA on a Resource-Limited Target Domain](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_How_To_Practice_VQA_on_a_Resource-Limited_Target_Domain_WACV_2023_paper.pdf)<br>:house:[project](https://people.cs.pitt.edu/~mzhang/practice-vqa/)
* [Guiding Visual Question Answering With Attention Priors](https://openaccess.thecvf.com/content/WACV2023/papers/Le_Guiding_Visual_Question_Answering_With_Attention_Priors_WACV_2023_paper.pdf)
* VideoQA
  * [Dense but Efficient VideoQA for Intricate Compositional Reasoning](https://arxiv.org/abs/2210.10300)
* 视觉问题生成
  * [K-VQG: Knowledge-Aware Visual Question Generation for Common-Sense Acquisition](https://openaccess.thecvf.com/content/WACV2023/papers/Uehara_K-VQG_Knowledge-Aware_Visual_Question_Generation_for_Common-Sense_Acquisition_WACV_2023_paper.pdf)<br>:house:[project](https://uehara-mech.github.io/kvqg)

<a name="34"/>

## 34.SLAM\Robots
* SLAM
  * [Probabilistic Volumetric Fusion for Dense Monocular SLAM](https://arxiv.org/abs/2210.01276)
* AR
  * [Heightfields for Efficient Scene Reconstruction for AR](https://openaccess.thecvf.com/content/WACV2023/papers/Watson_Heightfields_for_Efficient_Scene_Reconstruction_for_AR_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/nianticlabs/heightfields)

<a name="33"/>

## 33.View Synthesis(视图合成)
* [Vision Transformer for NeRF-Based View Synthesis From a Single Input Image](https://openaccess.thecvf.com/content/WACV2023/papers/Lin_Vision_Transformer_for_NeRF-Based_View_Synthesis_From_a_Single_Input_WACV_2023_paper.pdf)
* [Self-improving Multiplane-to-layer Images for Novel View Synthesis](https://openaccess.thecvf.com/content/WACV2023/papers/Solovev_Self-Improving_Multiplane-To-Layer_Images_for_Novel_View_Synthesis_WACV_2023_paper.pdf)<br>:house:[project](https://samsunglabs.github.io/MLI/)

<a name="32"/>

## 32.Continual Learning(持续学习)
* [Continual Learning with Dependency Preserving Hypernetworks](https://arxiv.org/abs/2209.07712)
* [Do Pre-trained Models Benefit Equally in Continual Learning](https://arxiv.org/abs/2210.15701)<br>:star:[code](https://github.com/eric11220/pretrained-models-in-CL)
* [Saliency Guided Experience Packing for Replay in Continual Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Saha_Saliency_Guided_Experience_Packing_for_Replay_in_Continual_Learning_WACV_2023_paper.pdf)

<a name="31"/>

## 31.Deepfake Detection(假象检测)
* [TI2Net: Temporal Identity Inconsistency Network for Deepfake Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_TI2Net_Temporal_Identity_Inconsistency_Network_for_Deepfake_Detection_WACV_2023_paper.pdf)
* 图像伪造
  * [CFL-Net: Image Forgery Localization Using Contrastive Learning](https://arxiv.org/abs/2210.02182)<br>:star:[code](https://github.com/niloy193/CFLNet)

<a name="30"/>

## 30.Reinforcement Learning(强化学习)
* [Switching to Discriminative Image Captioning by Relieving a Bottleneck of Reinforcement Learning](https://arxiv.org/abs/2212.03230)<br>:star:[code](https://github.com/ukyh/switchdisccaption)

<a name="29"/>

## 29.Image Classification(图像分类)
* [Wavelength-Aware 2D Convolutions for Hyperspectral Imaging](https://openaccess.thecvf.com/content/WACV2023/papers/Varga_Wavelength-Aware_2D_Convolutions_for_Hyperspectral_Imaging_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/cogsys-tuebingen/hyve_conv)
* [ML-Decoder: Scalable and Versatile Classification Head](https://openaccess.thecvf.com/content/WACV2023/papers/Ridnik_ML-Decoder_Scalable_and_Versatile_Classification_Head_WACV_2023_paper.pdf)
* [CNN2Graph: Building Graphs for Image Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Trivedy_CNN2Graph_Building_Graphs_for_Image_Classification_WACV_2023_paper.pdf)
* [Token Pooling in Vision Transformers for Image Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Marin_Token_Pooling_in_Vision_Transformers_for_Image_Classification_WACV_2023_paper.pdf)
* [Augmentation by Counterfactual Explanation -Fixing an Overconfident Classifier](https://openaccess.thecvf.com/content/WACV2023/papers/Singla_Augmentation_by_Counterfactual_Explanation_-_Fixing_an_Overconfident_Classifier_WACV_2023_paper.pdf)
* [Treatment Learning Causal Transformer for Noisy Image Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Treatment_Learning_Causal_Transformer_for_Noisy_Image_Classification_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/huckiyang/treatment-causal-transformer)
* 长尾识别
  * [Difficulty-Net: Learning to Predict Difficulty for Long-Tailed Recognition](https://arxiv.org/abs/2209.02960)
* pen-Set Classification
  * [Large-Scale Open-Set Classification Protocols for ImageNet](https://arxiv.org/abs/2210.06789)
* 细粒度分类
  * [SSFE-Net: Self-Supervised Feature Enhancement for Ultra-Fine-Grained Few-Shot Class Incremental Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Pan_SSFE-Net_Self-Supervised_Feature_Enhancement_for_Ultra-Fine-Grained_Few-Shot_Class_Incremental_Learning_WACV_2023_paper.pdf)
* 多标签分类
  * [Spatial Consistency Loss for Training Multi-Label Classifiers From Single-Label Annotations](https://openaccess.thecvf.com/content/WACV2023/papers/Verelst_Spatial_Consistency_Loss_for_Training_Multi-Label_Classifiers_From_Single-Label_Annotations_WACV_2023_paper.pdf)
* 小样本分类
  * [Contrastive Knowledge-Augmented Meta-Learning for Few-Shot Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Subramanyam_Contrastive_Knowledge-Augmented_Meta-Learning_for_Few-Shot_Classification_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Rakshith-2905/CAML) 
  * [CORL: Compositional Representation Learning for Few-Shot Classification](https://openaccess.thecvf.com/content/WACV2023/papers/He_CORL_Compositional_Representation_Learning_for_Few-Shot_Classification_WACV_2023_paper.pdf)
 
<a name="28"/>

## 28.Pose Estimation(姿态估计)
* 6D
  * [CRT-6D: Fast 6D Object Pose Estimation with Cascaded Refinement Transformers](https://arxiv.org/abs/2210.11718)<br>:star:[code](https://github.com/PedroCastro/CRT-6D)
  * [SD-Pose: Structural Discrepancy Aware Category-Level 6D Object Pose Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Li_SD-Pose_Structural_Discrepancy_Aware_Category-Level_6D_Object_Pose_Estimation_WACV_2023_paper.pdf)

<a name="27"/>

## 27.Defect Detection(缺陷检测)

<a name="26"/>

## 26.Dataset\Benchmark(数据集\基准)
* [OpenEarthMap: A Benchmark Dataset for Global High-Resolution Land Cover Mapping](https://arxiv.org/abs/2210.10732)<br>:sunflower:[dataset](https://open-earth-map.org/)
* [IDD-3D: A Dataset for Driving in Unstructured Road Scenes](https://arxiv.org/abs/2210.12878)<br>:sunflower:[dataset](https://github.com/shubham1810/idd3d_kit)
* [Vis2Rec: A Large-Scale Visual Dataset for Visit Recommendation](https://openaccess.thecvf.com/content/WACV2023/papers/Soumm_Vis2Rec_A_Large-Scale_Visual_Dataset_for_Visit_Recommendation_WACV_2023_paper.pdf)<br>:sunflower:[dataset](https://github.com/MSoumm/Vis2Rec)
* 目标检测、分割、跟踪
  * [BURST: A Benchmark for Unifying Object Recognition, Segmentation and Tracking in Video](https://openaccess.thecvf.com/content/WACV2023/papers/Athar_BURST_A_Benchmark_for_Unifying_Object_Recognition_Segmentation_and_Tracking_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Ali2500/BURST-benchmark)

<a name="25"/>

## 25.Image Captioning(图像字幕)
* 人体图像分析
  * [Split To Learn: Gradient Split for Multi-Task Human Image Analysis](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Split_To_Learn_Gradient_Split_for_Multi-Task_Human_Image_Analysis_WACV_2023_paper.pdf)
* 图像字幕
  * [Expert-defined Keywords Improve Interpretability of Retinal Image Captioning](https://openaccess.thecvf.com/content/WACV2023/papers/Wu_Expert-Defined_Keywords_Improve_Interpretability_of_Retinal_Image_Captioning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Jhhuangkay/Expert-defined-Keywords-Improve-Interpretability-of-Retinal-Image-Captioning)
* 视频字幕
  * [Lightweight Video Denoising Using Aggregated Shifted Window Attention](https://openaccess.thecvf.com/content/WACV2023/papers/Lindner_Lightweight_Video_Denoising_Using_Aggregated_Shifted_Window_Attention_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/LLindn/ASwin-Video-Denoising)

<a name="24"/>

## 24.Image Retrieval(图像检索)
* [Boosting vision transformers for image retrieval](https://arxiv.org/abs/2210.11909)<br>:star:[code](https://github.com/dealicious-inc/DToP)
* [Certified Defense for Content Based Image Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Kakizaki_Certified_Defense_for_Content_Based_Image_Retrieval_WACV_2023_paper.pdf)
* [Fashion Image Retrieval with Text Feedback by Additive Attention Compositional Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Tian_Fashion_Image_Retrieval_With_Text_Feedback_by_Additive_Attention_Compositional_WACV_2023_paper.pdf)
* 图像-句子检索
  * [Cross-modal Semantic Enhanced Interaction for Image-Sentence Retrieval](https://arxiv.org/abs/2210.08908)
* 图像-文本检索
  * [Dissecting Deep Metric Learning Losses for Image-Text Retrieval](https://arxiv.org/abs/2210.13188)<br>:star:[code](https://github.com/littleredxh/VSE-Gradient)
  * [NAPReg: Nouns As Proxies Regularization for Semantically Aware Cross-Modal Embeddings](https://openaccess.thecvf.com/content/WACV2023/papers/Jawade_NAPReg_Nouns_As_Proxies_Regularization_for_Semantically_Aware_Cross-Modal_Embeddings_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/bhavinjawade/NAPReq)
* 跨域检索
  * [Contrastive Learning of Semantic Concepts for Open-set Cross-domain Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Contrastive_Learning_of_Semantic_Concepts_for_Open-Set_Cross-Domain_Retrieval_WACV_2023_paper.pdf)

<a name="23"/>

## 23.Autonomous Driving(智能驾驶)
* [IDD-3D: Indian Driving Dataset for 3D Unstructured Road Scenes](https://arxiv.org/abs/2210.12878)<br>:star:[code](https://github.com/shubham1810/idd3d_kit)
* [PP4AV: A Benchmarking Dataset for Privacy-Preserving Autonomous Driving](https://openaccess.thecvf.com/content/WACV2023/papers/Trinh_PP4AV_A_Benchmarking_Dataset_for_Privacy-Preserving_Autonomous_Driving_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/khaclinh/pp4av)
* 车辆重识别
  * [Relation Preserving Triplet Mining for Stabilising the Triplet Loss In re-Identification Systems](https://openaccess.thecvf.com/content/WACV2023/papers/Ghosh_Relation_Preserving_Triplet_Mining_for_Stabilising_the_Triplet_Loss_In_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/adhirajghosh/RPTM_reid)
* 车道线检测
  * [Learning to Detect 3D Lanes by Shape Matching and Embedding](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_Learning_To_Detect_3D_Lanes_by_Shape_Matching_and_Embedding_WACV_2023_paper.pdf)
* 轨迹预测
  * [Robustness of Trajectory Prediction Models Under Map-Based Attacks](https://openaccess.thecvf.com/content/WACV2023/papers/Zheng_Robustness_of_Trajectory_Prediction_Models_Under_Map-Based_Attacks_WACV_2023_paper.pdf)

<a name="22"/>

## 22.Human Action Recognition(人体动作识别与检测)
* 动作识别
  * [Modality Mixer for Multi-modal Action Recognition](https://arxiv.org/abs/2208.11314)
  * [STAR-Transformer: A Spatio-temporal Cross Attention Transformer for Human Action Recognition](https://arxiv.org/abs/2210.07503)
  * [Holistic Interaction Transformer Network for Action Detection](https://arxiv.org/abs/2210.12686)<br>:star:[code](https://github.com/joslefaure/HIT)
  * [Reconstructing Humpty Dumpty: Multi-feature Graph Autoencoder for Open Set Action Recognition](https://arxiv.org/abs/2212.06023)<br>:star:[code](https://github.com/Kitware/graphautoencoder)
  * [DA-AIM: Exploiting Instance-based Mixed Sampling via Auxiliary Source Domain Supervision for Domain-adaptive Action Detection](https://arxiv.org/pdf/2209.15439.pdf)<br>:star:[code](https://github.com/wwwfan628/DA-AIM)
  * [Spatio-Temporal Action Detection Under Large Motion](https://arxiv.org/pdf/2209.02250.pdf)<br>:star:[code](https://github.com/gurkirt/ActionTrackDetectron)
  * [Efficient Skeleton-Based Action Recognition via Joint-Mapping Strategies](https://openaccess.thecvf.com/content/WACV2023/papers/Kang_Efficient_Skeleton-Based_Action_Recognition_via_Joint-Mapping_Strategies_WACV_2023_paper.pdf)
  * [Recur, Attend or Convolve? On Whether Temporal Modeling Matters for Cross-Domain Robustness in Action Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Broome_Recur_Attend_or_Convolve_On_Whether_Temporal_Modeling_Matters_for_WACV_2023_paper.pdf)
  * [Semantics Guided Contrastive Learning of Transformers for Zero-Shot Temporal Activity Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Nag_Semantics_Guided_Contrastive_Learning_of_Transformers_for_Zero-Shot_Temporal_Activity_WACV_2023_paper.pdf)
  * [Adaptive Local-Component-Aware Graph Convolutional Network for One-Shot Skeleton-Based Action Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Zhu_Adaptive_Local-Component-Aware_Graph_Convolutional_Network_for_One-Shot_Skeleton-Based_Action_Recognition_WACV_2023_paper.pdf)
  * [Multi-View Action Recognition using Contrastive Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Shah_Multi-View_Action_Recognition_Using_Contrastive_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/kshah33/ViewCon)
* 时序动作定位
  * [Temporal Feature Enhancement Dilated Convolution Network for Weakly-Supervised Temporal Action Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Zhou_Temporal_Feature_Enhancement_Dilated_Convolution_Network_for_Weakly-Supervised_Temporal_Action_WACV_2023_paper.pdf)
  * [Action-aware Masking Network with Group-based Attention for Temporal Action Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Kang_Action-Aware_Masking_Network_With_Group-Based_Attention_for_Temporal_Action_Localization_WACV_2023_paper.pdf)

<a name="21"/>

## 21.Point Cloud(点云)
* [PointNeuron: 3D Neuron Reconstruction via Geometry and Topology Learning of Point Clouds](https://arxiv.org/abs/2210.08305)
* [Visualizing Global Explanations of Point Cloud DNNs](https://openaccess.thecvf.com/content/WACV2023/papers/Tan_Visualizing_Global_Explanations_of_Point_Cloud_DNNs_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Explain3D/PointCloudAM)
* [RSF: Optimizing Rigid Scene Flow From 3D Point Clouds Without Labels](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_RSF_Optimizing_Rigid_Scene_Flow_From_3D_Point_Clouds_Without_WACV_2023_paper.pdf)
* [Nearest Neighbors Meet Deep Neural Networks for Point Cloud Analysis](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Nearest_Neighbors_Meet_Deep_Neural_Networks_for_Point_Cloud_Analysis_WACV_2023_paper.pdf)
* [Explainability-Aware One Point Attack for Point Cloud Neural Networks](https://openaccess.thecvf.com/content/WACV2023/papers/Tan_Explainability-Aware_One_Point_Attack_for_Point_Cloud_Neural_Networks_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Explain3D/Exp-One-Point-Atk-PC)
* 点云分类
  * [Fractual Projection Forest: Fast and Explainable Point Cloud Classifier](https://openaccess.thecvf.com/content/WACV2023/papers/Tan_Fractual_Projection_Forest_Fast_and_Explainable_Point_Cloud_Classifier_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Explain3D/FracProjForest)
  * [Cross-Modality Feature Fusion Network for Few-Shot 3D Point Cloud Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Cross-Modality_Feature_Fusion_Network_for_Few-Shot_3D_Point_Cloud_Classification_WACV_2023_paper.pdf)
* 点云分割
  * [Sim2real Transfer Learning for Point Cloud Segmentation: An Industrial Application Case on Autonomous Disassembly](https://openaccess.thecvf.com/content/WACV2023/papers/Wu_Sim2real_Transfer_Learning_for_Point_Cloud_Segmentation_An_Industrial_Application_WACV_2023_paper.pdf)
* 点云配准
  * [Overlap-guided Gaussian Mixture Models for Point Cloud Registration](https://arxiv.org/abs/2210.09836)<br>:star:[code](https://github.com/gfmei/ogmm)
  * [SGPCR: Spherical Gaussian Point Cloud Representation and its Application to Object Registration and Retrieval](https://openaccess.thecvf.com/content/WACV2023/papers/Salihu_SGPCR_Spherical_Gaussian_Point_Cloud_Representation_and_Its_Application_To_WACV_2023_paper.pdf)
* 点云重建
  * [PointInverter: Point Cloud Reconstruction and Editing via a Generative Model with Shape Priors](https://arxiv.org/abs/2211.08702)<br>:star:[code](https://github.com/hkust-vgd/point_inverter)
* 3D点云
  * [PIDS: Joint Point Interaction-Dimension Search for 3D Point Cloud](https://arxiv.org/abs/2211.15759)

<a name="20"/>

## 20.Transformer
* [EmbryosFormer: Deformable Transformer and Collaborative Encoding-Decoding for Embryos Stage Development Classification](https://arxiv.org/abs/2210.04615)<br>:star:[code](https://github.com/UARK-AICV/Embryos)
* [Delving into Masked Autoencoders for Multi-Label Thorax Disease Classification](https://arxiv.org/abs/2210.12843)<br>:star:[code](https://github.com/lambert-x/Medical_MAE)
* [Accumulated Trivial Attention Matters in Vision Transformers on Small Datasets](https://arxiv.org/abs/2210.12333)<br>:star:[code](https://github.com/xiangyu8/SATA)
* [Couplformer: Rethinking Vision Transformer With Coupling Attention](https://openaccess.thecvf.com/content/WACV2023/papers/Lan_Couplformer_Rethinking_Vision_Transformer_With_Coupling_Attention_WACV_2023_paper.pdf)
* [Trans4Map: Revisiting Holistic Bird's-Eye-View Mapping From Egocentric Images to Allocentric Semantics With Vision Transformers](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Trans4Map_Revisiting_Holistic_Birds-Eye-View_Mapping_From_Egocentric_Images_to_Allocentric_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/jamycheung/Trans4Map)
* [PatchDropout: Economizing Vision Transformers Using Patch Dropout](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_PatchDropout_Economizing_Vision_Transformers_Using_Patch_Dropout_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/yueliukth/PatchDropout)
* [OutfitTransformer: Learning Outfit Representations for Fashion Recommendation](https://openaccess.thecvf.com/content/WACV2023/papers/Sarkar_OutfitTransformer_Learning_Outfit_Representations_for_Fashion_Recommendation_WACV_2023_paper.pdf)
* [Discrete Cosin TransFormer: Image Modeling From Frequency Domain](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Discrete_Cosin_TransFormer_Image_Modeling_From_Frequency_Domain_WACV_2023_paper.pdf)

<a name="19"/>

## 19.Model Compression\Knowledge Distillation\Pruning(模型压缩\知识蒸馏\剪枝)
* 剪枝
  * [Pushing the Efficiency Limit Using Structured Sparse Convolutions](https://arxiv.org/abs/2210.12818)<br>:star:[code](https://github.com/vkvermaa/SSC)
  * [Calibrating Deep Neural Networks using Explicit Regularisation and Dynamic Data Pruning](https://arxiv.org/abs/2212.10005)
* 知识蒸馏
  * [Collaborative Multi-Teacher Knowledge Distillation for Learning Low Bit-width Deep Neural Networks](https://arxiv.org/abs/2210.16103)
  * [Understanding the Role of Mixup in Knowledge Distillation: \\An Empirical Study](https://arxiv.org/abs/2211.03946)<br>:star:[code](https://github.com/hchoi71/MIX-KD)
  * [Understanding the Role of Mixup in Knowledge Distillation:An Empirical Study](https://openaccess.thecvf.com/content/WACV2023/papers/Choi_Understanding_the_Role_of_Mixup_in_Knowledge_Distillation_An_Empirical_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/hchoi71/MIX-KD)
* 自我蒸馏
  * [SSSD: Self-Supervised Self Distillation](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_SSSD_Self-Supervised_Self_Distillation_WACV_2023_paper.pdf)

<a name="18"/>

## 18.NAS(神经架构搜索)
* [Revisiting Training-free NAS Metrics: An Efficient Training-based Method](https://arxiv.org/abs/2211.08666)<br>:star:[code](https://github.com/taoyang1122/Revisit_TrainingFree_NAS)
* [SVD-NAS: Coupling Low-Rank Approximation and Neural Architecture Search](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_SVD-NAS_Coupling_Low-Rank_Approximation_and_Neural_Architecture_Search_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Yu-Zhewen/SVD-NAS)
* [FreeREA: Training-Free Evolution-based Architecture Search](https://openaccess.thecvf.com/content/WACV2023/papers/Cavagnero_FreeREA_Training-Free_Evolution-Based_Architecture_Search_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/NiccoloCavagnero/FreeREA)

<a name="17"/>

## 17.OCR(文本检测)
* [OCR-VQGAN: Taming Text-within-Image Generation](https://arxiv.org/abs/2210.11248)<br>:star:[code](https://github.com/joanrod/ocr-vqgan)
* [Efficient few-shot learning for pixel-precise handwritten document layout analysis](https://arxiv.org/abs/2210.15570)
* [D-Extract: Extracting Dimensional Attributes From Product Images](https://openaccess.thecvf.com/content/WACV2023/papers/Ghosh_D-Extract_Extracting_Dimensional_Attributes_From_Product_Images_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/amazon-science/dimension-extraction-dataset)
* 文本识别
  * [Seq-UPS: Sequential Uncertainty-aware Pseudo-label Selection for Semi-Supervised Text Recognition](https://arxiv.org/abs/2209.00641)
* 表格检测
  * [LayerDoc: Layer-Wise Extraction of Spatial Hierarchical Structure in Visually-Rich Documents](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_LayerDoc_Layer-Wise_Extraction_of_Spatial_Hierarchical_Structure_in_Visually-Rich_Documents_WACV_2023_paper.pdf)
* LOGO检测
  * [Image-Text Pre-Training for Logo Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Hubenthal_Image-Text_Pre-Training_for_Logo_Recognition_WACV_2023_paper.pdf)
* 文档检测
  * [One-Shot Doc Snippet Detection: Powering Search in Document Beyond Text](https://openaccess.thecvf.com/content/WACV2023/papers/Java_One-Shot_Doc_Snippet_Detection_Powering_Search_in_Document_Beyond_Text_WACV_2023_paper.pdf)

<a name="16"/>

## 16.Super-Resolution(超分辨率)
* [Single Image Super-Resolution via a Dual Interactive Implicit Neural Network](https://arxiv.org/abs/2210.12593)
* [HIME: Efficient Headshot Image Super-Resolution with Multiple Exemplars](https://arxiv.org/abs/2203.14863)
* [Deep Model-Based Super-Resolution With Non-Uniform Blur](https://openaccess.thecvf.com/content/WACV2023/papers/Laroche_Deep_Model-Based_Super-Resolution_With_Non-Uniform_Blur_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/claroche-r/DMBSR)
* [Kernel-Aware Burst Blind Super-Resolution](https://openaccess.thecvf.com/content/WACV2023/papers/Lian_Kernel-Aware_Burst_Blind_Super-Resolution_WACV_2023_paper.pdf)
* [Enriched CNN-Transformer Feature Aggregation Networks for Super-Resolution](https://openaccess.thecvf.com/content/WACV2023/papers/Yoo_Enriched_CNN-Transformer_Feature_Aggregation_Networks_for_Super-Resolution_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/jinsuyoo/act)
* 视频超分辨率
  * [Cross-Resolution Flow Propagation for Foveated Video Super-Resolution](https://arxiv.org/abs/2212.13525)<br>:star:[code](https://github.com/eugenelet/CRFP)
  * [Fast Online Video Super-Resolution With Deformable Attention Pyramid](https://openaccess.thecvf.com/content/WACV2023/papers/Fuoli_Fast_Online_Video_Super-Resolution_With_Deformable_Attention_Pyramid_WACV_2023_paper.pdf)
  * [Efficient Reference-based Video Super-Resolution (ERVSR):Single Reference Image Is All You Need](https://openaccess.thecvf.com/content/WACV2023/papers/Kim_Efficient_Reference-Based_Video_Super-Resolution_ERVSR_Single_Reference_Image_Is_All_WACV_2023_paper.pdf)(https://github.com/haewonc/ERVSR)

<a name="15"/>

## 15.Image Synthesis(图像合成)
* [One-Shot Synthesis of Images and Segmentation Masks](https://arxiv.org/abs/2209.07547)<br>:star:[code](https://github.com/boschresearch/one-shot-synthesis)
* [Style-Guided Inference of Transformer for High-resolution Image Synthesis](https://arxiv.org/abs/2210.05533)
* [Evaluating Generative Networks Using Gaussian Mixtures of Image Features](https://openaccess.thecvf.com/content/WACV2023/papers/Luzi_Evaluating_Generative_Networks_Using_Gaussian_Mixtures_of_Image_Features_WACV_2023_paper.pdf)
* [More Control for Free! Image Synthesis with Semantic Diffusion Guidance](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_More_Control_for_Free_Image_Synthesis_With_Semantic_Diffusion_Guidance_WACV_2023_paper.pdf)
* 图像生成
  * [Adaptively-Realistic Image Generation from Stroke and Sketch with Diffusion Model](https://arxiv.org/abs/2208.12675)<br>:star:[code](https://github.com/cyj407/DiSS):house:[project](https://cyj407.github.io/DiSS/)
  * [Spatially Multi-Conditional Image Generation](https://openaccess.thecvf.com/content/WACV2023/papers/Popovic_Spatially_Multi-Conditional_Image_Generation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/96ritika/TLAM)
* 文本-图像合成
  * [Arbitrary Style Guidance for Enhanced Diffusion-Based Text-to-Image Generation](https://arxiv.org/abs/2211.07751)<br>:star:[code](https://github.com/openai/glide-text2im)
* 文字引导的图像操作
  * [Interactive Image Manipulation with Complex Text Instructions](https://arxiv.org/abs/2211.15352) 
 
<a name="14"/>

## 14.Un\Self\Semi-Supervised Learning(无\自\半监督学习)
* 自监督
  * [Self-Supervised Pyramid Representation Learning for Multi-Label Visual Analysis and Beyond](https://arxiv.org/abs/2208.14439)<br>:star:[code](https://github.com/WesleyHsieh0806/SS-PRL)
  * [FUSSL: Fuzzy Uncertain Self Supervised Learning](https://arxiv.org/abs/2210.15818)
  * [Self-Supervised Correspondence Estimation via Multiview Registration](https://arxiv.org/abs/2212.03236)<br>:house:[project](https://mbanani.github.io/syncmatch/)
  * [Similarity Contrastive Estimation for Image and Video Soft Contrastive Self-Supervised Learning](https://arxiv.org/abs/2212.11187)
  * [Self-Supervised Relative Pose With Homography Model-Fitting in the Loop](https://openaccess.thecvf.com/content/WACV2023/papers/Muller_Self-Supervised_Relative_Pose_With_Homography_Model-Fitting_in_the_Loop_WACV_2023_paper.pdf)
  * [Self-Distilled Self-supervised Representation Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Jang_Self-Distilled_Self-Supervised_Representation_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/hagiss/SDSSL)
  * [Multi-Level Contrastive Learning for Self-Supervised Vision Transformers](https://openaccess.thecvf.com/content/WACV2023/papers/Mo_Multi-Level_Contrastive_Learning_for_Self-Supervised_Vision_Transformers_WACV_2023_paper.pdf)
  * [Self-Supervised Distilled Learning for Multi-modal Misinformation Identification](https://openaccess.thecvf.com/content/WACV2023/papers/Mu_Self-Supervised_Distilled_Learning_for_Multi-Modal_Misinformation_Identification_WACV_2023_paper.pdf)
* 半监督
  * [Class-Level Confidence Based 3D Semi-Supervised Learning](https://arxiv.org/abs/2210.10138)
  * [Dynamic Re-Weighting for Long-Tailed Semi-Supervised Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Peng_Dynamic_Re-Weighting_for_Long-Tailed_Semi-Supervised_Learning_WACV_2023_paper.pdf)
  * [Semantics-Depth-Symbiosis: Deeply Coupled Semi-Supervised Learning of Semantics and Depth](https://openaccess.thecvf.com/content/WACV2023/papers/Bansal_Semantics-Depth-Symbiosis_Deeply_Coupled_Semi-Supervised_Learning_of_Semantics_and_Depth_WACV_2023_paper.pdf)

<a name="13"/>

## 13.Image Segmentation(图像分割)
* [Image Segmentation-based Unsupervised Multiple Objects Discovery](https://arxiv.org/abs/2212.10124)
* [WSNet: Towards An Effective Method for Wound Image Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Oota_WSNet_Towards_an_Effective_Method_for_Wound_Image_Segmentation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/subbareddy248/WSNET)
* VOS
  * [Unsupervised Video Object Segmentation via Prototype Memory Network](https://arxiv.org/abs/2209.03712)
  * [Treating Motion as Option To Reduce Motion Dependency in Unsupervised Video Object Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Cho_Treating_Motion_as_Option_To_Reduce_Motion_Dependency_in_Unsupervised_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/suhwan-cho/TMO)
* VSS
  * [Domain Adaptive Video Semantic Segmentation via Cross-Domain Moving Object Mixing](https://arxiv.org/abs/2211.02307)
  * [Human-in-the-Loop Video Semantic Segmentation Auto-Annotation](https://openaccess.thecvf.com/content/WACV2023/papers/Qiao_Human-in-the-Loop_Video_Semantic_Segmentation_Auto-Annotation_WACV_2023_paper.pdf)
* 语义分割
  * [Attribution-aware Weight Transfer: A Warm-Start Initialization for Class-Incremental Semantic Segmentation](https://arxiv.org/abs/2210.07207)<br>:star:[code](https://github.com/dfki-av/AWT-for-CISS)
  * [Full Contextual Attention for Multi-resolution Transformers in Semantic Segmentation](https://arxiv.org/abs/2212.07890)
  * [Urban Scene Semantic Segmentation with Low-Cost Coarse Annotation](https://arxiv.org/abs/2212.07911)
  * [LoopDA: Constructing Self-loops to Adapt Nighttime Semantic Segmentation](https://arxiv.org/abs/2211.11870)<br>:star:[code](https://github.com/fy-vision/LoopDA)
  * [Empirical Generalization Study: Unsupervised Domain Adaptation vs. Domain Generalization Methods for Semantic Segmentation in the Wild](https://openaccess.thecvf.com/content/WACV2023/papers/Piva_Empirical_Generalization_Study_Unsupervised_Domain_Adaptation_vs._Domain_Generalization_Methods_WACV_2023_paper.pdf)
  * [Reducing Annotation Effort by Identifying and Labeling Contextually Diverse Classes for Semantic Segmentation Under Domain Shift](https://arxiv.org/abs/2210.06749)<br>:star:[code](https://github.com/sharat29ag/contextual_class)
  * [Cooperative Self-Training for Multi-Target Adaptive Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Cooperative_Self-Training_for_Multi-Target_Adaptive_Semantic_Segmentation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Mael-zys/CoaST)
  * [Refign: Align and Refine for Adaptation of Semantic Segmentation to Adverse Conditions](https://openaccess.thecvf.com/content/WACV2023/papers/Bruggemann_Refign_Align_and_Refine_for_Adaptation_of_Semantic_Segmentation_to_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/brdav/refign)
  * [BEVSegFormer: Bird's Eye View Semantic Segmentation From Arbitrary Camera Rigs](https://openaccess.thecvf.com/content/WACV2023/papers/Peng_BEVSegFormer_Birds_Eye_View_Semantic_Segmentation_From_Arbitrary_Camera_Rigs_WACV_2023_paper.pdf)
  * [ProtoSeg: Interpretable Semantic Segmentation with Prototypical Parts](https://openaccess.thecvf.com/content/WACV2023/papers/Sacha_ProtoSeg_Interpretable_Semantic_Segmentation_With_Prototypical_Parts_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/gmum/proto-segmentation)
  * [Complementary Bi-directional Feature Compression for Indoor 360° Semantic Segmentation with Self-distillation](https://openaccess.thecvf.com/content/WACV2023/papers/Zheng_Complementary_Bi-Directional_Feature_Compression_for_Indoor_360deg_Semantic_Segmentation_With_WACV_2023_paper.pdf)
  * 半监督语义分割
    * [Pruning-Guided Curriculum Learning for Semi-Supervised Semantic Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Kong_Pruning-Guided_Curriculum_Learning_for_Semi-Supervised_Semantic_Segmentation_WACV_2023_paper.pdf)
  * Multi-class part parsing
    * [AFPSNet: Multi-Class Part Parsing Based on Scaled Attention and Feature Fusion](https://openaccess.thecvf.com/content/WACV2023/papers/Alsudays_AFPSNet_Multi-Class_Part_Parsing_Based_on_Scaled_Attention_and_Feature_WACV_2023_paper.pdf)
* BEV segmentation
  * [X-Align: Cross-Modal Cross-View Alignment for Bird's-Eye-View Segmentation](https://arxiv.org/abs/2210.06778)<br>:star:[code](https://github.com/robot-learning-freiburg/PanopticBEV)
* 全景分割
  * [MonoDVPS: A Self-Supervised Monocular Depth Estimation Approach to Depth-aware Video Panoptic Segmentation](https://arxiv.org/abs/2210.07577)
  * [PRN: Panoptic Refinement Network](https://openaccess.thecvf.com/content/WACV2023/papers/Sun_PRN_Panoptic_Refinement_Network_WACV_2023_paper.pdf)
  * [Intra-Batch Supervision for Panoptic Segmentation on High-Resolution Images](https://openaccess.thecvf.com/content/WACV2023/papers/de_Geus_Intra-Batch_Supervision_for_Panoptic_Segmentation_on_High-Resolution_Images_WACV_2023_paper.pdf)<br>:house:[project](https://ddegeus.github.io/intra-batch-supervision/)
* 实例分割
  * [From Forks to Forceps: A New Framework for Instance Segmentation of Surgical Instruments](https://arxiv.org/abs/2211.16200)
  * [CellTranspose: Few-shot Domain Adaptation for Cellular Instance Segmentation](https://arxiv.org/abs/2212.14121)
  * [Weakly Supervised Cell-Instance Segmentation With Two Types of Weak Labels by Single Instance Pasting](https://openaccess.thecvf.com/content/WACV2023/papers/Nishimura_Weakly_Supervised_Cell-Instance_Segmentation_With_Two_Types_of_Weak_Labels_WACV_2023_paper.pdf)
  * [Self-Supervised Learning With Masked Image Modeling for Teeth Numbering, Detection of Dental Restorations, and Instance Segmentation in Dental Panoramic Radiographs](https://openaccess.thecvf.com/content/WACV2023/papers/Almalki_Self-Supervised_Learning_With_Masked_Image_Modeling_for_Teeth_Numbering_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/AmaniHAlmalki/DentalMIM)
  * [Weakly-Supervised Point Cloud Instance Segmentation With Geometric Priors](https://openaccess.thecvf.com/content/WACV2023/papers/Du_Weakly-Supervised_Point_Cloud_Instance_Segmentation_With_Geometric_Priors_WACV_2023_paper.pdf)
  * [NeuralBF: Neural Bilateral Filtering for Top-down Instance Segmentation on Point Clouds](https://openaccess.thecvf.com/content/WACV2023/papers/Sun_NeuralBF_Neural_Bilateral_Filtering_for_Top-Down_Instance_Segmentation_on_Point_WACV_2023_paper.pdf)<br>:house:[project](https://neuralbf.github.io/)
* 小样本分割
  * [Elimination of Non-Novel Segments at Multi-Scale for Few-Shot Segmentation](https://arxiv.org/abs/2211.02300)
* 叶子疾病分割
  * [AnoLeaf: Unsupervised Leaf Disease Segmentation via Structurally Robust Generative Inpainting](https://openaccess.thecvf.com/content/WACV2023/papers/Bhugra_AnoLeaf_Unsupervised_Leaf_Disease_Segmentation_via_Structurally_Robust_Generative_Inpainting_WACV_2023_paper.pdf)
* 细胞分割
  * [Knowing What to Label for Few Shot Microscopy Image Cell Segmentation](https://arxiv.org/abs/2211.10244)<br>:star:[code](https://github.com/Yussef93/KnowWhatToLabel/)
* 目标分割
  * [Unsupervised 4D LiDAR Moving Object Segmentation in Stationary Settings with Multivariate Occupancy Time Series](https://arxiv.org/abs/2212.14750)
* 抠图
  * [Video Object Matting via Hierarchical Space-Time Semantic Guidance](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_Video_Object_Matting_via_Hierarchical_Space-Time_Semantic_Guidance_WACV_2023_paper.pdf)

<a name="12"/>

## 12.One\Few-Shot Learning or Domain Adaptation\Generalization\Shift(单\小样本学习 or 域适应\泛化\偏移)
* 域适应
  * [Self-Distillation for Unsupervised 3D Domain Adaptation](https://arxiv.org/abs/2210.08226)<br>:house:[project](https://cvlab-unibo.github.io/FeatureDistillation/)
  * [CoNMix for Source-free Single and Multi-target Domain Adaptation](https://arxiv.org/abs/2211.03876)<br>:star:[code](https://github.com/vcl-iisc/CoNMix):house:[project](https://sites.google.com/view/conmix-vcl)
  * [Learning Classifiers of Prototypes and Reciprocal Points for Universal Domain Adaptation](https://arxiv.org/abs/2212.08355)
  * [Select, Label, and Mix: Learning Discriminative Invariant Feature Representations for Partial Domain Adaptation](https://openaccess.thecvf.com/content/WACV2023/papers/Sahoo_Select_Label_and_Mix_Learning_Discriminative_Invariant_Feature_Representations_for_WACV_2023_paper.pdf)<br>:house:[project](https://cvir.github.io/projects/slm)
  * [TVT: Transferable Vision Transformer for Unsupervised Domain Adaptation](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_TVT_Transferable_Vision_Transformer_for_Unsupervised_Domain_Adaptation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/uta-smile/TVT)
  * [Backprop Induced Feature Weighting for Adversarial Domain Adaptation with Iterative Label Distribution Alignment](https://openaccess.thecvf.com/content/WACV2023/papers/Westfechtel_Backprop_Induced_Feature_Weighting_for_Adversarial_Domain_Adaptation_With_Iterative_WACV_2023_paper.pdf)
  * [SALAD : Source-free Active Label-Agnostic Domain Adaptation for Classification, Segmentation and Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Kothandaraman_SALAD_Source-Free_Active_Label-Agnostic_Domain_Adaptation_for_Classification_Segmentation_and_WACV_2023_paper.pdf)
  * 半监督域适应
    * [Semi-Supervised Domain Adaptation with Auto-Encoder via Simultaneous Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Semi-Supervised_Domain_Adaptation_With_Auto-Encoder_via_Simultaneous_Learning_WACV_2023_paper.pdf)
* 域泛化
  * [Intra-Source Style Augmentation for Improved Domain Generalization](https://arxiv.org/abs/2210.10175)
  * [Center-aware Adversarial Augmentation for Single Domain Generalization](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Center-Aware_Adversarial_Augmentation_for_Single_Domain_Generalization_WACV_2023_paper.pdf)
* 零样本
  * [Learning Attention Propagation for Compositional Zero-Shot Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Khan_Learning_Attention_Propagation_for_Compositional_Zero-Shot_Learning_WACV_2023_paper.pdf)
* 小样本
  * [Aggregating Bilateral Attention for Few-Shot Instance Localization](https://openaccess.thecvf.com/content/WACV2023/papers/Hsieh_Aggregating_Bilateral_Attention_for_Few-Shot_Instance_Localization_WACV_2023_paper.pdf)
  * [HyperShot: Few-Shot Learning by Kernel HyperNetworks](https://openaccess.thecvf.com/content/WACV2023/papers/Sendera_HyperShot_Few-Shot_Learning_by_Kernel_HyperNetworks_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/gmum/few-shot-hypernets-public)
  * [Few-Shot Learning of Compact Models via Task-Specific Meta Distillation](https://openaccess.thecvf.com/content/WACV2023/papers/Wu_Few-Shot_Learning_of_Compact_Models_via_Task-Specific_Meta_Distillation_WACV_2023_paper.pdf)

<a name="11"/>

## 11.Face(人脸)
* [My Face My Choice: Privacy Enhancing Deepfakes for Social Media Anonymization](https://arxiv.org/abs/2211.01361)
* [Improving Deep Facial Phenotyping for Ultra-rare Disorder Verification Using Model Ensembles](https://openaccess.thecvf.com/content/WACV2023/papers/Hustinx_Improving_Deep_Facial_Phenotyping_for_Ultra-Rare_Disorder_Verification_Using_Model_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/igsb/GestaltMatcher-Arc)
* 读唇术
  * [Towards MOOCs for Lip Reading: Using Synthetic Talking Heads to Train Humans in Lipreading at Scale](https://arxiv.org/abs/2208.09796)
* 3D人脸
  * [Controllable 3D Generative Adversarial Face Model via Disentangling Shape and Appearance](https://openaccess.thecvf.com/content/WACV2023/papers/Taherkhani_Controllable_3D_Generative_Adversarial_Face_Model_via_Disentangling_Shape_and_WACV_2023_paper.pdf)<br>:house:[project](https://aashishrai3799.github.io/3DFaceCAM/)
* 人脸识别
  * [DigiFace-1M: 1 Million Digital Face Images for Face Recognition](https://arxiv.org/abs/2210.02579)<br>:star:[code](https://github.com/microsoft/DigiFace1M)
  * [CAST: Conditional Attribute Subsampling Toolkit for Fine-Grained Evaluation](https://openaccess.thecvf.com/content/WACV2023/papers/Robbins_CAST_Conditional_Attribute_Subsampling_Toolkit_for_Fine-Grained_Evaluation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/WesRobbins/CAST)
  * [Unifying Margin-Based Softmax Losses in Face Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Unifying_Margin-Based_Softmax_Losses_in_Face_Recognition_WACV_2023_paper.pdf)
  * [Harnessing Unrecognizable Faces for Improving Face Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Harnessing_Unrecognizable_Faces_for_Improving_Face_Recognition_WACV_2023_paper.pdf)
* 人脸修复/恢复
  * [Nested Deformable Multi-head Attention for Facial Image Inpainting](https://openaccess.thecvf.com/content/WACV2023/papers/Phutke_Nested_Deformable_Multi-Head_Attention_for_Facial_Image_Inpainting_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/shrutiphutke/NDMA_Facial_Inpainting)
  * [AT-DDPM: Restoring Faces degraded by Atmospheric Turbulence using Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2208.11284)
* 人脸交换
  * [FaceOff: A Video-to-Video Face Swapping System](https://arxiv.org/abs/2208.09788)
  * [FaceDancer: Pose- and Occlusion-Aware High Fidelity Face Swapping](https://openaccess.thecvf.com/content/WACV2023/papers/Rosberg_FaceDancer_Pose-_and_Occlusion-Aware_High_Fidelity_Face_Swapping_WACV_2023_paper.pdf)
  * [FastSwap: A Lightweight One-Stage Framework for Real-Time Face Swapping](https://openaccess.thecvf.com/content/WACV2023/papers/Yoo_FastSwap_A_Lightweight_One-Stage_Framework_for_Real-Time_Face_Swapping_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/sahngmin/fastswap)
* 人脸表情识别
  * [Uncertainty-aware Label Distribution Learning for Facial Expression Recognition](https://arxiv.org/abs/2209.10448)<br>:star:[code](https://github.com/minhnhatvt/label-distribution-learning-fer-tf)
  * 微表情识别
    * [RNAS-MER: A Refined Neural Architecture Search With Hybrid Spatiotemporal Operations for Micro-Expression Recognition](https://openaccess.thecvf.com/content/WACV2023/papers/Verma_RNAS-MER_A_Refined_Neural_Architecture_Search_With_Hybrid_Spatiotemporal_Operations_WACV_2023_paper.pdf)
* 人脸重现
  * [Audio-Visual Face Reenactment](https://arxiv.org/abs/2210.02755)<br>:house:[project](http://cvit.iiit.ac.in/research/projects/cvit-projects/avfr)
* 人脸命名
  * [Weakly Supervised Face Naming with Symmetry-Enhanced Contrastive Loss](https://arxiv.org/abs/2210.08957)
* 人脸重建
  * [ReEnFP: Detail-Preserving Face Reconstruction by Encoding Facial Priors](https://openaccess.thecvf.com/content/WACV2023/papers/Sun_ReEnFP_Detail-Preserving_Face_Reconstruction_by_Encoding_Facial_Priors_WACV_2023_paper.pdf)
* 人脸合成
  * [Scaling Neural Face Synthesis to High FPS and Low Latency by Neural Caching](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_Scaling_Neural_Face_Synthesis_to_High_FPS_and_Low_Latency_WACV_2023_paper.pdf)
* Deepfake
  * [Proactive Deepfake Defence via Identity Watermarking](https://openaccess.thecvf.com/content/WACV2023/papers/Zhao_Proactive_Deepfake_Defence_via_Identity_Watermarking_WACV_2023_paper.pdf)
* Facial Action Unit Detection
  * [FAN-Trans: Online Knowledge Distillation for Facial Action Unit Detection](https://arxiv.org/abs/2211.06143) 
* 人脸质量评估
  * [IFQA: Interpretable Face Quality Assessment](https://arxiv.org/abs/2211.07077)<br>:star:[code](https://github.com/VCLLab/IFQA) 
* 活体检测
* [Domain Invariant Vision Transformer Learning for Face Anti-Spoofing](https://openaccess.thecvf.com/content/WACV2023/papers/Liao_Domain_Invariant_Vision_Transformer_Learning_for_Face_Anti-Spoofing_WACV_2023_paper.pdf)
* 基于表情的脸部皱纹合成
  * [Mesh-Tension Driven Expression-Based Wrinkles for Synthetic Faces](https://arxiv.org/abs/2210.03529)
* 文字和图像引导的3D头像生成
  * [Text and Image Guided 3D Avatar Generation and Manipulation](https://openaccess.thecvf.com/content/WACV2023/papers/Canfes_Text_and_Image_Guided_3D_Avatar_Generation_and_Manipulation_WACV_2023_paper.pdf) 
 
 
<a name="10"/>

## 10.Adversarial Learning(对抗学习)
* [Leveraging Local Patch Differences in Multi-Object Scenes for Generative Adversarial Attacks](https://arxiv.org/abs/2209.09883)
* [Inducing Data Amplification Using Auxiliary Datasets in Adversarial Training](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_Inducing_Data_Amplification_Using_Auxiliary_Datasets_in_Adversarial_Training_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Saehyung-Lee/BiaMAT)
* [FLOAT: Fast Learnable Once-for-All Adversarial Training for Tunable Trade-off between Accuracy and Robustness](https://openaccess.thecvf.com/content/WACV2023/papers/Kundu_FLOAT_Fast_Learnable_Once-for-All_Adversarial_Training_for_Tunable_Trade-Off_Between_WACV_2023_paper.pdf)
* [Adversarial robustness in discontinuous spaces via alternating sampling & descent](https://openaccess.thecvf.com/content/WACV2023/papers/Venkatesh_Adversarial_Robustness_in_Discontinuous_Spaces_via_Alternating_Sampling__Descent_WACV_2023_paper.pdf)

<a name="9"/>

## 9.Remote Sensing\Satellite Image(遥感\卫星图像)
* RS
  * [Handling Image and Label Resolution Mismatch in Remote Sensing](https://arxiv.org/abs/2211.15790)
  * [GAF-Net: Improving the Performance of Remote Sensing Image Fusion Using Novel Global Self and Cross Attention Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Jha_GAF-Net_Improving_the_Performance_of_Remote_Sensing_Image_Fusion_Using_WACV_2023_paper.pdf)
* 变化检测
  * [Self-Pair: Synthesizing Changes from Single Source for Object Change Detection in Remote Sensing Imagery](https://arxiv.org/abs/2212.10236)<br>:star:[code](https://github.com/seominseok0429/Self-Pair-for-Change-Detection)
* 航空图像检测
  * [ARUBA: An Architecture-Agnostic Balanced Loss for Aerial Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Sairam_ARUBA_An_Architecture-Agnostic_Balanced_Loss_for_Aerial_Object_Detection_WACV_2023_paper.pdf)
  * [Transformers For Recognition In Overhead Imagery: A Reality Check](https://openaccess.thecvf.com/content/WACV2023/papers/Luzi_Transformers_for_Recognition_in_Overhead_Imagery_A_Reality_Check_WACV_2023_paper.pdf)
* 航空图像分割
  * [Semantic Segmentation in Aerial Imagery Using Multi-level Contrastive Learning with Local Consistency](https://openaccess.thecvf.com/content/WACV2023/papers/Tang_Semantic_Segmentation_in_Aerial_Imagery_Using_Multi-Level_Contrastive_Learning_With_WACV_2023_paper.pdf)
* 国际边界检测
  * [Computer Vision for International Border Legibility](https://openaccess.thecvf.com/content/WACV2023/papers/Ortega_Computer_Vision_for_International_Border_Legibility_WACV_2023_paper.pdf)

<a name="8"/>

## 8.Image Processing(图像处理)
* 图像恢复
  * [Large-to-small Image Resolution Asymmetry in Deep Metric Learning](https://arxiv.org/abs/2210.05463)<br>:star:[code](https://github.com/pavelsuma/raml)
  * [DSTrans: Dual-Stream Transformer for Hyperspectral Image Restoration](https://openaccess.thecvf.com/content/WACV2023/papers/Yu_DSTrans_Dual-Stream_Transformer_for_Hyperspectral_Image_Restoration_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/yudadabing/Dual-Stream-Transformer-for-Hyperspectral-Image-Restoration)
  * [Semi-Supervised Learning for Low-light Image Restoration through Quality Assisted Pseudo-Labeling](https://openaccess.thecvf.com/content/WACV2023/papers/Malik_Semi-Supervised_Learning_for_Low-Light_Image_Restoration_Through_Quality_Assisted_Pseudo-Labeling_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/sameerIISc/SSL-LLR)
* 图像修复
  * [GeoFill: Reference-Based Image Inpainting With Better Geometric Understanding](https://openaccess.thecvf.com/content/WACV2023/papers/Zhao_GeoFill_Reference-Based_Image_Inpainting_With_Better_Geometric_Understanding_WACV_2023_paper.pdf)
  * [Keys to Better Image Inpainting: Structure and Texture Go Hand in Hand](https://openaccess.thecvf.com/content/WACV2023/papers/Jain_Keys_To_Better_Image_Inpainting_Structure_and_Texture_Go_Hand_WACV_2023_paper.pdf)<br>:house:[project](https://praeclarumjj3.github.io/fcf-inpainting/)
* 图像增强
  * [Perceptual Image Enhancement for Smartphone Real-Time Applications](https://arxiv.org/abs/2210.13552)<br>:star:[code](https://github.com/mv-lab/AISP)
  * [Robust Real-World Image Enhancement Based on Multi-Exposure LDR Images](https://openaccess.thecvf.com/content/WACV2023/papers/Ren_Robust_Real-World_Image_Enhancement_Based_on_Multi-Exposure_LDR_Images_WACV_2023_paper.pdf)
  * [End-to-End Single-Frame Image Signal Processing for High Dynamic Range Scenes](https://openaccess.thecvf.com/content/WACV2023/papers/Dinh_End-to-End_Single-Frame_Image_Signal_Processing_for_High_Dynamic_Range_Scenes_WACV_2023_paper.pdf)
  * [PSENet: Progressive Self-Enhancement Network for Unsupervised Extreme-Light Image Enhancement](https://openaccess.thecvf.com/content/WACV2023/papers/Nguyen_PSENet_Progressive_Self-Enhancement_Network_for_Unsupervised_Extreme-Light_Image_Enhancement_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/VinAIResearch/PSENet-Image-Enhancement)
* 图像着色
  * [Guiding Users to Where to Give Color Hints for Efficient Interactive Sketch Colorization via Unsupervised Region Prioritization](https://arxiv.org/abs/2210.14270)
  * [Generative Colorization of Structured Mobile Web Pages](https://arxiv.org/abs/2212.11541)<br>:star:[code](https://github.com/CyberAgentAILab/webcolor)
  * [iColoriT: Towards Propagating Local Hints to the Right Region in Interactive Colorization by Leveraging Vision Transformer](https://openaccess.thecvf.com/content/WACV2023/papers/Yun_iColoriT_Towards_Propagating_Local_Hints_to_the_Right_Region_in_WACV_2023_paper.pdf)<br>:house:[project](https://pmh9960.github.io/research/iColoriT/)
* 图像补全
  * [An Unified Framework for Language Guided Image Completion](https://openaccess.thecvf.com/content/WACV2023/papers/Kim_An_Unified_Framework_for_Language_Guided_Image_Completion_WACV_2023_paper.pdf)
* 图像重新缩放
  * [Effective Invertible Arbitrary Image Rescaling](https://openaccess.thecvf.com/content/WACV2023/papers/Pan_Effective_Invertible_Arbitrary_Image_Rescaling_WACV_2023_paper.pdf)
* HDR重构
  * [Single-Image HDR Reconstruction by Multi-Exposure Generation](https://arxiv.org/abs/2210.15897)<br>:star:[code](https://github.com/VinAIResearch/single_image_hdr)
* 去噪
  * [On the Importance of Denoising When Learning To Compress Images](https://openaccess.thecvf.com/content/WACV2023/papers/Brummer_On_the_Importance_of_Denoising_When_Learning_To_Compress_Images_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/trougnouf/compression) 
  * [Self Supervised Low Dose Computed Tomography Image Denoising Using Invertible Network Exploiting Inter Slice Congruence](https://openaccess.thecvf.com/content/WACV2023/papers/Bera_Self_Supervised_Low_Dose_Computed_Tomography_Image_Denoising_Using_Invertible_WACV_2023_paper.pdf) 
* 去雾
  * [Aerial Image Dehazing With Attentive Deformable Transformers](https://openaccess.thecvf.com/content/WACV2023/papers/Kulkarni_Aerial_Image_Dehazing_With_Attentive_Deformable_Transformers_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/AshutoshKulkarni4998/AIDTransformer)
* De-fencing
  * [Efficient Flow-Guided Multi-frame De-fencing](https://openaccess.thecvf.com/content/WACV2023/papers/Tsogkas_Efficient_Flow-Guided_Multi-Frame_De-Fencing_WACV_2023_paper.pdf)
* 阴影消除
  * [Fine-Context Shadow Detection Using Shadow Removal](https://openaccess.thecvf.com/content/WACV2023/papers/Valanarasu_Fine-Context_Shadow_Detection_Using_Shadow_Removal_WACV_2023_paper.pdf) 
  * [LRA&LDRA: Rethinking Residual Predictions for Efficient Shadow Detection and Removal](https://openaccess.thecvf.com/content/WACV2023/papers/Yucel_LRALDRA_Rethinking_Residual_Predictions_for_Efficient_Shadow_Detection_and_Removal_WACV_2023_paper.pdf) 
  * [SHARDS: Efficient SHAdow Removal using Dual Stage Network for High-Resolution Images](https://openaccess.thecvf.com/content/WACV2023/papers/Sen_SHARDS_Efficient_Shadow_Removal_Using_Dual_Stage_Network_for_High-Resolution_WACV_2023_paper.pdf)
   
<a name="7"/>

## 7.Human Pose(人体姿态)
* [Kinematic-aware Hierarchical Attention Network for Human Pose Estimation in Videos](https://arxiv.org/abs/2211.15868)<br>:star:[code](https://github.com/KyungMinJin/HANet)
* [HuPR: A Benchmark for Human Pose Estimation Using Millimeter Wave Radar](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_HuPR_A_Benchmark_for_Human_Pose_Estimation_Using_Millimeter_Wave_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/robert80203/HuPR-A-Benchmark-for-Human-Pose-Estimation-Using-Millimeter-Wave-Radar)
* 多人姿态估计
  * [SoMoFormer: Multi-Person Pose Forecasting with Transformers](https://arxiv.org/abs/2208.14023)<br>:house:[project](https://somof.stanford.edu/result/217/)
* 三维人体
  * [Placing Human Animations into 3D Scenes by Learning Interaction- and Geometry-Driven Keyframes](https://arxiv.org/abs/2209.06314)
  * [Uplift and Upsample: Efficient 3D Human Pose Estimation with Uplifting Transformers](https://arxiv.org/abs/2210.06110)<br>:star:[code](https://github.com/goldbricklemon/uplift-upsample-3dhpe)
  * [Learning 3D Human Pose Estimation from Dozens of Datasets using a Geometry-Aware Autoencoder to Bridge Between Skeleton Formats](https://arxiv.org/abs/2212.14474)<br>:house:[project](https://vision.rwth-aachen.de/wacv23sarandi)
  * [GarSim: Particle Based Neural Garment Simulator](https://openaccess.thecvf.com/content/WACV2023/papers/Tiwari_GarSim_Particle_Based_Neural_Garment_Simulator_WACV_2023_paper.pdf)
  * [Learnable Human Mesh Triangulation for 3D Human Pose and Shape Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Chun_Learnable_Human_Mesh_Triangulation_for_3D_Human_Pose_and_Shape_WACV_2023_paper.pdf)
* 手部姿势
  * 3D手
    * [Marker-Removal Networks To Collect Precise 3D Hand Data for RGB-Based Estimation and Its Application in Piano](https://openaccess.thecvf.com/content/WACV2023/papers/Wu_Marker-Removal_Networks_To_Collect_Precise_3D_Hand_Data_for_RGB-Based_WACV_2023_paper.pdf)
    * [HandGCNFormer: A Novel Topology-Aware Transformer Network for 3D Hand Pose Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_HandGCNFormer_A_Novel_Topology-Aware_Transformer_Network_for_3D_Hand_Pose_WACV_2023_paper.pdf)
    * [Image-free Domain Generalization via CLIP for 3D Hand Pose Estimation](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_Image-Free_Domain_Generalization_via_CLIP_for_3D_Hand_Pose_Estimation_WACV_2023_paper.pdf)
  * 手部重建
    * [THOR-Net: End-to-end Graformer-based Realistic Two Hands and Object Reconstruction with Self-supervision](https://arxiv.org/abs/2210.13853)<br>:star:[code](https://github.com/ATAboukhadra/THOR-Net)
  * 手-物体姿势估计
    * [Interacting Hand-Object Pose Estimation via Dense Mutual Attention](https://arxiv.org/abs/2211.08805)<br>:star:[code](https://github.com/rongakowang/DenseMutualAttention)

<a name="6"/>

## 6.Video(视频相关)
* [A Deep Neural Framework to Detect Individual Advertisement (Ad) from Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_A_Deep_Neural_Framework_To_Detect_Individual_Advertisement_Ad_From_WACV_2023_paper.pdf)
* 视频增强
  * [Fast and Accurate: Video Enhancement Using Sparse Depth](https://openaccess.thecvf.com/content/WACV2023/papers/Feng_Fast_and_Accurate_Video_Enhancement_Using_Sparse_Depth_WACV_2023_paper.pdf)
* 视频理解
  * [Event-Specific Audio-Visual Fusion Layers:A Simple and New Perspective on Video Understanding](https://openaccess.thecvf.com/content/WACV2023/papers/Senocak_Event-Specific_Audio-Visual_Fusion_Layers_A_Simple_and_New_Perspective_on_WACV_2023_paper.pdf)
  * 通用事件边界检测
    * [Motion Aware Self-Supervision for Generic Event Boundary Detection](https://arxiv.org/abs/2210.05574)<br>:star:[code](https://github.com/rayush7/motion_ssl_gebd)
* 视频摘要
  * [Contrastive Losses Are Natural Criteria for Unsupervised Video Summarization](https://arxiv.org/abs/2211.10056)<br>:star:[code](https://github.com/pangzss/pytorch-CTVSUM)
  * [Progressive Video Summarization via Multimodal Self-Supervised Learning](https://arxiv.org/abs/2201.02494)
* 多人检测
  * [Two-level Data Augmentation for Calibrated Multi-view Detection](https://arxiv.org/abs/2210.10756)<br>:star:[code](https://github.com/cvlab-epfl/MVAug)
* 场景识别
  * [MovieCLIP: Visual Scene Recognition in Movies](https://arxiv.org/abs/2210.11065)<br>:house:[project](https://sail.usc.edu/~mica/MovieCLIP/)
* Video Grounding
  * [Language-free Training for Zero-shot Video Grounding](https://arxiv.org/abs/2210.12977)
* 视频异常检测(VAD)
  * [DyAnNet: A Scene Dynamicity Guided Self-Trained Video Anomaly Detection Network](https://arxiv.org/abs/2211.00882)
  * [Cross-Domain Video Anomaly Detection without Target Domain Adaptation](https://arxiv.org/abs/2212.07010)
  * [Bi-Directional Frame Interpolation for Unsupervised Video Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Deng_Bi-Directional_Frame_Interpolation_for_Unsupervised_Video_Anomaly_Detection_WACV_2023_paper.pdf)
  * [Towards Interpretable Video Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Doshi_Towards_Interpretable_Video_Anomaly_Detection_WACV_2023_paper.pdf)
  * [Normality Guided Multiple Instance Learning for Weakly Supervised Video Anomaly Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Park_Normality_Guided_Multiple_Instance_Learning_for_Weakly_Supervised_Video_Anomaly_WACV_2023_paper.pdf)
* 图像视频编解码
  * [Universal Deep Image Compression via Content-Adaptive Optimization with Adapters](https://arxiv.org/abs/2211.00918)<br>:star:[code](https://github.com/kktsubota/universal-dic)
  * [Boosting Neural Video Codecs by Exploiting Hierarchical Redundancy](https://openaccess.thecvf.com/content/WACV2023/papers/Pourreza_Boosting_Neural_Video_Codecs_by_Exploiting_Hierarchical_Redundancy_WACV_2023_paper.pdf)
  * [Neural Distributed Image Compression with Cross-Attention Feature Alignment](https://openaccess.thecvf.com/content/WACV2023/papers/Mital_Neural_Distributed_Image_Compression_With_Cross-Attention_Feature_Alignment_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/ipc-lab/NDIC-CAM)
  * [Lossy Image Compression with Quantized Hierarchical VAEs](https://openaccess.thecvf.com/content/WACV2023/papers/Duan_Lossy_Image_Compression_With_Quantized_Hierarchical_VAEs_WACV_2023_paper.pdf)
* 视频人像合成
  * [Dynamic Neural Portraits](https://arxiv.org/abs/2211.13994)
* 视频帧插值
  * [Splatting-based Synthesis for Video Frame Interpolation](https://arxiv.org/abs/2201.10075)<br>:house:[project](http://sniklaus.com/splatsyn)
  * [FLAVR: Flow-Agnostic Video Representations for Fast Frame Interpolation](https://openaccess.thecvf.com/content/WACV2023/papers/Kalluri_FLAVR_Flow-Agnostic_Video_Representations_for_Fast_Frame_Interpolation_WACV_2023_paper.pdf)<br>:house:[project](https://tarun005.github.io/FLAVR/)
  * [Enhanced Bi-directional Motion Estimation for Video Frame Interpolation](https://openaccess.thecvf.com/content/WACV2023/papers/Jin_Enhanced_Bi-Directional_Motion_Estimation_for_Video_Frame_Interpolation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/srcn-ivl/EBME)
* 视频运动重定位
  * [Cross-Identity Video Motion Retargeting With Joint Transformation and Synthesis](https://openaccess.thecvf.com/content/WACV2023/papers/Ni_Cross-Identity_Video_Motion_Retargeting_With_Joint_Transformation_and_Synthesis_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/nihaomiao/WACV23_TSNet)
* 视频运动放大
  * [Lightweight Network For Video Motion Magnification](https://openaccess.thecvf.com/content/WACV2023/papers/Singh_Lightweight_Network_for_Video_Motion_Magnification_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/jasdeep-singh-007/LightweightNetworkForVideoMotionMagnification)
* 视频稳定
  * [GlobalFlowNet: Video Stabilization using Deep Distilled Global Motion Estimates](https://openaccess.thecvf.com/content/WACV2023/papers/James_GlobalFlowNet_Video_Stabilization_Using_Deep_Distilled_Global_Motion_Estimates_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/GlobalFlowNet/GlobalFlowNet)
* 视频分类
  * [MASTAF: A Model-Agnostic Spatio-Temporal Attention Fusion Network for Few-shot Video Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_MASTAF_A_Model-Agnostic_Spatio-Temporal_Attention_Fusion_Network_for_Few-Shot_Video_WACV_2023_paper.pdf)<br>:house:[project](https://anonymous.4open.science/r/STAF-30CF1/README.md)
* 视频分割
  * [LiveSeg: Unsupervised Multimodal Temporal Segmentation of Long Livestream Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Qiu_LiveSeg_Unsupervised_Multimodal_Temporal_Segmentation_of_Long_Livestream_Videos_WACV_2023_paper.pdf)
* 视频伪造检测
  * [Watch Those Words:Video Falsification Detection Using Word-Conditioned Facial Motion](https://openaccess.thecvf.com/content/WACV2023/papers/Agarwal_Watch_Those_Words_Video_Falsification_Detection_Using_Word-Conditioned_Facial_Motion_WACV_2023_paper.pdf)

<a name="5"/>

## 5.Object Detection(目标检测)
* [ConfMix: Unsupervised Domain Adaptation for Object Detection via Confidence-based Mixing](https://arxiv.org/abs/2210.11539)<br>:star:[code](https://github.com/giuliomattolin/ConfMix)
* [The Box Size Confidence Bias Harms Your Object Detector](https://openaccess.thecvf.com/content/WACV2023/papers/Gilg_The_Box_Size_Confidence_Bias_Harms_Your_Object_Detector_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Blueblue4/ObjectDetection-Confidence-Bias)
* [Resolving Class Imbalance for LiDAR-based Object Detector by Dynamic Weight Average and Contextual Ground Truth Sampling](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_Resolving_Class_Imbalance_for_LiDAR-Based_Object_Detector_by_Dynamic_Weight_WACV_2023_paper.pdf)
* [Is Your Noise Correction Noisy? PLS: Robustness To Label Noise With Two Stage Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Albert_Is_Your_Noise_Correction_Noisy_PLS_Robustness_To_Label_Noise_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/PaulAlbert31/PLS)
* [Phantom Sponges: Exploiting Non-Maximum Suppression to Attack Deep Object Detectors](https://openaccess.thecvf.com/content/WACV2023/papers/Shapira_Phantom_Sponges_Exploiting_Non-Maximum_Suppression_To_Attack_Deep_Object_Detectors_WACV_2023_paper.pdf)
* [Domain Adaptive Object Detection for Autonomous Driving under Foggy Weather](https://arxiv.org/abs/2210.15176)<br>:star:[code](https://github.com/jinlong17/DA-Detect)
* [ROMA: Run-Time Object Detection To Maximize Real-Time Accuracy](https://arxiv.org/abs/2210.16083)
* [Towards Online Domain Adaptive Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/VS_Towards_Online_Domain_Adaptive_Object_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Vibashan/memXformer-online-da)
* [MT-DETR: Robust End-to-end Multimodal Detection with Confidence Fusion](https://openaccess.thecvf.com/content/WACV2023/papers/Chu_MT-DETR_Robust_End-to-End_Multimodal_Detection_With_Confidence_Fusion_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Chushihyun/MT-DETR)
* [Towards Few-Annotation Learning for Object Detection:Are Transformer-based Models More Efficient ?](https://openaccess.thecvf.com/content/WACV2023/papers/Bouniot_Towards_Few-Annotation_Learning_for_Object_Detection_Are_Transformer-Based_Models_More_WACV_2023_paper.pdf)
* [Mobile Robot Manipulation using Pure Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Griffin_Mobile_Robot_Manipulation_Using_Pure_Object_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/griffbr/TFOD)
* 小样本目标检测
  * [Few-shot Object Detection via Improved Classification Features](https://openaccess.thecvf.com/content/WACV2023/papers/Jiang_Few-Shot_Object_Detection_via_Improved_Classification_Features_WACV_2023_paper.pdf)
* 弱监督目标检测
  * [D2F2WOD: Learning Object Proposals for Weakly-Supervised Object Detection via Progressive Domain Adaptation](https://openaccess.thecvf.com/content/WACV2023/papers/Wang_D2F2WOD_Learning_Object_Proposals_for_Weakly-Supervised_Object_Detection_via_Progressive_WACV_2023_paper.pdf)
  * [Complementary Cues from Audio Help Combat Noise in Weakly-Supervised Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Gungor_Complementary_Cues_From_Audio_Help_Combat_Noise_in_Weakly-Supervised_Object_WACV_2023_paper.pdf)<br>:house:[project](https://cagrigungor.github.io/AudioVisualWSOD/)
* 3D目标检测
  * [TransPillars: Coarse-To-Fine Aggregation for Multi-Frame 3D Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Luo_TransPillars_Coarse-To-Fine_Aggregation_for_Multi-Frame_3D_Object_Detection_WACV_2023_paper.pdf)
  * [Adaptive Feature Fusion for Cooperative Perception Using LiDAR Point Clouds](https://openaccess.thecvf.com/content/WACV2023/papers/Qiao_Adaptive_Feature_Fusion_for_Cooperative_Perception_Using_LiDAR_Point_Clouds_WACV_2023_paper.pdf)
  * [ImpDet: Exploring Implicit Fields for 3D Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Qian_ImpDet_Exploring_Implicit_Fields_for_3D_Object_Detection_WACV_2023_paper.pdf)
  * [Li3DeTr: A LiDAR based 3D Detection Transformer](https://arxiv.org/abs/2210.15365)
  * [Far3Det: Towards Far-Field 3D Detection](https://arxiv.org/abs/2211.13858)
  * [Dense Voxel Fusion for 3D Object Detection](https://arxiv.org/abs/2203.00871)
  * [MonoEdge: Monocular 3D Object Detection Using Local Perspectives](https://arxiv.org/pdf/2301.01802.pdf)
  * [Multivariate Probabilistic Monocular 3D Object Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Shi_Multivariate_Probabilistic_Monocular_3D_Object_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Rock-100/MonoDet)
  * [SAILOR: Scaling Anchors via Insights into Latent Object Representation](https://openaccess.thecvf.com/content/WACV2023/papers/Malic_SAILOR_Scaling_Anchors_via_Insights_Into_Latent_Object_Representation_WACV_2023_paper.pdf)
* VOD
  * [BoxMask: Revisiting Bounding Box Supervision for Video Object Detection](https://arxiv.org/abs/2210.06008)
* OOD
  * [Out-of-distribution Detection via Frequency-regularized Generative Models](https://arxiv.org/abs/2208.09083)<br>:star:[code](https://github.com/mu-cai/FRL)
  * [Heatmap-based Out-of-Distribution Detection](https://arxiv.org/abs/2211.08115)<br>:star:[code](https://github.com/jhornauer/heatmap_ood)
  * [Out-of-Distribution Detection with Reconstruction Error and Typicality-based Penalty](https://arxiv.org/abs/2212.12641)
  * [Mixture Outlier Exposure: Towards Out-of-Distribution Detection in Fine-grained Environments](https://openaccess.thecvf.com/content/WACV2023/papers/Zhang_Mixture_Outlier_Exposure_Towards_Out-of-Distribution_Detection_in_Fine-Grained_Environments_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/zjysteven/MixOE)
  * [Hyperdimensional Feature Fusion for Out-of-Distribution Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Wilson_Hyperdimensional_Feature_Fusion_for_Out-of-Distribution_Detection_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/SamWilso/HDFF_Official)
* WSOD
  * [D2DF2WOD: Learning Object Proposals for Weakly-Supervised Object Detection via Progressive Domain Adaptation](https://arxiv.org/abs/2212.01376)
* 伪装目标检测
  * [MFFN: Multi-view Feature Fusion Network for Camouflaged Object Detection](https://arxiv.org/abs/2210.06361)<br>:star:[code](https://github.com/dwardzheng/MFFN_COD)
* 目标发现
  * [Foreground Guidance and Multi-Layer Feature Fusion for Unsupervised Object Discovery with Transformers](https://arxiv.org/abs/2210.13053)<br>:star:[code](https://github.com/VDIGPKU/FORMULA) 
* 变化检测
  * [The Change You Want to See](https://arxiv.org/abs/2209.14341)
* 用于穿行式安检系统的三维雷达图像的实时隐蔽武器检测
  * [Real-Time Concealed Weapon Detection on 3D Radar Images for Walk-Through Screening System](https://openaccess.thecvf.com/content/WACV2023/papers/Khan_Real-Time_Concealed_Weapon_Detection_on_3D_Radar_Images_for_Walk-Through_WACV_2023_paper.pdf)
* 图像识别
  * [Federated Domain Generalization for Image Recognition via Cross-Client Style Transfer](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Federated_Domain_Generalization_for_Image_Recognition_via_Cross-Client_Style_Transfer_WACV_2023_paper.pdf)<br>:house:[project](https://chenjunming.ml/proj/CCST/)
* 入侵物种检测
  * [Deep Learning Methodology for Early Detection and Outbreak Prediction of Invasive Species Growth](https://openaccess.thecvf.com/content/WACV2023/papers/Elias_Deep_Learning_Methodology_for_Early_Detection_and_Outbreak_Prediction_of_WACV_2023_paper.pdf) 

<a name="4"/>

## 4.GAN(生成对抗网络)
* [HoechstGAN: Virtual Lymphocyte Staining Using Generative Adversarial Networks](https://arxiv.org/abs/2210.06909)
* [Image Completion with Heterogeneously Filtered Spectral Hints](https://arxiv.org/abs/2211.03700)<br>:star:[code](https://github.com/SHI-Labs/SH-GAN)
* [Indirect Adversarial Losses via an Intermediate Distribution for Training GANs](https://openaccess.thecvf.com/content/WACV2023/papers/Yang_Indirect_Adversarial_Losses_via_an_Intermediate_Distribution_for_Training_GANs_WACV_2023_paper.pdf)
* [SLI-pSp: Injecting Multi-Scale Spatial Layout in pSp](https://openaccess.thecvf.com/content/WACV2023/papers/Mathur_SLI-pSp_Injecting_Multi-Scale_Spatial_Layout_in_pSp_WACV_2023_paper.pdf)
* [Realistic Full-Body Anonymization with Surface-Guided GANs](https://openaccess.thecvf.com/content/WACV2023/papers/Hukkelas_Realistic_Full-Body_Anonymization_With_Surface-Guided_GANs_WACV_2023_paper.pdf)
* [Fantastic Style Channels and Where to Find Them:A Submodular Framework for Discovering Diverse Directions in GANs](https://openaccess.thecvf.com/content/WACV2023/papers/Simsar_Fantastic_Style_Channels_and_Where_To_Find_Them_A_Submodular_WACV_2023_paper.pdf)
* [3D GAN Inversion with Pose Optimization](https://openaccess.thecvf.com/content/WACV2023/papers/Ko_3D_GAN_Inversion_With_Pose_Optimization_WACV_2023_paper.pdf)<br>:house:[project](https://3dgan-inversion.github.io/)
* [UVCGAN: UNet Vision Transformer cycle-consistent GAN for unpaired image-to-image translation](https://openaccess.thecvf.com/content/WACV2023/papers/Torbunov_UVCGAN_UNet_Vision_Transformer_Cycle-Consistent_GAN_for_Unpaired_Image-to-Image_Translation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/LS4GAN/uvcgan)
* fashion attribute editing(时尚属性编辑)
  * [Leveraging Off-the-shelf Diffusion Model for Multi-attribute Fashion Image Manipulation](https://arxiv.org/abs/2210.05872)
* 匿名化
  * [DeepPrivacy2: Towards Realistic Full-Body Anonymization](https://arxiv.org/abs/2211.09454)<br>:star:[code](https://github.com/hukkelas/deep_privacy2)  
* 指纹生成
  * [Synthetic Latent Fingerprint Generator](https://openaccess.thecvf.com/content/WACV2023/papers/Wyzykowski_Synthetic_Latent_Fingerprint_Generator_WACV_2023_paper.pdf)<br>:house:[project](https://prip-lab.github.io/Synthetic-Latent-Fingerprint-Generator/)  
* 开集识别
  * [MORGAN: Meta-Learning-based Few-Shot Open-Set Recognition via Generative Adversarial Network](https://openaccess.thecvf.com/content/WACV2023/papers/Pal_MORGAN_Meta-Learning-Based_Few-Shot_Open-Set_Recognition_via_Generative_Adversarial_Network_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/DebabrataPal7/MORGAN)  
  
<a name="3"/>

## 3.3D(三维视觉)
* [Generative Range Imaging for Learning Scene Priors of 3D LiDAR Data](https://arxiv.org/abs/2210.11750)<br>:star:[code](https://github.com/kazuto1011/dusty-gan-v2)
* [Seg&Struct: The Interplay Between Part Segmentation and Structure Inference for 3D Shape Parsing](https://arxiv.org/abs/2211.00382)
* [Surface normal estimation from optimized and distributed light sources using DNN-based photometric stereo](https://openaccess.thecvf.com/content/WACV2023/papers/Iwaguchi_Surface_Normal_Estimation_From_Optimized_and_Distributed_Light_Sources_Using_WACV_2023_paper.pdf)
* [Meta-Auxiliary Learning for Future Depth Prediction in Videos](https://openaccess.thecvf.com/content/WACV2023/papers/Liu_Meta-Auxiliary_Learning_for_Future_Depth_Prediction_in_Videos_WACV_2023_paper.pdf)
* [3D Neural Sculpting (3DNS): Editing Neural Signed Distance Functions](https://openaccess.thecvf.com/content/WACV2023/papers/Tzathas_3D_Neural_Sculpting_3DNS_Editing_Neural_Signed_Distance_Functions_WACV_2023_paper.pdf)
* [Improving the Robustness of Point Convolution on k-Nearest Neighbor Neighborhoods with a Viewpoint-Invariant Coordinate Transform](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Improving_the_Robustness_of_Point_Convolution_on_K-Nearest_Neighbor_Neighborhoods_WACV_2023_paper.pdf)
* [CountNet3D: A 3D Computer Vision Approach to Infer Counts of Occluded Objects](https://openaccess.thecvf.com/content/WACV2023/papers/Jenkins_CountNet3D_A_3D_Computer_Vision_Approach_To_Infer_Counts_of_WACV_2023_paper.pdf)
* 三维重建
  * [Automated Line Labelling: Dataset for Contour Detection and 3D Reconstruction](https://openaccess.thecvf.com/content/WACV2023/papers/Santhanam_Automated_Line_Labelling_Dataset_for_Contour_Detection_and_3D_Reconstruction_WACV_2023_paper.pdf)
* 深度估计
  * [Frequency-Aware Self-Supervised Monocular Depth Estimation](https://arxiv.org/abs/2210.05479)<br>:star:[code](https://github.com/xingyuuchen/freq-aware-depth)
  * [Attention Attention Everywhere: Monocular Depth Prediction with Skip Attention](https://arxiv.org/abs/2210.09071)<br>:star:[code](https://github.com/ashutosh1807/PixelFormer)
  * [High-Resolution Depth Estimation for 360-degree Panoramas through Perspective and Panoramic Depth Images Registration](https://arxiv.org/abs/2210.10414)
  * [Improving Pixel-Level Contrastive Learning by Leveraging Exogenous Depth Information](https://arxiv.org/abs/2211.10177)
  * [Temporally Consistent Online Depth Estimation in Dynamic Scenes](https://arxiv.org/abs/2111.09337)<br>:star:[code](https://github.com/facebookresearch/CODD)
  * [Self-Supervised Monocular Depth Estimation: Solving the Edge-Fattening Problem](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Self-Supervised_Monocular_Depth_Estimation_Solving_the_Edge-Fattening_Problem_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/xingyuuchen/tri-depth)
  * [High-Resolution Depth Estimation for 360◦ Panoramas through Perspective and Panoramic Depth Images Registration](https://openaccess.thecvf.com/content/WACV2023/papers/Peng_High-Resolution_Depth_Estimation_for_360deg_Panoramas_Through_Perspective_and_Panoramic_WACV_2023_paper.pdf)
* 深度补全
  * [Sparsity Agnostic Depth Completion](https://arxiv.org/abs/2212.00790)
  * [SIUNet: Sparsity Invariant U-Net for Edge-Aware Depth Completion](https://openaccess.thecvf.com/content/WACV2023/papers/Ramesh_SIUNet_Sparsity_Invariant_U-Net_for_Edge-Aware_Depth_Completion_WACV_2023_paper.pdf)
  * [Uncertainty-Aware Interactive LiDAR Sampling for Deep Depth Completion](https://openaccess.thecvf.com/content/WACV2023/papers/Taguchi_Uncertainty-Aware_Interactive_LiDAR_Sampling_for_Deep_Depth_Completion_WACV_2023_paper.pdf)
* MVS
  * [Multi-View Photometric Stereo Revisited](https://arxiv.org/abs/2210.07670)
  * [DELS-MVS: Deep Epipolar Line Search for Multi-View Stereo](https://arxiv.org/abs/2212.06626)
  * [nLMVS-Net: Deep Non-Lambertian Multi-View Stereo](https://openaccess.thecvf.com/content/WACV2023/papers/Yamashita_nLMVS-Net_Deep_Non-Lambertian_Multi-View_Stereo_WACV_2023_paper.pdf)<br>:house:[project](https://vision.ist.i.kyoto-u.ac.jp/)
  * [360MVSNet: Deep Multi-view Stereo Network with 360◦ Images for Indoor Scene Reconstruction](https://openaccess.thecvf.com/content/WACV2023/papers/Chiu_360MVSNet_Deep_Multi-View_Stereo_Network_With_360deg_Images_for_Indoor_WACV_2023_paper.pdf)
  * [Improving the Pair Selection and the Model Fusion Steps of Satellite Multi-View Stereo Pipelines](https://openaccess.thecvf.com/content/WACV2023/papers/Gomez_Improving_the_Pair_Selection_and_the_Model_Fusion_Steps_of_WACV_2023_paper.pdf)
* RGB-D重建
  * [High-Quality RGB-D Reconstruction via Multi-View Uncalibrated Photometric Stereo and Gradient-SDF](https://arxiv.org/abs/2210.12202)<br>:star:[code](https://github.com/Sangluisme/PSgradientSDF)
* Stereo Matching
  * [Expansion of Visual Hints for Improved Generalization in Stereo Matching](https://arxiv.org/abs/2211.00392)
* 神经辐射场
  * [ScanNeRF: a Scalable Benchmark for Neural Radiance Fields](https://arxiv.org/abs/2211.13762)<br>:house:[project](https://eyecan-ai.github.io/scannerf/)
* 三维定位
  * [3D Change Localization and Captioning From Dynamic Scans of Indoor Scenes](https://openaccess.thecvf.com/content/WACV2023/papers/Qiu_3D_Change_Localization_and_Captioning_From_Dynamic_Scans_of_Indoor_WACV_2023_paper.pdf)

<a name="2"/>

## 2.Medical Image(医学影像)
* [DBCE: A Saliency Method for Medical Deep Learning Through Anatomically-Consistent Free-Form Deformations](https://openaccess.thecvf.com/content/WACV2023/papers/Peters_DBCE_A_Saliency_Method_for_Medical_Deep_Learning_Through_Anatomically-Consistent_WACV_2023_paper.pdf)
* [Representation Recovering for Self-Supervised Pre-training on Medical Images](https://openaccess.thecvf.com/content/WACV2023/papers/Yan_Representation_Recovering_for_Self-Supervised_Pre-Training_on_Medical_Images_WACV_2023_paper.pdf)
* 胸部X光分类
  * [Probabilistic Integration of Object Level Annotations in Chest X-ray Classification](https://arxiv.org/abs/2210.06980)
* CT图像融合
  * [Self-Supervised 2D/3D Registration for X-Ray to CT Image Fusion](https://arxiv.org/abs/2210.07611)
* 医学图像定位
  * [Attend Who is Weak: Pruning-assisted Medical Image Localization under Sophisticated and Implicit Imbalances](https://arxiv.org/abs/2212.02675)
* 医学图像分割
  * [Few-shot Medical Image Segmentation with Cycle-resemblance Attention](https://arxiv.org/abs/2212.03967)
  * [Medical Image Segmentation via Cascaded Attention Decoding](https://openaccess.thecvf.com/content/WACV2023/papers/Rahman_Medical_Image_Segmentation_via_Cascaded_Attention_Decoding_WACV_2023_paper.pdf)
  * [HiFormer: Hierarchical Multi-scale Representations Using Transformers for Medical Image Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Heidari_HiFormer_Hierarchical_Multi-Scale_Representations_Using_Transformers_for_Medical_Image_Segmentation_WACV_2023_paper.pdf)
  * [Training Auxiliary Prototypical Classifiers for Explainable Anomaly Detection in Medical Image Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Cho_Training_Auxiliary_Prototypical_Classifiers_for_Explainable_Anomaly_Detection_in_Medical_WACV_2023_paper.pdf)
  * 病变分割
    * [Cut-Paste Consistency Learning for Semi-Supervised Lesion Segmentation](https://openaccess.thecvf.com/content/WACV2023/papers/Yap_Cut-Paste_Consistency_Learning_for_Semi-Supervised_Lesion_Segmentation_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/BPYap/Cut-Paste-Consistency)
* 医学图像分类
  * [ScoreNet: Learning Non-Uniform Attention and Augmentation for Transformer-Based Histopathological Image Classification](https://openaccess.thecvf.com/content/WACV2023/papers/Stegmuller_ScoreNet_Learning_Non-Uniform_Attention_and_Augmentation_for_Transformer-Based_Histopathological_Image_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/stegmuel/ScoreNet)
* 医学图像超分辨率
  * [Multimodal Multi-Head Convolutional Attention With Various Kernel Sizes for Medical Image Super-Resolution](https://openaccess.thecvf.com/content/WACV2023/papers/Georgescu_Multimodal_Multi-Head_Convolutional_Attention_With_Various_Kernel_Sizes_for_Medical_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/lilygeorgescu/MHCA)
* 心血管检测
  * [Performer: A Novel PPG-to-ECG Reconstruction Transformer for a Digital Biomarker of Cardiovascular Disease Detection](https://openaccess.thecvf.com/content/WACV2023/papers/Lan_Performer_A_Novel_PPG-to-ECG_Reconstruction_Transformer_for_a_Digital_Biomarker_WACV_2023_paper.pdf)
* 远程心率估计
  * [ALPINE: Improving Remote Heart Rate Estimation using Contrastive Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Birla_ALPINE_Improving_Remote_Heart_Rate_Estimation_Using_Contrastive_Learning_WACV_2023_paper.pdf)
* CT重建
  * [PINER: Prior-informed Implicit Neural Representation Learning for Test-time Adaptation in Sparse-view CT Reconstruction](https://openaccess.thecvf.com/content/WACV2023/papers/Song_PINER_Prior-Informed_Implicit_Neural_Representation_Learning_for_Test-Time_Adaptation_in_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/efzero/PINER)

<a name="1"/>

## 1.其它
* [Instance-Dependent Noisy Label Learning via Graphical Modelling](https://arxiv.org/abs/2209.00906)
* [Color Recommendation for Vector Graphic Documents based on Multi-Palette Representation](https://arxiv.org/abs/2209.10820)
* [TeST: Test-time Self-Training under Distribution Shift](https://arxiv.org/abs/2209.11459)
* [Simultaneous Acquisition of High Quality RGB Image and Polarization Information using a Sparse Polarization Sensor](https://arxiv.org/abs/2209.13106)<br>:star:[code](https://github.com/sony/polar-densification)
* [Enabling ISP-less Low-Power Computer Vision](https://arxiv.org/abs/2210.05451)
* [AdaNorm: Adaptive Gradient Norm Correction based Optimizer for CNNs](https://arxiv.org/abs/2210.06364)<br>:star:[code](https://github.com/shivram1987/AdaNorm)
* [Composite Learning for Robust and Effective Dense Predictions](https://arxiv.org/abs/2210.07239)
* [SAILOR: Scaling Anchors via Insights into Latent Object](https://arxiv.org/abs/2210.07811)<br>:star:[code](https://github.com/malicd/sailor)
* [Modeling the Lighting in Scenes as Style for Auto White-Balance Correction](https://arxiv.org/abs/2210.09090)<br>:star:[code](https://github.com/birdortyedi/lighting-as-style-awb-correction)
* [DE-CROP: Data-efficient Certified Robustness for Pretrained Classifiers](https://arxiv.org/abs/2210.08929)<br>:house:[project](https://sites.google.com/view/decrop)
* [Anisotropic Multi-Scale Graph Convolutional Network for Dense Shape Correspondence](https://arxiv.org/abs/2210.09466)
* [ATCON: Attention Consistency for Vision Models](https://arxiv.org/abs/2210.09705)<br>:star:[code](https://github.com/alimirzazadeh/SemisupervisedAttention)
* [LAVA: Label-efficient Visual Learning and Adaptation](https://arxiv.org/abs/2210.10317)
* [Interpolated SelectionConv for Spherical Images and Surfaces](https://arxiv.org/abs/2210.10123)
* [Augmentation by Counterfactual Explanation -- Fixing an Overconfident Classifier](https://arxiv.org/abs/2210.12196)
* [Weakly Supervised Annotations for Multi-modal Greeting Cards Dataset](https://arxiv.org/abs/2212.00847)
* [Multimodal Vision Transformers with Forced Attention for Behavior Analysis](https://arxiv.org/abs/2212.03968)<br>:star:[code](https://github.com/Parapompadoo/FAt-Transformers)
* [Motif Mining: Finding and Summarizing Remixed Image Content](https://openaccess.thecvf.com/content/WACV2023/papers/Theisen_Motif_Mining_Finding_and_Summarizing_Remixed_Image_Content_WACV_2023_paper.pdf)
* [LINEEX: Data Extraction from Scientific Line Charts](https://openaccess.thecvf.com/content/WACV2023/papers/P._LineEX_Data_Extraction_From_Scientific_Line_Charts_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Shiva-sankaran/LineEX)
* [Neural Implicit Representations for Physical Parameter Inference From a Single Video](https://openaccess.thecvf.com/content/WACV2023/papers/Hofherr_Neural_Implicit_Representations_for_Physical_Parameter_Inference_From_a_Single_WACV_2023_paper.pdf)<br>:house:[project](https://florianhofherr.github.io/phys-param-inference/)
* [Physically Plausible Animation of Human Upper Body from a Single Image](https://arxiv.org/abs/2212.04741)
* [Partially Calibrated Semi-Generalized Pose From Hybrid Point Correspondences](https://openaccess.thecvf.com/content/WACV2023/papers/Bhayani_Partially_Calibrated_Semi-Generalized_Pose_From_Hybrid_Point_Correspondences_WACV_2023_paper.pdf)
* [Learning How to MIMIC: Using Model Explanations To Guide Deep Learning Training](https://openaccess.thecvf.com/content/WACV2023/papers/Watson_Learning_How_to_MIMIC_Using_Model_Explanations_To_Guide_Deep_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/mattswatson/learning-to-mimic)
* [Robust and Efficient Alignment of Calcium Imaging Data through Simultaneous Low Rank and Sparse Decomposition](https://openaccess.thecvf.com/content/WACV2023/papers/Cho_Robust_and_Efficient_Alignment_of_Calcium_Imaging_Data_Through_Simultaneous_WACV_2023_paper.pdf)
* [Improving Multi-Fidelity Optimization With a Recurring Learning Rate for Hyperparameter Tuning](https://openaccess.thecvf.com/content/WACV2023/papers/Lee_Improving_Multi-Fidelity_Optimization_With_a_Recurring_Learning_Rate_for_Hyperparameter_WACV_2023_paper.pdf)
* [What can we Learn by Predicting Accuracy?](https://openaccess.thecvf.com/content/WACV2023/papers/Risser-Maroix_What_Can_We_Learn_by_Predicting_Accuracy_WACV_2023_paper.pdf)
* [Jointly Learning Band Selection and Filter Array Design for Hyperspectral Imaging](https://openaccess.thecvf.com/content/WACV2023/papers/Li_Jointly_Learning_Band_Selection_and_Filter_Array_Design_for_Hyperspectral_WACV_2023_paper.pdf)
* [LCS: Learning Compressible Subspaces for Efficient, Adaptive, Real-Time Network Compression at Inference Time](https://openaccess.thecvf.com/content/WACV2023/papers/Nunez_LCS_Learning_Compressible_Subspaces_for_Efficient_Adaptive_Real-Time_Network_Compression_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/apple/learning-compressible-subspaces)
* [Self-Attentive Pooling for Efficient Deep Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Self-Attentive_Pooling_for_Efficient_Deep_Learning_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/C-Fun/Non-Local-Pooling)
* [Fine-Grained Activities of People Worldwide](https://openaccess.thecvf.com/content/WACV2023/papers/Byrne_Fine-Grained_Activities_of_People_Worldwide_WACV_2023_paper.pdf)<br>:house:[project](https://visym.github.io/cap/)
* [Relaxing Contrastiveness in Multimodal Representation Learning](https://openaccess.thecvf.com/content/WACV2023/papers/Lin_Relaxing_Contrastiveness_in_Multimodal_Representation_Learning_WACV_2023_paper.pdf)
* [Spike-Based Anytime Perception](https://openaccess.thecvf.com/content/WACV2023/papers/Dutson_Spike-Based_Anytime_Perception_WACV_2023_paper.pdf)
* [Towards Disturbance-Free Visual Mobile Manipulation](https://openaccess.thecvf.com/content/WACV2023/papers/Ni_Towards_Disturbance-Free_Visual_Mobile_Manipulation_WACV_2023_paper.pdf)<br>:house:[project](https://sites.google.com/view/disturb-free)
* [SERF: Towards Better Training of Deep Neural Networks Using Log-Softplus ERror Activation Function](https://openaccess.thecvf.com/content/WACV2023/papers/Nag_SERF_Towards_Better_Training_of_Deep_Neural_Networks_Using_Log-Softplus_WACV_2023_paper.pdf)
* [RADIANT: Better rPPG Estimation Using Signal Embeddings and Transformer](https://openaccess.thecvf.com/content/WACV2023/papers/Gupta_RADIANT_Better_rPPG_Estimation_Using_Signal_Embeddings_and_Transformer_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/Deep-Intelligence-Lab/RADIANT)
* [Dataset Condensation With Distribution Matching](https://openaccess.thecvf.com/content/WACV2023/papers/Zhao_Dataset_Condensation_With_Distribution_Matching_WACV_2023_paper.pdf)
* [HyperPosePDF - Hypernetworks Predicting the Probability Distribution on SO(3)](https://openaccess.thecvf.com/content/WACV2023/papers/Hofer_HyperPosePDF_-_Hypernetworks_Predicting_the_Probability_Distribution_on_SO3_WACV_2023_paper.pdf)
* [RANCER: Non-Axis Aligned Anisotropic Certification with Randomized Smoothing](https://openaccess.thecvf.com/content/WACV2023/papers/Rumezhak_RANCER_Non-Axis_Aligned_Anisotropic_Certification_With_Randomized_Smoothing_WACV_2023_paper.pdf)
* [Match Cutting: Finding Cuts with Smooth Visual Transitions](https://openaccess.thecvf.com/content/WACV2023/papers/Chen_Match_Cutting_Finding_Cuts_With_Smooth_Visual_Transitions_WACV_2023_paper.pdf)
* [Are Straight-Through gradients and Soft-Thresholding all you need for Sparse Training?](https://openaccess.thecvf.com/content/WACV2023/papers/Vanderschueren_Are_Straight-Through_Gradients_and_Soft-Thresholding_All_You_Need_for_Sparse_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/vanderschuea/stthree)
* [Patch-based Privacy Preserving Neural Network for Vision Tasks](https://openaccess.thecvf.com/content/WACV2023/papers/Mabuchi_Patch-Based_Privacy_Preserving_Neural_Network_for_Vision_Tasks_WACV_2023_paper.pdf)
* [Adaptive Sample Selection for Robust Learning under Label Noise](https://openaccess.thecvf.com/content/WACV2023/papers/Patel_Adaptive_Sample_Selection_for_Robust_Learning_Under_Label_Noise_WACV_2023_paper.pdf)<br>:star:[code](https://github.com/dbp1994/masters_thesis_codes/tree/main/BARE)
* [Improving Saliency Models' Predictions of the Next Fixation With Humans' Intrinsic Cost of Gaze Shifts](https://openaccess.thecvf.com/content/WACV2023/papers/Kadner_Improving_Saliency_Models_Predictions_of_the_Next_Fixation_With_Humans_WACV_2023_paper.pdf)
* [Mapping DNN Embedding Manifolds for Network Generalization Prediction](https://openaccess.thecvf.com/content/WACV2023/papers/OBrien_Mapping_DNN_Embedding_Manifolds_for_Network_Generalization_Prediction_WACV_2023_paper.pdf)
* [GEMS: Generating Efficient Meta-Subnets](https://openaccess.thecvf.com/content/WACV2023/papers/Pimpalkhute_GEMS_Generating_Efficient_Meta-Subnets_WACV_2023_paper.pdf)
* BNN
  * [LAB: Learnable Activation Binarizer for Binary Neural Networks](https://arxiv.org/abs/2210.13858)<br>:star:[code](https://github.com/sfalkena/LAB)
  * [Searching for Robust Binary Neural Networks via Bimodal Parameter Perturbation](https://openaccess.thecvf.com/content/WACV2023/papers/Ahn_Searching_for_Robust_Binary_Neural_Networks_via_Bimodal_Parameter_Perturbation_WACV_2023_paper.pdf)
* 图像配准
  * [Diffeomorphic Image Registration with Neural Velocity Field](https://openaccess.thecvf.com/content/WACV2023/papers/Han_Diffeomorphic_Image_Registration_With_Neural_Velocity_Field_WACV_2023_paper.pdf)
* 视觉重建
  * [SimGlim: Simplifying glimpse based active visual reconstruction](https://openaccess.thecvf.com/content/WACV2023/papers/Jha_SimGlim_Simplifying_Glimpse_Based_Active_Visual_Reconstruction_WACV_2023_paper.pdf)


